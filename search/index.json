[{"content":"Transformer学习记录，py3.8\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 import torch import torch.nn as nn import torch.nn.functional as F import math # 不带可训练权重的PositionalEncoding class PositionalEncoding(nn.Module): def __init__(self, d_model, max_len=5000): \u0026#34;\u0026#34;\u0026#34; @param d_model: 模型的隐藏层维度 \u0026#34;\u0026#34;\u0026#34; super(PositionalEncoding, self).__init__() # 初始化位置编码矩阵，形状为(max_len=5000, d_model=1000)，其中的元素都是0。 self.encoding = torch.zeros(max_len, d_model) # 生成位置信息，形状为(max_len=5000, 1)，其中的元素是从0到max_len-1的整数。 position = torch.arange(0, max_len).unsqueeze(1).float() # # 计算分母的指数项，用于生成正弦和余弦函数的周期。 # # torch.arange(0, d_model, 2).float()：创建了一个从0到d_model-1的整数序列，步长为2 # div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)) # # 利用正弦和余弦函数生成位置编码矩阵 # self.encoding[:, 0::2] = torch.sin(position * div_term) # self.encoding[:, 1::2] = torch.cos(position * div_term) # 利用正弦和余弦函数生成位置编码矩阵 div_term = torch.arange(0, d_model, 2).float() / d_model self.encoding[:, 0::2] = torch.sin(position / torch.pow(10000.0, div_term)) self.encoding[:, 1::2] = torch.cos(position / torch.pow(10000.0, div_term)) # 将位置编码矩阵扩展为三维 # self.encoding 是一个形状为 (max_len, d_model) 的二维张量，表示位置编码矩阵 # 通过 unsqueeze(0)，形状变为 (1, max_len, d_model) # 以便与输入嵌入的词向量(batch_size, sequence_length, embedding_dim)进行相加 self.encoding = self.encoding.unsqueeze(0) def forward(self, x): \u0026#34;\u0026#34;\u0026#34; 前向传播方法，将位置编码加到输入张量上 @param x: 输入张量，形状为 (batch_size, seq_len, d_model) @return: 添加了位置编码后的张量 \u0026#34;\u0026#34;\u0026#34; # 在输入张量的第二维上加上位置编码 x = x + self.encoding[:, :x.size(1)] return x class MultiheadAttention(nn.Module): def __init__(self, d_model, n_heads): super(MultiheadAttention, self).__init__() self.d_model = d_model # 模型输入维度 self.n_heads = n_heads # 注意力头的数量 # 计算每个注意力头的维度 self.head_dim = d_model // n_heads # Query、Key和Value的线性变换 self.WQ = nn.Linear(d_model, d_model) self.WK = nn.Linear(d_model, d_model) self.WV = nn.Linear(d_model, d_model) # 注意力机制输出后的线性变换 self.fc_out = nn.Linear(d_model, d_model) def forward(self, query, key, value, mask=None): # mask在Encoder时是padding mask，在Decoder时是padding+自回归mask batch_size = query.size(0) # 对Query、Key和Value进行线性变换 # print(query.shape) Q = self.WQ(query) K = self.WK(key) V = self.WV(value) # print(Q.shape) # 为了进行多头注意力，对Q、K、V进行形状变换和转置 # TODO:这个地方，多头是把Embedding_dimension拆掉了？512变成了8个头和64？ # Embedding_dimension是一个单词或标记的编码维度。拆分和多头注意力机制的设计是为了让模型更好地捕捉输入序列的不同方面和关系。 Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) K = K.view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) V = V.view(batch_size, -1, self.n_heads, self.head_dim).transpose(1, 2) # 计算缩放点积注意力得分 scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim) # 如果提供了掩码，应用掩码 if mask is not None: scores = scores.masked_fill(mask == 0, float(\u0026#39;-1e20\u0026#39;)) # 应用softmax获取注意力权重，dim 参数用于指定在哪个维度上进行 softmax scores = F.softmax(scores, dim=-1) # 应用注意力权重到Values上 attention = torch.matmul(scores, V) # 恢复原始形状,[batch_size, num_heads, seq_len, embedding_dim]-\u0026gt;[batch_size, seq_len, num_heads, embedding_dim] # .contiguous() 是一个用于确保张量在内存中是连续的方法，切片和转置会造成矩阵在内存中不连续。 # .view(batch_size, -1, self.d_model): 这一步是对张量进行形状的变换。 # -1表示该维度的大小由其他维度决定，这里的目的是将num_heads和embedding_dim # 这两个维度合并成一个维度。最终得到的形状为[batch_size, seq_len, num_heads * embedding_dim]。 # 注意：注意力的多头输出仍然保持在同一个张量中，并没有进行显式的拼接操作。不是像 GoogleNet 那样进行拼接。 # 这样的设计是为了保持并行计算的效率，同时融合了不同头的信息。 attention = attention.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model) # TODO:多头注意力后，有 fc 吗？ # 最终输出的线性变换 output = self.fc_out(attention) return output # 定义位置前馈神经网络层 class PositionwiseFeedforward(nn.Module): def __init__(self, d_model, d_ff): super(PositionwiseFeedforward, self).__init__() # 第一个全连接层，输入维度为d_model，输出维度为d_ff self.fc1 = nn.Linear(d_model, d_ff) # 第二个全连接层，输入维度为d_ff，输出维度为d_model self.fc2 = nn.Linear(d_ff, d_model) def forward(self, x): # TODO:x是一个torch.Size([32, 20, 512])的张量。 # 使用ReLU激活函数的第一个全连接层 x = F.relu(self.fc1(x)) # 第二个全连接层，无激活函数 x = self.fc2(x) return x # 定义Transformer编码器 class TransformerEncoder(nn.Module): def __init__(self, d_model, n_heads, n_layers, d_ff): \u0026#34;\u0026#34;\u0026#34; @param d_model: 模型的隐藏层维度 @param n_heads: 注意力头的数量 @param n_layers: Transformer层的数量 @param d_ff: 位置前馈神经网络中间层的维度 \u0026#34;\u0026#34;\u0026#34; super(TransformerEncoder, self).__init__() # 词嵌入层，输入词汇表大小，输出维度为d_model self.embedding = nn.Embedding(input_vocab_size, d_model) # 位置编码层 self.positional_encoding = PositionalEncoding(d_model) # 由多个Transformer编码器层组成的层列表 self.transformer_layers = nn.ModuleList( [TransformerEncoderLayer(d_model, n_heads, d_ff) for _ in range(n_layers)]) def forward(self, x, mask=None): # 输入序列经过词嵌入层 x = self.embedding(x) # 加上位置编码 x = self.positional_encoding(x) # 通过多个Transformer编码器层 for layer in self.transformer_layers: x = layer(x, mask) return x # 定义Transformer编码器层 class TransformerEncoderLayer(nn.Module): def __init__(self, d_model, n_heads, d_ff): super(TransformerEncoderLayer, self).__init__() # 多头自注意力层 self.self_attention = MultiheadAttention(d_model, n_heads) # 位置前馈神经网络层 self.feedforward = PositionwiseFeedforward(d_model, d_ff) # 第一个Layer Normalization层，用于多头自注意力层输出后的残差连接 self.norm1 = nn.LayerNorm(d_model) # 第二个Layer Normalization层，用于前馈神经网络层输出后的残差连接 self.norm2 = nn.LayerNorm(d_model) # Dropout层，用于增加模型的泛化能力 self.dropout = nn.Dropout(0.1) def forward(self, x, mask=None): # 多头自注意力层的前向传播，传入相同的Query、Key和Value（self-attention） self_attention_out = self.self_attention(x, x, x, mask=mask) # 残差连接和Layer Normalization x = x + self.dropout(self_attention_out) x = self.norm1(x) # 位置前馈神经网络层的前向传播 ff_out = self.feedforward(x) # 残差连接和Layer Normalization x = x + self.dropout(ff_out) x = self.norm2(x) return x class TransformerDecoderLayer(nn.Module): def __init__(self, d_model, n_heads, d_ff): \u0026#34;\u0026#34;\u0026#34; 定义Transformer解码器层 @param d_model: 模型的隐藏层维度 @param n_heads: 注意力头的数量 @param d_ff: 位置前馈神经网络中间层的维度 \u0026#34;\u0026#34;\u0026#34; super(TransformerDecoderLayer, self).__init__() # 多头自注意力层，用于处理目标序列的内部关系 self.self_attention = MultiheadAttention(d_model, n_heads) # 多头注意力层，用于处理源序列到目标序列的关系 self.encoder_attention = MultiheadAttention(d_model, n_heads) # 位置前馈神经网络层 self.feedforward = PositionwiseFeedforward(d_model, d_ff) # 第一个Layer Normalization层，用于自注意力层输出后的残差连接 self.norm1 = nn.LayerNorm(d_model) # 第二个Layer Normalization层，用于源到目标注意力层输出后的残差连接 self.norm2 = nn.LayerNorm(d_model) # 第三个Layer Normalization层，用于前馈神经网络层输出后的残差连接 self.norm3 = nn.LayerNorm(d_model) # Dropout层，用于增加模型的泛化能力 self.dropout = nn.Dropout(0.1) def forward(self, x, encoder_output, src_mask=None, trg_mask=None): # 多头自注意力层的前向传播，传入相同的Query、Key和Value（self-attention），使用目标序列的mask self_attention_out = self.self_attention(x, x, x, mask=trg_mask) # 残差连接和Layer Normalization x = x + self.dropout(self_attention_out) x = self.norm1(x) # 多头注意力层的前向传播，传入Query为解码器的输出，Key和Value为编码器的输出，使用源序列的mask encoder_attention_out = self.encoder_attention(x, encoder_output, encoder_output, mask=src_mask) # 残差连接和Layer Normalization x = x + self.dropout(encoder_attention_out) x = self.norm2(x) # 位置前馈神经网络层的前向传播 ff_out = self.feedforward(x) # 残差连接和Layer Normalization x = x + self.dropout(ff_out) x = self.norm3(x) return x # 定义Transformer解码器 class TransformerDecoder(nn.Module): def __init__(self, d_model, n_heads, n_layers, d_ff, output_vocab_size): \u0026#34;\u0026#34;\u0026#34; @param d_model: 模型的隐藏层维度 @param n_heads: 注意力头的数量 @param n_layers: Transformer层的数量 @param d_ff: 位置前馈神经网络中间层的维度 @param output_vocab_size: 输出词汇表的大小 \u0026#34;\u0026#34;\u0026#34; super(TransformerDecoder, self).__init__() # 词嵌入层，输入词汇表大小，输出维度为d_model self.embedding = nn.Embedding(output_vocab_size, d_model) # 位置编码层 self.positional_encoding = PositionalEncoding(d_model) # 由多个Transformer解码器层组成的层列表 self.decoder_layers = nn.ModuleList([TransformerDecoderLayer(d_model, n_heads, d_ff) for _ in range(n_layers)]) # 最终输出层，将解码器的输出映射到词汇表大小 self.fc_out = nn.Linear(d_model, output_vocab_size) def forward(self, encoder_output, trg, src_mask=None, trg_mask=None): # 目标序列的词嵌入和位置编码 trg_emb = self.embedding(trg) trg_emb = self.positional_encoding(trg_emb) # 通过多个Transformer解码器层 for layer in self.decoder_layers: trg_emb = layer(trg_emb, encoder_output, src_mask, trg_mask) # 最终输出层，将解码器的输出映射到词汇表大小 output = self.fc_out(trg_emb) return output # 定义整体的Transformer模型 class Transformer(nn.Module): def __init__(self, d_model, n_heads, n_layers, d_ff, output_vocab_size): \u0026#34;\u0026#34;\u0026#34; @param d_model: 模型的隐藏层维度 @param n_heads: 注意力头的数量 @param n_layers: Transformer层的数量 @param d_ff: 位置前馈神经网络中间层的维度 @param input_vocab_size: 输入词汇表的大小 @param output_vocab_size: 输出词汇表的大小 \u0026#34;\u0026#34;\u0026#34; # TODO，这个地方没用到input_vocab_size super(Transformer, self).__init__() # Transformer编码器 self.encoder = TransformerEncoder(d_model, n_heads, n_layers, d_ff) # Transformer解码器 self.decoder = TransformerDecoder(d_model, n_heads, n_layers, d_ff, output_vocab_size) def forward(self, src, trg): # 源序列的padding mask，插入维度后：(batch_size, 1, 1, sequence_length) src_mask = (src != 0).unsqueeze(1).unsqueeze(2) # 目标序列的mask trg_mask = self.create_target_mask(trg) # 通过编码器得到编码器的输出 encoder_output = self.encoder(src, src_mask) # 通过解码器得到最终输出 output = self.decoder(encoder_output, trg, src_mask, trg_mask) return output # 创建目标序列的mask，包括填充部分和未来部分 def create_target_mask(self, target_data): # 创建目标序列的填充mask # (target_data != 0) 生成一个布尔张量，表示目标序列中非填充位置的元素 # .unsqueeze(1).unsqueeze(2) 在布尔张量的第一维和第二维上插入新的维度 # 形状变为 (batch_size, 1, 1, sequence_length) trg_pad_mask = (target_data != 0).unsqueeze(1).unsqueeze(2) # 获取目标序列的长度, (batch_size, sequence_length)取下角标1，即sequence_length=10 trg_len = target_data.size(1) # 创建目标序列的自回归（subsequent）mask，(sequence_length, sequence_length) # torch.tril(torch.ones(...)) 生成下三角矩阵，对角线及以下的元素为1，其余为0 # .bool() 将矩阵元素类型转换为布尔型 # 确保在计算自注意力时每个位置只能关注到当前位置及之前的位置 trg_subsequent_mask = torch.tril(torch.ones(trg_len, trg_len)).bool() # 将填充mask和自回归mask结合，取两者的逻辑与，得到最终的目标序列mask，(batch_size, 1, sequence_length, sequence_length) trg_mask = trg_pad_mask \u0026amp; trg_subsequent_mask return trg_mask # 示例用法 # Transformer模型的参数配置 d_model = 512 # 模型的隐藏层维度 n_heads = 8 # 注意力头的数量 n_layers = 6 # Transformer层的数量 d_ff = 2048 # 位置前馈神经网络中间层的维度 input_vocab_size = 10000 # 输入词汇表的大小 output_vocab_size = 10000 # 输出词汇表的大小 # 数据批次配置 # 例如，在机器翻译任务中，src_seq_length 可以表示输入语言的句子长度，而 trg_seq_length 表示对应的目标语言的句子长度。 # 这两个值可以根据数据集的最大句子长度进行设置。 batch_size = 32 # 每个批次的样本数量 src_seq_length = 20 # 源序列的长度 trg_seq_length = 10 # 目标序列的长度 # 创建Transformer模型实例 transformer = Transformer(d_model, n_heads, n_layers, d_ff, output_vocab_size) # 随机生成输入序列和目标序列数据，范围0-output_vocab_size，(batch_size, src_seq_length)：这是生成的整数张量的形状 input_data = torch.randint(0, input_vocab_size, (batch_size, src_seq_length)) target_data = torch.randint(0, output_vocab_size, (batch_size, trg_seq_length)) # 将数据传入Transformer模型进行前向传播 output = transformer(input_data, target_data) # 打印输出张量的形状 print(output.shape) # from tensorboardX import SummaryWriter # with SummaryWriter(log_dir=\u0026#39;\u0026#39;) as sw: # 实例化 SummaryWriter ,可以自定义数据输出路径 # sw.add_graph(transformer, (input_data,target_data)) # 输出网络结构图 # sw.close() # 关闭 sw ","date":"2024-12-22T00:00:00Z","permalink":"https://UPPO8.github.io/Myblog/p/%E6%9E%84%E5%BB%BAtransformer/","title":"构建Transformer"},{"content":"基于TensorFlow框架的线性回归 TensorFlow中文官网：\nhttps://tensorflow.google.cn/?hl=zh-cn 使用TensorFlow框架实现线性回归：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import tensorflow as tf import numpy as np # 1、散点输入，定义输入数据 data = [[-0.5, 7.7], [1.8, 98.5], [0.9, 57.8], [0.4, 39.2], [-1.4, -15.7], [-1.4, -37.3], [-1.8, -49.1], [1.5, 75.6], [0.4, 34.0], [0.8, 62.3]] # data列表10*2 # 转换成numpy data = np.array(data) x_data = data[:, 0] y_data = data[:, 1] # 转换成TensorFlow张量 x_train = tf.constant(x_data, dtype=tf.float32) y_train = tf.constant(y_data, dtype=tf.float32) # 2、定义前向模型 # (1, )指的是(None, 1)形状 model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1, ))]) # 3、定义损失函数和优化器 optimizer = tf.keras.optimizers.SGD(learning_rate=0.01) model.compile(optimizer=optimizer, loss=\u0026#34;mean_squared_error\u0026#34;) # 4、开始迭代 epoches = 500 # history = model.fit(x_train, y_train, epochs=epoches) for epoch in range(1, epoches + 1): history = model.fit(x_train, y_train, verbose=0) loss = history.history[\u0026#34;loss\u0026#34;][0] # 5、显示频率设置 if epoch % 10 == 0 or epoch == 1: print(f\u0026#34;epoch:{epoch}, loss:{loss}\u0026#34;) TensorFlow数据集的加载 https://tensorflow.google.cn/api_docs/python/tf/data/Dataset 1 2 3 4 5 6 7 # 转换成TensorFlow张量 x_train = tf.constant(x_data, dtype=tf.float32) y_train = tf.constant(y_data, dtype=tf.float32) dataset = tf.data.Dataset.from_tensor_slices(x_train,y_train) for TensorFlow模型保存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 import tensorflow as tf import numpy as np from tensorflow.keras import Model seed = 42 tf.random.set_seed(42) # 1、散点输入，定义输入数据 data = [[-0.5, 7.7], [1.8, 98.5], [0.9, 57.8], [0.4, 39.2], [-1.4, -15.7], [-1.4, -37.3], [-1.8, -49.1], [1.5, 75.6], [0.4, 34.0], [0.8, 62.3]] # data列表10*2 # 转换成numpy data = np.array(data) x_data = data[:, 0] y_data = data[:, 1] # 转换成TensorFlow张量 # x_train = tf.constant(x_data, dtype=tf.float32) x_train = tf.constant(np.expand_dims(x_data, axis=1), dtype=tf.float32) y_train = tf.constant(y_data, dtype=tf.float32) dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)) dataset = dataset.shuffle(buffer_size=10) dataset = dataset.batch(10) # CPU取数据同时GPU、TPU训练，CPU会预先取出来一批数据，在CPU上训练无效果 dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE) # for item in dataset: # print(item) # 2、定义前向模型 # (1, )指的是(None, 1)形状 # 方案1： # model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1, ))]) # 方案2： # model = tf.keras.Sequential() # model.add(tf.keras.Input(shape=(1, ))) # model.add(tf.keras.layers.Dense(1)) # 方案3： # class Linear(Model): # def __init__(self): # super(Linear, self).__init__() # self.linear = tf.keras.layers.Dense(1) # # def call(self, x, **kwargs): # x = self.linear(x) # return x # # model = Linear() # 方案4 def linear(): input = tf.keras.layers.Input(shape=(1, ), dtype=tf.float32) y = tf.keras.layers.Dense(1)(input) model = tf.keras.models.Model(inputs=input, outputs=y) return model model = linear() # 3、定义损失函数和优化器 optimizer = tf.keras.optimizers.SGD(learning_rate=0.01) model.compile(optimizer=optimizer, loss=\u0026#34;mean_squared_error\u0026#34;) # 4、开始迭代 epoches = 500 history = model.fit(x_train, y_train, epochs=epoches) # for epoch in range(1, epoches + 1): # total_loss = 0 # for batch_x, batch_y in dataset: # history = model.fit(x_train, y_train, verbose=0) # loss = history.history[\u0026#34;loss\u0026#34;][0] # total_loss += loss # # 计算平均损失 # avg_loss = total_loss / len(dataset) # # # 5、显示频率设置 # if epoch % 10 == 0 or epoch == 1: # print(f\u0026#34;epoch:{epoch}, avg_loss:{avg_loss}\u0026#34;) # 1、HDF5文件，模型必须是函数式模型或者是顺序模型，保存参数、模型结构、训练的配置 # model.save(\u0026#34;./my_model.h5\u0026#34;) # 2、只保存参数 model.save_weights(\u0026#34;model_weights.h5\u0026#34;) # 3、savedmodel格式，TensorFlow序列化格式，适合在不同的TensorFlow环境中部署 # TensorFlow serving model.save(\u0026#34;./saved_model\u0026#34;, save_format=\u0026#34;tf\u0026#34;) TensorFlow网络结构查看 模型网络结构是用TensorBoardX查看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 import tensorflow as tf import numpy as np from tensorflow.keras import Model seed = 42 tf.random.set_seed(42) # 1、散点输入，定义输入数据 data = [[-0.5, 7.7], [1.8, 98.5], [0.9, 57.8], [0.4, 39.2], [-1.4, -15.7], [-1.4, -37.3], [-1.8, -49.1], [1.5, 75.6], [0.4, 34.0], [0.8, 62.3]] # data列表10*2 # 转换成numpy data = np.array(data) x_data = data[:, 0] y_data = data[:, 1] # 转换成TensorFlow张量 # x_train = tf.constant(x_data, dtype=tf.float32) x_train = tf.constant(np.expand_dims(x_data, axis=1), dtype=tf.float32) y_train = tf.constant(y_data, dtype=tf.float32) dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)) dataset = dataset.shuffle(buffer_size=10) dataset = dataset.batch(10) # CPU取数据同时GPU、TPU训练，CPU会预先取出来一批数据，在CPU上训练无效果 dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE) # 2、定义前向模型 # 方案4 def linear(): input = tf.keras.layers.Input(shape=(1, ), dtype=tf.float32) y = tf.keras.layers.Dense(1)(input) model = tf.keras.models.Model(inputs=input, outputs=y) return model model = linear() # 3、定义损失函数和优化器 optimizer = tf.keras.optimizers.SGD(learning_rate=0.01) model.compile(optimizer=optimizer, loss=\u0026#34;mean_squared_error\u0026#34;) # 1) summary # print(model.summary()) # 2) plot_model函数保存网络结构图 # tf.keras.utils.plot_model(model, to_file=\u0026#34;model.png\u0026#34;, show_shapes=True) # 3)netron # 4)tensorboard方法 epoches = 500 # 在计算图中添加模型 tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\u0026#34;./logs\u0026#34;) model.fit(x_train, y_train, epochs=epoches, callbacks=[tensorboard_callback]) ","date":"2024-11-18T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/MachineLearning/2024.jpg","permalink":"https://UPPO8.github.io/Myblog/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-3/","title":"机器学习-3"},{"content":"Pytorch是什么 PyTorch 是一个开源的深度学习框架，由Meta公司（原名：Facebook）的人工智能研究团队开发和维护。它提供了一个灵活、动态的计算图计算模型，使得在深度学习领域进行实验和开发变得更加简单和直观。\n官网链接：\nhttps://pytorch.org/ PyTorch特点：\n动态计算图:\nPyTorch 使用动态计算图，这意味着计算图是在运行时构建的，而不是在编 译时静态定义的。\n自动求导（微分）:\nPyTorch 提供了自动求导机制，称为 Autograd。它能够自动计算张量的梯 度，这对于训练神经网络和其他深度学习模型非常有用。\n丰富的神经网络库:\nPyTorch 提供了丰富的神经网络库，包括各种各样的层、损失函数、优化器 等。这些库使得构建和训练神经网络变得更加容易。\n支持GPU加速:\nPyTorch 充分利用了 GPU 的并行计算能力，能够在 GPU 上高效地进行计 算，加速模型训练过程。\ntensor是什么 tensor是一种多维数组，类似于NumPy的ndarray。它是PyTorch中最基本的数据结构，用于存储和操作数据。tensor可以是标量、向量、矩阵或更高维度的数组，可以包含整数、浮点数或其他数据类型的元素。\nPyTorch的tensor与NumPy的ndarray非常相似，但在设计和功能上有一些不同之处。主要的区别包括：GPU加速、自动求导、动态计算图。\n1 2 3 4 5 6 7 8 9 10 11 12 13 import torch # 打印一个标量 scalar_tensor = torch.tensor(3.14) print(\u0026#34;scalar_tensor:\u0026#34;, scalar_tensor) # 打印一个向量 vector_tensor = torch.tensor([1, 2, 3, 4, 5, 6]) print(\u0026#34;vector_tensor:\u0026#34;, vector_tensor) 打印一个矩阵 matrix_tensor = torch.tensor([[1, 2], [3, 4]]) print(\u0026#34;matrix_tensor:\u0026#34;, matrix_tensor) tensor的存储机制 在 PyTorch 中，tensor 包含了两个部分，即 storage 和 metadata。Storage（存储）：存储是 tensor 中包含的实际数据的底层缓冲区，它是一维数组，存储了 tensor 的元素值。不同 tensor 可能共享相同的存储，即使它们具有不同的形状和步幅。存储是一块连续的内存区域，实际上存储了 tensor 中的数据。\nMetadata（元数据）：元数据是 tensor 的描述性信息，包括 tensor 的形状、数据类型、步幅、存储偏移量、设备等。元数据提供了关于 tensor 的结构和属性的信息，但并不包含 tensor 中的实际数据。元数据允许 PyTorch 知道如何正确地解释存储中的数据以及如何访问它们。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import torch tensor1 = torch.tensor([[1., 2, 3], [4, 5, 6]]) # 打印张量 print(tensor1) # 打印形状 print(tensor1.shape) # 数据类型 print(tensor1.dtype) # 存储的内容 print(tensor1.storage().tolist()) \u0026#39;\u0026#39;\u0026#39;打印结果\u0026#39;\u0026#39;\u0026#39; tensor([[1., 2., 3.], [4., 5., 6.]]) torch.Size([2, 3]) torch.float32 [0, 0, 128, 63, 0, 0, 0, 64, 0, 0, 64, 64, 0, 0, 128, 64, 0, 0, 160, 64, 0, 0, 192, 64] Storage存储的具体过程 在PyTorch中，张量的存储是通过torch.Storage类来管理的。张量的值被分配在连续的内存块中，这些内存块是大小可变的一维数组，可以包含不同类型的数据，如float或int32。\n具体来说，当我们创建一个张量时，PyTorch会根据我们提供的数据和指定的数据类型来分配一块连续的内存空间。这块内存空间由torch.Storage对象管理，而张量本身则提供了一种视图，让我们可以通过多维索引来访问这些数据。\n此外，PyTorch还提供了一系列的函数和方法来操作张量，包括改变形状、获取元素、拼接和拆分等。这些操作通常不会改变底层的存储，而是返回一个新的张量视图，这个视图指向相同的数据但可能有不同的形状或索引方式。\n总的来说，张量的存储实现是PyTorch能够高效进行张量运算的关键。通过管理一块连续的内存空间，并提供了丰富的操作方法，使得用户可以方便地对多维数组进行各种计算和变换。\ntensor的步长 步长指的是在每个维度上移动一个元素时在底层存储中需要跨越的元素数。\n1 2 3 4 5 6 7 8 9 a = torch.arange(12).reshape(3, 4) print(a) print(a.stride()) \u0026#39;\u0026#39;\u0026#39;打印结果\u0026#39;\u0026#39;\u0026#39; tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) (4, 1) 第一个数字4表示在矩阵的行（第一个维度）上移动一个元素时需要跨越的存储单元数。因为矩阵的每行包含4个元素，所以每次沿着行移动一个元素需要跨越4个存储单元。\n第二个数字1表示在矩阵的列（第二个维度）上移动一个元素时需要跨越的存储单元数。因为矩阵的列数是1，所以在列上移动一个元素时只需跨越一个存储单元。\ntensor的偏移 偏移是指从张量的第一个元素开始的索引位置。\n1 2 3 4 5 6 7 8 9 10 11 a = torch.arange(12).reshape(3, 4) print(a) b=a[1:3,0:2] print(b) \u0026#39;\u0026#39;\u0026#39;打印结果\u0026#39;\u0026#39;\u0026#39; tensor([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) tensor([[4, 5], [8, 9]]) 选取第2行到第3行、第1列到第2列的元素，得到了一个新的张量b。\ntensor的连续性 Tensor的连续性是什么 Tensor的连续性指的是其元素在内存中按照其在张量中的顺序紧密存储，没有间隔或间隔是连续的。生成的tensor样子（张量中的顺序）：\n1 2 3 4 5 6 7 8 9 10 11 12 [ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11] 展开后： [0,1,2,3,4,5,6,7,8,9,10,11] 在storage存储（内存中）： [0,1,2,3,4,5,6,7,8,9,10,11] 生成的tensor根据“行优先”策略，在展开后与storage存储的顺序是一致，即该tensor连续。 tensor的不连续性举例 当对Tensor进行某些操作，如转置（transpose）时，可能会导致Tensor变得不连续。\n连续的tensor优势：\n高效的内存访问：连续的张量在内存中占用一块连续的空间，这使得CPU可以高效地按顺序访问数据，减少了内存寻址的时间，从而提高了数据处理的速度。 优化的计算性能：在进行数学运算时，连续张量可以减少数据的移动和复制，因为数据已经按照计算所需的顺序排列，这样可以减少计算中的延迟，提高整体的计算性能。 其它：在不连续的tensor上进行view()操作会报错。 解决方案：\n通过contiguous()方法将不连续的张量转换为连续的张量。 如果tensor不是连续的，则会重新开辟一块内存空间保证数据是在内存中是连续的。 如果Tensor 是连续的，则contiguous()无操作。\nPyTorch模型保存与加载 该函数将模型的状态字典保存到文件中，其中包括模型的权重 和其他参数。\n1 2 3 4 5 6 7 8 9 10 11 12 import torch import torch.nn as nn #假设一个模型 model = nn.Linear(5,2) #保存一个模型的权重和其他参数 torch.save(model.state_dict(), \u0026#39;model.pth\u0026#39;) #保存整个模型 torch.save(model, \u0026#39;entire_model.pth\u0026#39;) #加载一个模型的状态字典 model.load_state_dict(torch.load(\u0026#39;model.pth\u0026#39;)) #或加载整个模型 entire_model= torch.load(\u0026#39;entire_model.pth\u0026#39;) model.state_dict() 返回模型的状态字典，其中包含模型的所有参数。然后，torch.save() 函数将这个状态字典保存到名为 \u0026lsquo;model.pth\u0026rsquo; 的文件中。\n整个模型保存到名为 \u0026rsquo;entire_model.pth\u0026rsquo; 的文件中。但是要注意，保存整个模型可能会占用更多的磁盘空间，并且不如保存状态字典灵活，因为状态字典可以与不同的模型结构兼容。\n基于PyTorch框架的线性回归原理 定义前向模型 其中的输入特征和输出特征对应了y=wx+b公式中的x和y，所以只能选1，也就是只有一个输入特征x和一个输出特征y。如果学过线性代数，你可以把它认为是一个1*n的矩阵，n指的是n个散点，即一行n列。如果没学过，那么就暂时把它当做是所有散点横坐标或者纵坐标的一个数组就行。\n定义损失函数 损失函数的选择通常取决于具体的任务和数据类型。对于分类问题，常用的损失函数包括交叉熵损失函数、对数损失函数等；对于回归问题，常用的损失函数包括均方误差损失函数、平均绝对误差损失函数等。\n构建前向模型 nn.sequential nn.sequential是pytorch的一个容器，按顺序组合多个网络层。\nnn.sequential默认带forward方法。\n1 model = nn.Sequential(nn.Linear(1,1)) nn.ModuleList 按列表组合多个网络层\n1 model = nn.ModuleList(nn.Linear(1,1)) nn.ModeleDict 按字典组合多个网络层\n1 model = nn.ModeleDict(\u0026#39;Linear\u0026#39;:nn.Linear(1,1)) 完整代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 import torch import torch.nn as nn import numpy as np # #设置一个随机数种子，确保每次运行开始时相同 # seed =55 # torch.manual_seed(seed) # torch.rand(3,4) # 1.散点输入 data = [[-0.5, 7.7], [1.8, 98.5], [0.9, 57.8], [0.4, 39.2], [-1.4, -15.7], [-1.4, -37.3], [-1.8, -49.1], [1.5, 75.6], [0.4, 34.0], [0.8, 62.3]] # # 转换为Numpy数组 data = np.array(data) # 提取x和y x_data = data[:, 0] y_data = data[:, 1] #将x y转换为tensor x_train = torch.tensor(x_data, dtype=torch.float32) y_train = torch.tensor(y_data, dtype=torch.float32) #print(x_train) #设置一个随机数种子，确保每次运行开始时相同 seed =55 torch.manual_seed(seed) # 2. 定义前向模型 model = nn.Linear(1,1) # 3. 定义损失函数和优化器 criterion = nn.MSELoss() optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # 4. 开始迭代 epochs =500 for n in range(1,epochs+1): #维度对齐 y_hat = model(x_train.unsqueeze(1)) loss = criterion(y_hat.squeeze(1), y_train) #清空之前存储在优化器中的梯度 optimizer.zero_grad() #计算损失函数关于模型参数的梯度 loss.backward() #根据优化算法更新参数 optimizer.step() # 5. 显示频率设置 if n % 10 ==0 or n==1: print(f\u0026#39;epoch: {n}, loss: {loss.item()}\u0026#39;) 使用ensorDataset加载数据集 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 import torch import torch.nn as nn from torch.utils.data import TensorDataset, DataLoader import numpy as np # 1.散点输入 data = [[-0.5, 7.7], [1.8, 98.5], [0.9, 57.8], [0.4, 39.2], [-1.4, -15.7], [-1.4, -37.3], [-1.8, -49.1], [1.5, 75.6], [0.4, 34.0], [0.8, 62.3]] # # 转换为Numpy数组 data = np.array(data) # 提取x和y x_data = data[:, 0] y_data = data[:, 1] #将x y转换为tensor x_train = torch.tensor(x_data, dtype=torch.float32) y_train = torch.tensor(y_data, dtype=torch.float32) #用于封装张量。 将输入张量和目标张量组成一个数据集。 dataset = TensorDataset(x_train, y_train) .... #加载数据。 每次去四个。 打乱。 dataloader = DataLoader(dataset, batch_size=4, shuffle=True) for n in range(1,epochs+1): total_loss = 0 for batch_x,batch_y in dataloader: #维度对齐 y_hat = model(batch_x.unsqueeze(1)) loss = criterion(y_hat.squeeze(1), batch_y) total_loss += loss #清空之前存储在优化器中的梯度 optimizer.zero_grad() #计算损失函数关于模型参数的梯度 loss.backward() #根据优化算法更新参数 optimizer.step() # 计算的平均损失。 avg_loss = total_loss/len(dataloader) # 5. 显示频率设置 if n % 10 ==0 or n==1: print(f\u0026#39;epoch: {n}, loss: {avg_loss}\u0026#39;) ","date":"2024-11-15T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/MachineLearning/2024.jpg","permalink":"https://UPPO8.github.io/Myblog/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-2/","title":"机器学习-2"},{"content":"介绍 机器学习 (ML) 是人工智能 (AI) 的一个分支，旨在构建能够根据所使用的数据进行学习或改进性能的系统。\n人工智能是一个宽泛的术语，指的是模仿人类智能的系统或机器。机器学习和人工智能这两个术语经常被相提并论，有时甚至互换使用，但它们的含义并不相同。其中一个重大区别是，所有的机器学习都是 AI，但不是所有的 AI 都是机器学习。\n具体介绍可以在网络上搜索，\nhttps://www.oracle.com/cn/artificial-intelligence/machine-learning/what-is-machine-learning/\nhttps://easyai.tech/ai-definition/machine-learning/\n机器学习分类 监督学习 监督学习是从已有的训练数据集（标记数据）中学习模型，然后对新的数据进行预测的一种机器学习方法。\n常见的算法如：\n线性回归：通过找到最佳拟合线来预测因变量的值。 逻辑回归：用于二元分类的监督学习算法 决策树：通过构建树状结构来对新的数据进行分类或回归。 这些在分类问题和回归问题中应用场景更多\n无监督学习 它的定义是通过分析输入数据的特点和结构，自动地找出数据中的模式和规律，而不需要人工标注和干预。\n他的常见算法如：\nK-means：用于聚类分析。 DBSCAN：基于密度的算法，发现任意形状的聚类。 层次聚类：基于距离的算法，将数据点按照距离远近进行聚类。 他的应用场景多用于数据分析，如\n聚类：将数据集划分为多个组。 降维：将高维数据降维，更容易理解和可视化数据。 关联规则学习：超市购物篮分析中，发现哪些商品经常一起被购买。 半监督学习 它的定义是利用标记和未标记的数据来进行训练和预测。\n这一类算法较多，如：\n标签传播：通过迭代地传播标签，使得每个样本的标签都尽可能地一致。 学习算法：通过学习算法可以训练出更好的模型，提高分类准确率。 它的应用场景也较广，如：\n分类问题：垃圾邮件识别、人脸识别等。 聚类问题：市场细分、社交网络分析等。 强化学习 它的定义是通过试错的方式让机器学习如何做出最优决策。\n它的常见算法有：\nQ-Learning：构建Q表来对环境进行建模实现决策。 Deep Q Network (DQN)：结合深度学习通过训练神经网络来逼近Q函数，实现更高效的学习。 Policy Gradient Methods：优化策略寻找最优解。 它的应用场景：\n游戏AI：AlphaGo，通过自我对弈提升技能。 机器人控制：根据环境反馈进行自我调整，实现更精准的控制。 scikit-learn工具介绍 scikit-learn提供了简单高效的算法和工具，方便用户快速进行数据分析和机器学习。其模块化设计，使得用户可以根据需要自由组合不同的算法和工具。并且提供了丰富多样的机器学习算法，包括分类、回归、聚类、降维等，满足用户不同需求。\n官网：https://scikit-learn.org/\n安装scikit-learn 使用pip或conda等包管理工具进行安装，例如：\npip install -U scikit-learn 基本使用方法 导入必要的模块和函数，例如：\n1 2 from sklearn.linear_model import LinearRegression 使用场景 数据清洗：scikit-learn提供了数据清洗的功能，包括缺失值处 理和异常值检测等。 特征选择：scikit-learn提供了特征选择的功能，可以帮助用户 选择最重要的特征，提高模型的准确率。 特征转换：scikit-learn提供了特征转换的功能，可以将原始特 征转换为更符合模型需求的特征。 优缺点 优点\n功能强大：scikit-learn提供了丰富的机器学习算法和工具，可以满足各种不同的需求。 易于使用：scikit-learn的API设计简洁明了，易于理解和使用，降低了机器学习的门槛。 社区支持：scikit-learn拥有庞大的用户和开发者社区，为使用者提供了丰富的资源和支持。 缺点 不易理解：对于初学者来说，scikit-learn的文档和API可能难以理解，特别是英文官网，入手难度高，中文网站API往往滞后。\nKNN算法 介绍 KNN算法是一种基于实例的学习，通过测量不同数据点之间的距离进行分类或回归分析。 其原理是基于实例的学习（instance-based learning），属于懒惰学习（lazy learning），即KNN没有显式的学习过程，也就是说没有训练阶段，它是通过测量不同数据点之间的距离进行分类或回归分析。\nKNN算法的特点是简单易懂，易于实现；无需训练阶段，直接进行分类或回归；适用于多分类问题；对数据集的大小和维度不敏感。\n比如在下面这个问题中，在某二维平面内有三种不同颜色的点：红色、蓝色、绿色，它们的颜色和它们的位置（即X、Y轴的坐标）有关系，给它们三类点画出它们各自的“房间”，采用KNN解决。\n计算过程 那么如何使用KNN将新的点进行分类呢？需要给KNN制定步骤：\n（1）计算距离；\n（2）取出距离最近的点，找到新的点与哪一类更接近，观察分类结果。\n在预测过程中：新的点就是某一个真实的二维坐标的点。 在绘制决策边界时：新的点是二维坐标中所有的点（为了使其可计算，每隔距离x取一个点）。\nKNN最简单的思想是：找到与预测数据最相近的K个数据，然后对预测数据进行投票，票数最高的标签作为预测数据的标签。当k=1时，K近邻算法就变成了近邻算法。\n不同的K值的决策边界:\nk值为3：\n结论 K值选择太小：\n优点：复杂的数据集，K值较小可能会提供更详细的决策边界，因为模型更加灵活。\n缺点：容易受到局部结构的影响，模型对噪声和异常值的影响更大。\nK值选择太大：\n优点：考虑了更多的全局信息，对于平滑的数据集，较大的K值可以提供更稳定的决策边界。\n缺点：对于复杂的数据集，较大的K值可能会导致模型过于简单，无法准确捕获数据的局部特征。\nK是什么：在KNN中，需要人为选择不同的K的不同取值，这个参数是需要人为选择的。需要人为确定的参数称为超参数（hyperparameter）。\n因此k值的确定步骤：\n准备数据集：准备好包含特征和标签的数据集。 K折交叉验证：确定K的值，例如选择5或7作为K值。 划分数据集：将数据集划分为K个大小相似的子集。 循环训练和评估：使用K-1个子集作为训练集，剩余的1个子集作为测试集。在训练集上练KNN模型。使用训练好的模型对测试集进行预测。使用性能指标评估。 计算平均性能：将K次验证的性能指标取平均值，作为KNN模型的最终性能评估。 选择最佳K值：尝试不同的K值，并通过交叉验证选择性能最好的K值。然后选择在交叉验证中表现最佳的K值。 选定最终的K值：使用选择的最佳K值，在整个训练集上重新训练KNN模型，以获得最终的模型。 代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # 导入必须的库 from sklearn.neighbors import KNeighborsClassifier import numpy as np import matplotlib.pyplot as plt # 1、定义数据集 # 定义三个点集 point1 = [[7.7, 6.1], [3.1, 5.9], [8.6, 8.8], [9.5, 7.3], [3.9, 7.4], [5.0, 5.3], [1.0, 7.3]] point2 = [[0.2, 2.2], [4.5, 4.1], [0.5, 1.1], [2.7, 3.0], [4.7, 0.2], [2.9, 3.3], [7.3, 7.9]] point3 = [[9.2, 0.7], [9.2, 2.1], [7.3, 4.5], [8.9, 2.9], [9.5, 3.7], [7.7, 3.7], [9.4, 2.4]] # 点集特征的合并 np_train_data = np.concatenate((point1, point2, point3), axis=0) # print(np_train_data) # 根据输入的数据创建标签 np_train_label = np.array([0] * len(point1) + [1] * len(point2) + [2] * len(point3)) # 2、构建KNN算法：实例化KNN算法，KNN训练 # 初始化K近邻分类器 knn_clf = KNeighborsClassifier(1) # 训练 knn_clf.fit(np_train_data, np_train_label) # 3、设定未知点，设定坐标点网络 axis = [0, 10, 0, 10] # 生成坐标点网络 x0, x1 = np.meshgrid( np.linspace(axis[0], axis[1], 100), # x轴上的均匀的点 np.linspace(axis[0], axis[1], 100) # y轴上的均匀的点 ) axis_xy = np.c_[x0.ravel(), x1.ravel()] # 4、KNN的预测与绘制决策边界 y_predict = knn_clf.predict(axis_xy) y_predict = y_predict.reshape(x0.shape) # 等高线的绘制 plt.contour(x0, x1, y_predict) plt.scatter(np_train_data[np_train_label == 0, 0], np_train_data[np_train_label == 0, 1], marker=\u0026#34;^\u0026#34;) plt.scatter(np_train_data[np_train_label == 1, 0], np_train_data[np_train_label == 1, 1], marker=\u0026#34;*\u0026#34;) plt.scatter(np_train_data[np_train_label == 2, 0], np_train_data[np_train_label == 2, 1], marker=\u0026#34;s\u0026#34;) plt.show() 前向传播与损失函数 前向传播 前向传播是机器学习和深度学习中一种信息传递的过程。在神经网络中，前向传播指的是将输入数据通过网络的各个层，依次传递到输出层的过程。\n在前向传播中，每一层的神经元会根据输入数据和对应的权重进行计算，产生一个输出。这个输出又会作为下一层的输入，参与到下一层的计算中。通过这种方式，数据会在网络中不断传递，直到达到输出层。\n在传统的神经网络中，前向传播的计算可以用矩阵乘法和非线性激活函数来表示。首先，将输入数据表示为一个向量，然后和对应的权重矩阵进行乘法运算，得到一个中间层的输出。接着，对这个输出应用非线性激活函数，以引入非线性变换。最后，将这个结果作为下一层的输入，依次进行计算，直到达到输出层。\n通过前向传播，神经网络可以通过学习输入数据和对应标签之间的模式，实现对未知数据的预测和分类。前向传播过程中的参数即网络的权重和偏置，最终会被用于计算损失函数。\n损失函数 损失函数是衡量模型预测结果与实际标签之间差异的指标。在机器学习和深度学习中，通常使用损失函数来衡量模型的性能。\n损失函数的选择通常取决于具体的任务和数据类型。对于分类问题，常用的损失函数包括交叉熵损失函数、对数损失函数等；对于回归问题，常用的损失函数包括均方误差损失函数、平均绝对误差损失函数等。\n在训练神经网络时，我们的目标是最小化损失函数。通过反向传播算法，我们可以根据损失函数的导数来调整网络中的权重和偏置，从而使得模型能够更好地拟合训练数据。\n损失函数的选择和优化对于模型的性能和泛化能力有重要影响。一个合适的损失函数可以帮助模型更好地学习数据之间的模式，并且在实际应用中能够得到良好的结果。\n前向传播与损失函数的关系 前向传播和损失函数是紧密相关的。在前向传播过程中，数据会通过网络的各个层，最终到达输出层。在这个过程中，每一层的神经元会根据输入数据和权重进行计算，产生一个输出。\n而损失函数衡量了模型的预测结果与实际标签之间的差异。通过比较预测结果和实际标签，损失函数可以量化模型的性能，评估其预测的准确性和误差大小。\n在训练过程中，我们通过最小化损失函数来优化模型。通过反向传播算法，我们可以根据损失函数关于网络参数的导数，来调整参数的取值，从而使得模型的预测结果更接近真实标签。\n通过不断迭代前向传播和损失函数的计算，我们可以逐渐优化模型的性能。最终，我们可以得到一个在训练数据上表现良好的模型，能够在新数据上做出准确的预测。\n","date":"2024-11-11T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/MachineLearning/2024.jpg","permalink":"https://UPPO8.github.io/Myblog/p/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1/","title":"机器学习-1"},{"content":"图像梯度处理 sober算子，， 图像梯度计算的是图像变化的速度。对于图像的边缘部分，其灰度值变化较大，梯度值也较大；相反，对于图像中比较平滑的部分，其灰度值变化较小，相应的梯度值也较小。一般情况下，图像梯度计算的是图像的边缘信息。\nSobel 算子是一种离散的微分算子，该算子结合了高斯平滑和微分求导运算。该算子利用局部差分寻找边缘，计算所得的是一个梯度的近似值。下图为Sobel算子示例：\n[-1 0 1] [-1 -2 -1] [-2 0 2] [0 0 0] [-1 0 1] [1 2 1] dst = cv2.Sobel( src, ddepth, dx, dy,ksize, scale, delta, borderType )\n式中：\ndst 代表目标图像。\nsrc 代表原始图像。\nddepth 代表输出图像的深度，-1：与输入图像深度相同。\ndx 代表 x 方向上的求导阶数，值为1或0。\ndy 代表 y 方向上的求导阶数，值为1或0。\n（dx和dy不能同时为0）\nksize 代表 Sobel 核的大小。该值为-1 时，则会使用 Scharr 算子进行运算。\nscale 代表计算导数值时所采用的缩放因子，默认情况下该值是 1，是没有缩放的。\nfilter2D方法 参考链接：\nhttps://docs.opencv.org/4.5.1/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04 dst=cv.filter2D(src, ddepth, kernel, dst, anchor, delta, borderType)\n式中的参数与sobel类似。\nLaplaceian算子 参考链接：\nhttps://docs.opencv.org/4.5.1/d4/d86/group__imgproc__filter.html#gad78703e4c8fe703d479c1860d76429e6 dst\t=\tcv.Laplacian(src, ddepth, dst, ksize, scale, delta, borderType)\n例子 原图:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import cv2 import numpy as np if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./001.png\u0026#34; image_np = cv2.imread(path) #使用sobel算子 sobel_res = cv2.Sobel(image_np, -1, 1, 0, ksize=3) #filter2D方法 kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32) f2D_res = cv2.filter2D(image_np, -1, kernel) #使用拉普拉斯变换 laplcian_res = cv2.Laplacian(image_np, -1) # 返回处理正确后的内容 cv2.imshow(\u0026#34;sobel\u0026#34;, sobel_res) cv2.imwrite(\u0026#34;002.png\u0026#34;, sobel_res) cv2.imshow(\u0026#39;filter2D\u0026#39;, f2D_res) cv2.imwrite(\u0026#34;003.png\u0026#34;, f2D_res) cv2.imshow(\u0026#34;laplacian\u0026#34;, laplcian_res) cv2.imwrite(\u0026#34;004.png\u0026#34;, laplcian_res) cv2.waitKey(0) 使用sobel算子：\nfilter2D方法：\n使用拉普拉斯变换：\n图像边缘检测 canny算法 Canny算法是一种被广泛应用于边缘检测的标准算法，其目标是找到一个最优的边缘检测解或找寻一幅图像中灰度强度变化最强的位置。最优边缘检测主要通过低错误率、高定位性和最小响应三个标准进行评价。Canny算子的简要步骤如下：\n（1）去噪声：应用高斯滤波来平滑图像，目的是去除噪声\n（2）梯度：找寻图像的梯度\n（3）非极大值抑制：应用非最大抑制技术来过滤掉非边缘像素，将模糊的边界变得清晰。该过程保留了每个像素点上梯度强度的极大值，过滤掉其他的值。\n（4）应用双阈值的方法来决定可能的（潜在的）边界；\n（5）利用滞后技术来跟踪边界。若某一像素位置和强边界相连的弱边界认为是边界，其他的弱边界则被删除。\n非极大值抑制 对于每个像素点，它进行如下操作：应用非最大抑制技术来过滤掉非边缘像素，将模糊的边界变得清晰。该过程保留了每个像素点上梯度强度的极大值，过滤掉其他的值。\n1）将其梯度方向近似为以下值中的一个，包括0、45、90、135、180、225、270和315，即表示上下左右和45度方向。\n2）比较该像素点和其梯度正负方向的像素点的梯度强度，如果该像素点梯度强度最大则保留，否则抑制（删除，即置为0）。\n双阈值筛选 经过非极大抑制后图像中仍然有很多噪声点。Canny算法中应用了一种叫双阈值的技术。即设定一个阈值上界和阈值下界（opencv中通常由人为指定的），图像中的像素点如果大于阈值上界则认为必然是边界（称为强边界，strong edge），小于阈值下界则认为必然不是边界，两者之间的则认为是候选项（称为弱边界，weak edge），需进行进一步处理。\n示例 在OpenCV中，Canny() 函数用法如下所示：\nedges = Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]])\n其中，参数：\nmage 表示输入图像； edges 表示输出的边缘图，其大小和类型与输入图像相同； threshold1 表示第一个滞后性阈值； threshold2 表示第二个滞后性阈值； apertureSize 表示应用Sobel算子的孔径大小，其默认值为3； L2gradient 表示一个计算图像梯度幅值的标识，默认值为false。 原图：\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import cv2 if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./002.png\u0026#34; image_np = cv2.imread(path) # 转为灰度图 image_np_gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY) # 进行二值化 ret, image_np_thresh = cv2.threshold( image_np_gray, 127, 255, cv2.THRESH_BINARY) # canny边缘检测 edges_images = cv2.Canny(image_np_thresh, 30, 70) # 返回处理正确后的内容 cv2.imshow(\u0026#34;edges_images\u0026#34;, edges_images) #cv2.imwrite(\u0026#39;006.png\u0026#39;, edges_images) cv2.waitKey(0) 结果展示：\n参考链接 https://docs.opencv.org/4.5.1/da/d5c/tutorial_canny_detector.html\nhttps://blog.csdn.net/zaishuiyifangxym/article/details/90142702\n图像凸包检测 凸包：通俗的说，就是完全凸起，没有凹处的多边形，也叫做凸多边形。一般来说凸包都是伴随着某类点集存在的，也被称为某个点集的凸包。\n对于一个点集来说，如果该点集存在凸包，那么这个点集中的所有的点要么在这个凸包上，要么在这个凸包内。\n凸包检测常用在物体识别、手势识别及边界检测等领域。\ngraham扫描法 Graham扫描法：\n将纵坐标最小的点记为P0，且以该点为原点构建二维坐标系，那么P0就一定是一个凸包点。 计算各个点对于P0的角度�，按照从小到大的顺序进行排序（逆时针顺序），当角度相同时,与P0 较近的点排在前面。那么角度最大的点和角度最小的点一定是凸包点。 用栈来记录已知的凸包点，先将P0和P1放入栈中，然后去求下一个凸包点。 入栈下一个点，将栈顶的两个点相连，得到一条直线。看下一个点在直线的右侧还是左侧，如果 是右侧就执行步骤5，如果在左侧或在直线上就执行步骤6。 如果在右侧，说明栈顶的那个点不是凸包点，将栈顶元素出栈并执行步骤4。 如果在左侧或直线上，说明该点是凸包点，就将其保存。 检查栈顶的点是不是步骤2中角度值最大的那个点，如果是就结束了，如果不是就将当前点的下个 点作为要计算的对象，执行步骤4，直到栈顶元素就是步骤2中角度值最大的点，那么循环结束。 Andrew扫描链法 Andrew扫描链法:\n对所有点按坐标x为第一关键字、y为第二关键字排序，第1个和最后一个肯定在凸包上。包点，这样就可以构建出下凸包。 先顺序遍历所有点，通过三个点所构建的两个向量的叉积来判断是不是凸 然后逆序遍历所有点，按照相同的方式就可以构建出上凸包，最后将上凸 包和下凸包连接即可。 QuickHull法 QuickHull法：\n将所有的点放在二维坐标系中，找到最横坐标最小和最大的两个点P1和 P2并连线。此时整个点集被该直线分为两部分，直线上方叫上包，直线 下方叫下包。 以上包为例，找到上包中的点距离该直线最远的点P3，连线P1、P3，并 寻找直线P1P3左侧的点与直线P2P3右侧的点，然后重复本步骤，直到找 不到为止。对下包也是这么操作。 示例 原图：\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import cv2 if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./011.png\u0026#34; image = cv2.imread(path) convex_image = image.copy() # 得到灰度图做Canny边缘检测 image_np_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) edges = cv2.Canny(image_np_gray, 120, 255, 0) # 提取并绘制轮廓 contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) img_contour = cv2.drawContours(convex_image, contours, -1, (0, 255, 0), 2) # 寻找凸包 hulls = [] for contour in contours: hull = cv2.convexHull(contour) hulls.append(hull) # 绘制凸包 img_convex_hull = cv2.drawContours(image, hulls, -1, (0, 255, 0), 2) # 返回处理正确后的内容 cv2.imshow(\u0026#34;convex_image\u0026#34;, img_convex_hull) #cv2.imwrite(\u0026#39;012.png\u0026#39;, convex_image) cv2.waitKey(0) 结果展示：\n绘制图像轮廓 轮廓的概念： 轮廓是指目标物体或者区域在图像中的外部边界线或者边界区域，通常由一系 列相连的像素组成，这些像素共同构成了一个封闭的形状，从而组成了轮廓。\n轮廓与边缘的区别： 轮廓是一组连续的点或线，而边缘不连续。并且边缘更多的是作为图像的特征使用，比如可以用边缘特征来区分脸和手，而轮廓主要用来分析物体的形态，比如物体的周长、面积等。\n轮廓的作用：\n形状分析：通过轮廓，可以分析物体的形状，比如是圆形、矩形还是更复 杂的形状。 目标识别：在识别特定物体时，轮廓可以作为物体的一个重要特征。 图像分割：利用轮廓，可以将图像分割成多个区域，每个区域代表一个物 体或者物体的一个部分。 检测轮廓 在opencv中,使用cv2.findContours()函数来查找检测物体的轮廓:\ncontours, hierarchy = cv2.findContours(image, mode, method)\n式中：\nimage：输入图像. mode：轮廓的模式。cv2.RETR_EXTERNAL只检测外轮廓；cv2.RETR_LIST检测的轮廓不建立等级关系；cv2.RETR_CCOMP建立两个等级的轮廓，上一层为外边界，内层为内孔的边界。如果内孔内还有连通物体，则这个物体的边界也在顶层；cv2.RETR_TREE建立一个等级树结构的轮廓。 method：轮廓的近似方法。cv2.CHAIN_APPROX_NOME存储所有的轮廓点，相邻的两个点的像素位置差不超过1；cv2.CHAIN_APPROX_SIMPLE压缩水平方向、垂直方向、对角线方向的元素，只保留该方向的终点坐标，例如一个矩形轮廓只需要4个点来保存轮廓信息；cv2.CHAIN_APPROX_TC89_L1，cv2.CV_CHAIN_APPROX_TC89_KCOS contours：返回的轮廓 hierarchy：每条轮廓对应的属性 轮廓的绘制 OpenCV中通过cv2.drawContours在图像上绘制轮廓。\ncv2.drawContours(image, contours, contourIdx, color, thickness=None, lineType=None, hierarchy=None, maxLevel=None, offset=None)\n式中：\n第一个参数是指明在哪幅图像上绘制轮廓； 第二个参数是轮廓本身，在Python中是一个list。 第三个参数指定绘制轮廓list中的哪条轮廓，如果是-1，则绘制其中的所有轮廓。 color：线的颜色（0，0，255）表示红色；（255，0，0）表示蓝色； thickness表明轮廓线的宽度，如果是-1（cv2.FILLED），则为填充模式。 示例 实现代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import cv2 if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./007.png\u0026#34; image_np = cv2.imread(path) contour_image = image_np.copy() # 转为灰度图 image_np_gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY) # 进行二值化 ret, image_np_thresh = cv2.threshold(image_np_gray, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU) # 查找轮廓 contours, hierarchy = cv2.findContours(image_np_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # 绘制轮廓 cv2.drawContours(contour_image, contours, -1, (0, 0, 255), 2) # 结果显示 cv2.imshow(\u0026#34;contour_image\u0026#34;, contour_image) cv2.waitKey(0) 结果展示： ","date":"2024-10-31T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/OpenCVCourse/write-plan.jpg","permalink":"https://UPPO8.github.io/Myblog/p/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E4%B8%8Eopencv-3/","title":"机器视觉与OpenCV-3"},{"content":"形态学变换 形态学变换：是一种基于形状的简单变化，它的处理对象通常是二值化图像。他的操作对象由两部分组成，一个是要进行形态学变换的原始的二值图像，另一个是核(在这里也叫做结构化元素)。\n形态学变换的基本操作有两种：腐蚀和膨胀。\n腐蚀 腐蚀操作是将物体的边缘加以腐蚀。具体的操作方法是拿一个宽m，高n的矩形作为模板，对图像中的每一个像素x做如下处理：像素x至于模板的中心，根据模版的大小，遍历所有被模板覆盖的其他像素，修改像素x的值为所有像素中最小的值。这样操作的结果是会将图像外围的突出点加以腐蚀。如下图的操作过程：\n腐蚀的原理简单说就是，在背景为黑（0），前景为白（1）的图像中，核（1）与其覆盖的图像部分做“与”操作，如果全为1，则该像素点为1，否则为0；也就是1不容易得到，白色部分更少了，白色部分被腐蚀了。\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import cv2 from matplotlib import pyplot as plt if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./006.png\u0026#34; image_np = cv2.imread(path) # 转为灰度图 image_np_gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY) # 进行自适应二值化 image_np_thresh = cv2.adaptiveThreshold( image_np_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) #形态学操作 #设定卷积核 kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)) erode_images = cv2.erode(image_np_thresh, kernel) dilate_images = cv2.dilate(image_np_thresh, kernel) # 返回处理正确后的内容 titles = [\u0026#39;thresh Image\u0026#39;, \u0026#39;erode_images\u0026#39;, \u0026#39;dilate_images\u0026#39;] images = [image_np_thresh, erode_images, dilate_images] for i in range(3): plt.subplot(1,3,i+1), plt.imshow(images[i], \u0026#39;gray\u0026#39;) plt.title(titles[i]) plt.xticks([]), plt.yticks([]) plt.show() 膨胀 膨胀操作与腐蚀操作相反，是将图像的轮廓加以膨胀。操作方法与腐蚀操作类似，也是拿一个矩形模板，对图像的每个像素做遍历处理。不同之处在于修改像素的值不是所有像素中最小的值，而是最大的值。这样操作的结果会将图像外围的突出点连接并向外延伸。如下图的操作过程：\n膨胀的原理简单说就是，在背景为黑（0），前景为白（1）的图像中，核（1）与其覆盖的图像部分做“与”操作，如果全为0，则该像素点为0，否则为1；也就是1容易得到，图像更多的地方变白了，白色部分膨胀了。\n代码实现见上。\n卷积核 上面代码实现中，设定卷积核时：kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)) 这一行代码中两个必须的参数，cv2.MORPH_RECT是设定卷积核的形状,有三种形状： cv2. MORPH_RECT：矩形结构元素，所有元素值都是1； cv2. MORPH_CROSS：十字形结构元素，对角线元素值都是1； cv2. MORPH_ELLIPSE：椭圆形结构元素\n（3，3）设定卷积核的大小.一般有3×3，5×5，7×7\n不同的卷积核，处理后的结果也不同。 实现代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import cv2 from matplotlib import pyplot as plt if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./006.png\u0026#34; image_np = cv2.imread(path) # 转为灰度图 image_np_gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY) # 进行自适应二值化 image_np_thresh = cv2.adaptiveThreshold( image_np_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 3) #形态学操作 #设定卷积核 kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)) kernel2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)) kernel3 = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3)) kernel4 = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) kernel5 = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7)) #不同卷积核形状对比 erode_MORPH_RECT = cv2.erode(image_np_thresh, kernel1) erode_MORPH_ELLIPSE = cv2.erode(image_np_thresh, kernel2) erode_MORPH_CROSS = cv2.erode(image_np_thresh, kernel3) #不同卷积核大小对比 kernel_size_3 = cv2.erode(image_np_thresh, kernel1) kernel_size_5 = cv2.erode(image_np_thresh, kernel4) kernel_size_7 = cv2.erode(image_np_thresh, kernel5) # 返回处理正确后的内容 titles = [\u0026#39;MORPH_RECT\u0026#39;,\u0026#39;MORPH_ELLIPSE\u0026#39;,\u0026#39;MORPH_CROSS\u0026#39;, \u0026#39;kernel_size_3\u0026#39;,\u0026#39;kernel_size_5\u0026#39;,\u0026#39;kernel_size_7\u0026#39;] images = [erode_MORPH_RECT,erode_MORPH_ELLIPSE,erode_MORPH_CROSS, kernel_size_3,kernel_size_5,kernel_size_7] for i in range(6): plt.subplot(2,3,i+1), plt.imshow(images[i], \u0026#39;gray\u0026#39;) plt.title(titles[i]) plt.xticks([]) plt.yticks([]) plt.show() HSV颜色空间 RGB颜色模型使用红、绿、蓝三原色的强度来表示颜色，是一种加色法模型，即颜色的混合是添加三原色的强度。而HSV颜色空间使用色调（Hue）、饱和度（Saturation）和亮度（Value）三个参数来表示颜色，色调H表示颜色的种类，如红色、绿色、蓝色等；饱和度表示颜色的纯度或强度，如红色越纯，饱和度就越高；亮度表示颜色的明暗程度，如黑色比白色亮度低。\n色调H：\n使用角度度量，取值范围为0°~360°，从红色开始按逆时针方向计算，红色为0°，绿色为120°，蓝色为240°。它们的补色是：黄色为60°，青色为180°，紫色为300°。通过改变H的值，可以选择不同的颜色。\n饱和度S：\n饱和度S表示颜色接近光谱色的程度。一种颜色可以看成是某种光谱色与白色混合的结果，其中光谱色所占的比例越大，颜色接近光谱色的程度就越高，颜色的饱和度就越高。通常取值范围为0%~100%，其中0%表示灰色或无色，100%表示纯色，通过调整饱和度的值，可以使颜色变得更加鲜艳或者更加灰暗。\n明度V：\n明度表示颜色明亮的程度，对于光源色，明度值与发光体的光亮度有关；对于物体色，此值和物体的透射比或反射比有关。通常取值范围为0%（黑）到100%（白），通过调整明度的值，可以使颜色变得更亮或者更暗。\nHSV的优点：\n符合人类对颜色的感知方式：人类对颜色的感知是基于色调、饱和度和亮度三个维度的，而HSV颜色空间恰好就是通过这三个维度来描述颜色的。 颜色调整更加直观：在RGB空间中要调整红色系的颜色，需要同时调整R、G、B三个通道的数值，而在HSV空间中只需要调整色调和饱和度即可。 图片颜色识别 使用OpenCV中cvtColor函数，设置参数为CV_BGR2HSV时,所需要的H、S、V值范围分别是[0,180)，[0,255)，[0,255)，而非[0,360]，[0,1]，[0,1]；这时可以查看下面的表格来确定颜色的大致区间。\n示例将绿色识别出来：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import cv2 import numpy as np from matplotlib import pyplot as plt if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./006.png\u0026#34; image_np = cv2.imread(path) # 转为HSV空间 hsv_image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2HSV) # 创建绿色掩膜 color_low = np.array([[35, 43, 46], [77, 255, 255]][0]) color_high = np.array([[35, 43, 46], [77, 255, 255]][1]) mask_image_np = cv2.inRange(hsv_image_np, color_low, color_high) # 获得颜色识别后的图像 color_image_np = cv2.bitwise_and(image_np, image_np, mask=mask_image_np) #转化为RGB图像 img = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB) color = cv2.cvtColor(color_image_np, cv2.COLOR_BGR2RGB) # 返回结果 titles = [\u0026#39;image\u0026#39;, \u0026#39;mask\u0026#39;, \u0026#39;color\u0026#39;] images = [img, mask_image_np, color] for i in range(3): plt.subplot(1, 3, i + 1), plt.imshow(images[i], \u0026#39;gray\u0026#39;) plt.title(titles[i]) plt.xticks([]) plt.yticks([]) plt.show() 实现将绿色识别出来：\n图片颜色替换 示例将绿色替换为红色（0，0，255）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import cv2 import numpy as np from matplotlib import pyplot as plt if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./006.png\u0026#34; image_np = cv2.imread(path) # 转为HSV空间 hsv_image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2HSV) color_low = np.array([[35, 43, 46], [77, 255, 255]][0]) color_high = np.array([[35, 43, 46], [77, 255, 255]][1]) # 创建掩膜 mask_image_np = cv2.inRange(hsv_image_np, color_low, color_high) # 开操作 kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)) open_image_np = cv2.morphologyEx(mask_image_np, cv2.MORPH_OPEN, kernel) # 替换为红色 image_np[open_image_np == 255] = (0, 0, 255) # 返回结果 img = plt.imread(path) res = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB) titles = [\u0026#39;img\u0026#39;, \u0026#39;mask\u0026#39;, \u0026#39;result\u0026#39;] images = [img, mask_image_np, res] for i in range(3): plt.subplot(1, 3, i + 1), plt.imshow(images[i], \u0026#39;gray\u0026#39;) plt.title(titles[i]) plt.xticks([]) plt.yticks([]) plt.show() 实现结果：\n这里的开运算和闭运算是处理噪点用的： open_image_np = cv2.morphologyEx(mask_image_np, cv2.MORPH_OPEN, kernel)\n开：先进行腐蚀运算，再进行膨胀运算，消去一个黑图中的很多小白点 闭：先进行膨胀运算，再进行腐蚀运算，消去一个白图中的很多小黑点\n颜色替换：image_np[open_image_np == 255] = (0, 0, 255) 并不在HSV空间替换，而是在RGB空间替换，因此这里替换为红色是（0，0，255）\nROI切割 ROI（region of interest）——感兴趣区域。\n这个区域是图像分析所关注的重点。圈定这个区域，以便进行进一步的处理。而且，使用ROI指定想读入的目标，可以减少处理时间，增加精度，给图像处理带来不小的便利。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import cv2 image_np = cv2.imread(\u0026#39;./006.png\u0026#39;) #获取图像高度和宽度属性 h,w = image_np.shape[0],image_np.shape[1] #指定切割区域 try: x_min,x_max = 200,350 y_min,y_max = 100,300 #对切割区域进行范围判断 if not (x_min\u0026gt;=0 and x_min\u0026lt;w and y_min\u0026gt;=0 and y_min\u0026lt;h): raise OverflowError(\u0026#39;x_min or x_max is out of range\u0026#39;) #使用cv2.rectangle画一个矩形框，调整切割范围 cv2.rectangle(image_np,(x_min,y_min),(x_max,y_max),(0,0,255),2) #使用np数组切片操作对图像进行判断 img_ROI = image_np[y_min:y_max,x_min:x_max] #显示结果 cv2.imshow(\u0026#39;img\u0026#39;,image_np) cv2.imshow(\u0026#39;ROI\u0026#39;,img_ROI) cv2.waitKey(0) except Exception as e: print(e) 实现结果：\n图像仿射变换 图像的几何变换改变了像素的空间位置，建立一种原图像像素与变换后图像像素之间的映射关系，通过这种映射关系能够实现下面两种计算：\n原图像任意像素计算该像素在变换后图像的坐标位置 变换后图像的任意像素在原图像的坐标位置 图像旋转 在OpenCV中使用getRotationMatrix2D (内置API)与wrapAffine (矩阵运算)两种方式完成图像的旋转.\nopencv中getRotationMatrix2D函数可以直接帮我们生成M 而不需要我们在程序里计算三角函数．\nM = getRotationMatrix2D(center, angle, scale)\n参数解析:\ncenter 旋转中心点 (cx, cy) 你可以随意指定\nangle 旋转的角度 单位是角度 逆时针方向为正方向 ， 角度为正值代表逆时针。\nscale 缩放倍数. 值等于1.0代表尺寸不变\n该函数返回的就是仿射变换矩阵M\n为了使用方便， 也可以封装一下旋转过程：\n1 2 3 4 5 6 7 8 9 10 11 def rotate(image, angle, center = None, scale = 1.0): (h, w) = image.shape[:2] if center is None: center = (w / 2, h / 2) M = cv2.getRotationMatrix2D(center, angle, scale) rotated = cv2.warpAffine(image, M, (w, h)) return rotated 利用wrapAffine实现缩放,完成原点旋转或是图像中心旋转\ncv2.warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])\n其中：\nsrc - 输入图像。\nM - 变换矩阵。\ndsize - 输出图像的大小。\nflags - 插值方法的组合（int 类型！）\nborderMode - 边界像素模式（int 类型！）\nborderValue - （重点！）边界填充值; 默认情况下，它为0。\n上述参数中：M作为仿射变换矩阵，由cv2.getRotationMatrix2D函数直接得到。\ndsize为输出图像的大小，一般用shape函数取原图属性。\nflages表示插值方式，默认为 flags=cv2.INTER_LINEAR，表示线性插值，此外还有：\ncv2.INTER_NEAREST（最近邻插值）\ncv2.INTER_AREA （区域插值）\ncv2.INTER_CUBIC（三次样条插值）\ncv2.INTER_LANCZOS4（Lanczos插值）\n在只设置前三个参数的情况下，如 cv2.warpAffine(img,M,(rows,cols))可以实现基本的仿射变换效果，但会出现黑边\n示例：将图片旋转90°\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import cv2 from matplotlib import pyplot as plt if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./006.png\u0026#34; image_np = cv2.imread(path) img_shape = image_np.shape # 对图片进行旋转 M = cv2.getRotationMatrix2D( (img_shape[1] // 2, img_shape[0] // 2), 90, 1) rotation_image = cv2.warpAffine( image_np, M, (img_shape[1], img_shape[0]), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101) img = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB) res = cv2.cvtColor(rotation_image, cv2.COLOR_BGR2RGB) titles = [\u0026#39;img\u0026#39;, \u0026#39;rotation\u0026#39;] images = [img, res] for i in range(2): plt.subplot(1, 2, i + 1), plt.imshow(images[i], \u0026#39;gray\u0026#39;) plt.title(titles[i]) plt.xticks([]) plt.yticks([]) plt.show() 示例结果：\n图像翻转 使图像进行翻转的函数是flip()\ncv2.flip(filename, flipcode)\nfilename：需要操作的图像 flipcode：翻转方式 flipcode 1 水平翻转 0 垂直翻转 -1 水平垂直翻转 翻转示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import cv2 from matplotlib import pyplot as plt if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./006.png\u0026#34; image_np = cv2.imread(path) # 对图片进行镜像操作 mirroring_image = cv2.flip(image_np, 0) img = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB) res = cv2.cvtColor(mirroring_image, cv2.COLOR_BGR2RGB) titles = [\u0026#39;img\u0026#39;, \u0026#39;mirroring\u0026#39;] images = [img, res] for i in range(2): plt.subplot(1, 2, i + 1), plt.imshow(images[i], \u0026#39;gray\u0026#39;) plt.title(titles[i]) plt.xticks([]) plt.yticks([]) plt.show() 结果：\n图像缩放 1 2 3 4 5 6 7 8 9 10 11 12 13 import cv2 if __name__ == \u0026#34;__main__\u0026#34;: path = \u0026#34;./006.png\u0026#34; image_np = cv2.imread(path) resize_image = cv2.resize( image_np, None, fx=0.8, fy=0.8, interpolation=cv2.INTER_LINEAR) # 对图片进行缩放 cv2.imshow(\u0026#34;image\u0026#34;, image_np) cv2.imshow(\u0026#34;resize_image\u0026#34;, resize_image) cv2.waitKey(0) 结果：\n图像纠正 具体参考链接： https://blog.csdn.net/wsp_1138886114/article/details/83374333\n","date":"2024-10-28T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/OpenCVCourse/write-plan.jpg","permalink":"https://UPPO8.github.io/Myblog/p/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E4%B8%8Eopencv-2/","title":"机器视觉与OpenCV-2"},{"content":"RGB图像 像素是图像的基本单元，每个像素存储着图像的颜色、亮度和其他特征，一张图片是由和多个像素组成。\n在计算机中，RGB三种颜色被称为RGB三通道，且每个通道的取值范围是0-255，根据这三个通道存储的像素值来对应不同的颜色。[0,0,0]为黑色，[255，255，255]为白色。\n在计算机中，图像是以数组的形式存在的。一个RGB图像放到内存中就是一个三维数组，第一维为图像的宽度，第二维为图像的高度，第三维则是图像中每个像素点的RGB三个像素值。注意在openCV中像素的存储顺序是BGR。\n比如将一个RGB图像使用openCV维度展开。 Python中实现代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 import cv2 import numpy as np import matplotlib.pyplot as plt # 创建一个空白的 700x700 彩色图像 image = np.zeros((700, 700, 3), dtype=np.uint8) # 绘制黑色边框，每个 100x100 像素的块周围 block_size = 100 #画出分割线 for i in range(0, 700, block_size): for j in range(0, 700, block_size): top_left = (j, i) bottom_right = (j + block_size - 1, i + block_size - 1) # 绘制 X 型图案，将两个对角线方向的块填充为红色 if ((i // block_size == j // block_size) or (i // block_size + j // block_size == 6)) and (i != 0) and (i != 600): cv2.rectangle(image, top_left, bottom_right, (0, 0, 255), -1) # 使用 -1 填充矩形为红色 else: cv2.rectangle(image, top_left, bottom_right, (255, 255, 255), 2) # 绘制其他块的白色边框 # 将 BGR 通道顺序转换为 RGB 顺序，用于 Matplotlib 显示 image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 显示原图 plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # 不显示坐标轴 plt.show() # 拆分彩色通道 b, g, r = cv2.split(image) # 创建三个空白图像，用于每个表示每个通道 blue_channel = np.zeros((700, 700, 3), dtype=np.uint8) green_channel = np.zeros((700, 700, 3), dtype=np.uint8) red_channel = np.zeros((700, 700, 3), dtype=np.uint8) # 分配颜色通道数据 blue_channel[:, :, 0] = b green_channel[:, :, 1] = g red_channel[:, :, 2] = r # 将 BGR 通道顺序转换为 RGB 顺序，用于 Matplotlib 显示 blue_channel_rgb = cv2.cvtColor(blue_channel, cv2.COLOR_BGR2RGB) green_channel_rgb = cv2.cvtColor(green_channel, cv2.COLOR_BGR2RGB) red_channel_rgb = cv2.cvtColor(red_channel, cv2.COLOR_BGR2RGB) #显示拆分的颜色通道 # 创建一行三列的布局，本图在第一个位置 plt.subplot(131) plt.imshow(blue_channel_rgb) #显示标题 plt.title(\u0026#39;Blue Channel\u0026#39;) #不显示坐标轴 plt.axis(\u0026#39;off\u0026#39;) plt.subplot(132) plt.imshow(green_channel_rgb) plt.title(\u0026#39;Green Channel\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(133) plt.imshow(red_channel_rgb) plt.title(\u0026#39;Red Channel\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) #合理布局所有图像 plt.tight_layout() plt.show() 图像灰度化 灰度图：单通道图，每个像素点只存一个像素值，图像整体表现为灰色，从0-255表现为从黑到白的过程。 灰度化的三种方法：\n加权均值法：对于彩色图像的每个像素，它会按照一定的权重去乘以每个通道的像素值，并将其相加，得到最后的值就是灰度图像中对应位置的像素值,比如一个像素值为[91，121，46]，则权重的比例为： R乘以0.299，G乘以0.587，B乘以0.114。\n91*0.99+121*0.587+46*0.114 平均值法：对于彩色图像的每个像素，它会将R、G、B三个通道的像素值全部加起来，然后再除以三，得到的平均值就是灰度图像中对应位置的像素值。\n最大值法：对于彩色图像的每个像素，它会从R、G、B三个通道的值中选出最大的一个，并将其作为灰度图像中对应位置的像素值。\n在Pyhton中使用openCV的cv2.imread()函数读取图片，使用shape函数读取属性，shape[0]为高度，shape[1]为宽度，shape[3]为维度。 代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 import cv2 import numpy as np from matplotlib import pyplot as plt def weight_average(): #设定权重 wr = 0.299 wg = 0.587 wb = 0.114 # 加权灰度化 #遍历彩色图像中的每一个像素点，进行加权平均操作。 for i in range(img_shape[0]): for j in range(img_shape[1]): image_np_gray[i, j] = (int(wr * image_np[i, j][2]) + int(wg * image_np[i, j][1]) + int( wb * image_np[i, j][0])) return image_np_gray def maximum(): # 最大值灰度化 for i in range(img_shape[0]): # 按行读取图片的像素bgr for j in range(img_shape[1]): # 对每一行按照列进行每一个像素格子进行读取 image_np_gray[i, j] = max(image_np[i, j][0], image_np[i, j][1], image_np[i, j][2]) # 求灰度值 return image_np_gray def average(): # 平均灰度化 for i in range(img_shape[0]): for j in range(img_shape[1]): image_np_gray[i, j] = (int(image_np[i, j][0]) + int(image_np[i, j][1]) + int(image_np[i, j][2])) // 3 return image_np_gray if __name__ == \u0026#34;__main__\u0026#34;: #设定读取图片的路径 path = \u0026#34;./hui.png\u0026#34; #读取该图片 image_np = cv2.imread(path) #读取图片Numpy数组的属性，【高度，宽度，像素值】 img_shape = image_np.shape image_np_gray = np.zeros((img_shape[0], img_shape[1]), dtype=np.uint8) #使用openCV读取的图像为BGR，用plt显示图像需要转化为RGB图像显示 res_img1 = cv2.cvtColor(weight_average(), cv2.COLOR_BGR2RGB) res_img2 = cv2.cvtColor(maximum(), cv2.COLOR_BGR2RGB) res_img3 = cv2.cvtColor(average(), cv2.COLOR_BGR2RGB) plt.subplot(131) plt.imshow(res_img1) plt.title(\u0026#39;weight_average\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(132) plt.imshow(res_img2) plt.title(\u0026#39;maximum\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(133) plt.imshow(res_img3) plt.title(\u0026#39;average\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() 二值化 二值化图：就是将图像中的像素改成只有两种值，其操作的图像必须是灰度图。 二值化的方法：参考链接\n阈值法(THRESH_BINARY)：通过设置一个阈值，将灰度图中的每一个像素值与该阈值进行比较，小于等于阈值的像素就被设置为0（黑），大于阈值的像素就被设置为maxval。\n反阈值法(THRESH_BINARY_INV)：与阈值法相反。反阈值法是当灰度图的像素值大于阈值时，该像素值将会变成0（黑），当灰度图的像素值小于等于阈值时，该像素值将会变成maxval。\n截断阈值法(THRESH_TRUNC)：指将灰度图中的所有像素与阈值进行比较，像素值大于阈值的部分将会被修改为阈值，小于等于阈值的部分不变。换句话说，经过截断阈值法处理过的二值化图中的最大像素值就是阈值。\n低阈值零处理(THRESH_TOZERO)：就是像素值小于等于阈值的部分被置为0（也就是黑色），大于阈值的部分不变。\n超阈值零处理(THRESH_TOZERO_INV):就是将灰度图中的每个像素与阈值进行比较，像素值大于阈值的部分置为0（也就是黑色），像素值小于等于阈值的部分不变。\nOTSU阈值法：OTSU算法是通过一个值将这张图分前景色和背景色（也就是灰度图中小于这个值的是一类，大于这个值的是一类），通过统计学方法（最大类间方差）来验证该值的合理性，当根据该值进行分割时，使用最大类间方差计算得到的值最大时，该值就是二值化算法中所需要的阈值。通常该值是从灰度图中的最小值加1开始进行迭代计算，直到灰度图中的最大像素值减1，然后把得到的最大类间方差值进行比较，来得到二值化的阈值。\n简单阈值法实现代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #!/usr/bin/env python3 # -*- coding: utf-8 -*- import cv2 import numpy as np from matplotlib import pyplot as plt img = cv2.imread(\u0026#39;006.png\u0026#39;, 0) #阈值法 ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY) #反阈值法 ret, th2 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV) #截断阈值法 ret, th3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC) #低阈值零处理 ret, th4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO) #超阈值零处理 ret, th5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV) titles = [\u0026#39;Original Image\u0026#39;, \u0026#39;BINARY\u0026#39;, \u0026#39;BINARY_INV\u0026#39;, \u0026#39;TRUNC\u0026#39;, \u0026#39;TOZERO\u0026#39;, \u0026#39;TOZERO_INV\u0026#39;] images = [img, th1, th2, th3, th4, th5] for i in range(6): plt.subplot(2, 3, i+1), plt.imshow(images[i], \u0026#39;gray\u0026#39;) plt.title(titles[i]) plt.xticks([]), plt.yticks([]) plt.show() 运行结果：\n使用OTSU方法；\n模式：cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import cv2 as cv import numpy as np from matplotlib import pyplot as plt img = cv.imread(\u0026#39;006.png\u0026#39;,0) # global thresholding ret1,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY) # Otsu\u0026#39;s thresholding ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU) # Otsu\u0026#39;s thresholding after Gaussian filtering blur = cv.GaussianBlur(img,(5,5),0) ret3,th3 = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU) # plot all the images and their histograms images = [img, 0, th1, img, 0, th2, blur, 0, th3] titles = [\u0026#39;Original Noisy Image\u0026#39;,\u0026#39;Histogram\u0026#39;,\u0026#39;Global Thresholding (v=127)\u0026#39;, \u0026#39;Original Noisy Image\u0026#39;,\u0026#39;Histogram\u0026#39;,\u0026#34;Otsu\u0026#39;s Thresholding\u0026#34;, \u0026#39;Gaussian filtered Image\u0026#39;,\u0026#39;Histogram\u0026#39;,\u0026#34;Otsu\u0026#39;s Thresholding\u0026#34;] for i in range(3): plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],\u0026#39;gray\u0026#39;) plt.title(titles[i*3]), plt.xticks([]), plt.yticks([]) plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256) plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([]) plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],\u0026#39;gray\u0026#39;) plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([]) plt.show() 运行结果：\n自适应阈值法 使用了一个全局值作为阈值，这可能并非在所有情况下都是好的，例如，如果图像在不同区域具有不同的照明条件。在这种情况下，自适应阈值可以提供帮助。在这里，算法根据像素周围的小区域确定像素的阈值。因此，我们为同一图像的不同区域获得不同的阈值，从而为具有不同照明的图像提供更好的结果。\n函数cv.adaptiveThreshold有三个参数，\ncv.ADAPTIVE_THRESH_MEAN_C：阈值是邻域面积减去常数 C 的平均值。 cv.ADAPTIVE_THRESH_GAUSSIAN_C：阈值是邻域值减去常数 C 的高斯加权和。 blockSize 确定邻域区域的大小 C 是从邻域像素的平均值或加权和中减去的常数。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #自适应阈值法 import cv2 as cv import numpy as np from matplotlib import pyplot as plt img = cv.imread(\u0026#39;006.png\u0026#39;,0) img = cv.medianBlur(img,5) #简单阈值法 ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY) #自适应平均阈值法 th2 = cv.adaptiveThreshold( img,255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 11,2)#blockSize为11，C为2 #自适应高斯阈值法 th3 = cv.adaptiveThreshold( img,255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11,2)#blockSize为11，C为2 titles = [\u0026#39;Original Image\u0026#39;, \u0026#39;Global Thresholding (v = 127)\u0026#39;, \u0026#39;Adaptive Mean Thresholding\u0026#39;, \u0026#39;Adaptive Gaussian Thresholding\u0026#39;] images = [img, th1, th2, th3] for i in range(4): plt.subplot(2,2,i+1),plt.imshow(images[i],\u0026#39;gray\u0026#39;) plt.title(titles[i]) plt.xticks([]),plt.yticks([]) plt.show() 运行结果：\n","date":"2024-10-27T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/OpenCVCourse/write-plan.jpg","permalink":"https://UPPO8.github.io/Myblog/p/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E4%B8%8Eopencv-1/","title":"机器视觉与OpenCV-1"},{"content":"递归介绍及原理 递归 递归(Recursion)，是一种解决问题的方法，其精髓在于将问题分解为规模更小的相同问题。持续分解，直到问题规模小到可以用非常简单直接的方式来解决。递归的问题分解方式非常独特，其算法方面的明显特征就是:在算法流程中调用自身。\n递归三定律:\n递归算法必须有一个基本结束条件(最小规模问题的直接解决) 递归算法必须能改变状态向基本结束条件演进(减小问题规模) 递归算法必须调用自身(解决减小了规模的相同问题) 递归应用 求斐波那契数列\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def fibo(n): if n \u0026lt;= 0: return [] elif n == 1: return [0] elif n == 2: return [0,1] else: fibo_list = fibo(n-1) fibo_list.append(fibo_list[-1]+fibo_list[-2]) return fibo_list print(fibo(10)) \u0026#39;\u0026#39;\u0026#39;打印结果\u0026#39;\u0026#39;\u0026#39; [0, 1, 1, 2, 3, 5, 8, 13, 21, 34] 线性查找与二分查找 查找：可以说是我们在代码中运用最多的操作，比如我们经常需要在一个列表里找到我们需要的一个元素，然后返回它的位置。其实之前的哈希表就是非常高效率的查找数据结构，很明显地它是用空间换时间。\n使用Python还有一些其他的查找方法:\n线性查找:它从数据集的开头开始逐个元素进行比较，直到找到目标元素或遍历完整个数据集。\n二分查找:二分查找适用于已排序的数据集。它通过反复将数据集一分为二，并比较中间元素来快速缩小搜索范围，直到找到目标元素或确定它不存在。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #线性查找 def linear_search(num_list,target_num): for i in range(len(num_list)): if num_list[i] == target_num: return i return -1 #二分查找 def binary_search(num_list,target_num): #sort()将改变原始列表，并从小到大排序；sorted()则不会改变原始列表 num_list.sort() low = 0 high = len(num_list)-1 while low \u0026lt;= high: mid = (low+high)//2 mid_num = num_list[mid] if mid_num == target_num: return mid elif mid_num \u0026lt; target_num: low = mid+1 elif mid_num \u0026gt; target_num: high = mid-1 else: return -1 num_list = [1,2,3,4,5,6,7,8,9,10] target_num = 9 #使用线性查找 res1 = linear_search(num_list,target_num) if res1 == -1: print(\u0026#39;没有找到目标值\u0026#39;) else: print(f\u0026#39;找到目标值{target_num}的索引:{res1}\u0026#39;) #使用二分查找 res2 = binary_search(num_list,target_num) if res2 == -1: print(\u0026#39;没有找到目标值\u0026#39;) else: print(f\u0026#39;找到目标值{target_num}的索引:{res2}\u0026#39;) 排序算法 冒泡排序 冒泡排序(Bubble Sort)，是一种简单直观的排序算法，它的工作原理是:重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。遍历数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为最大或最小的元素会经由交换慢慢“浮”到数列的顶端。\n算法步骤:\n比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较， 冒泡排序代码：\n1 2 3 4 5 6 def double_sort(arr): for i in range(1,len(arr)): for j in range(0,len(arr)-i): if arr[j]\u0026gt;arr[j+1]: arr[j],arr[j+1]=arr[j+1],arr[j] return arr 选择排序 选择排序(Selection Sort)，是一种简单的排序算法。他的工作原理:首先在未排序的序存放到排序序列的起始位置，然后，再从剩余未排序元素中列中找到最小(大)的元素，继续寻找最小(大)的元素，然后放回已排序序列的末尾。以此类推，直到所有元素均排序完毕。\n算法步骤：\n首先在未排序序列中找到最小(大)元素，存放到排序序列的起始位置 再从剩余未排序元素中继续寻找最小(大)元素，然后放到已排序序列的末尾 重复第二步，直到所有元素均排序完毕。 1 2 3 4 5 6 7 8 9 def selection_sort(arr): for i in range(len(arr)): min_id = i for j in range(i+1,len(arr)): if arr[min_id]\u0026gt;arr[j]: min_id = j #将找到的最小元素与第一个元素交换 arr[i],arr[min_id] = arr[min_id],arr[i] return arr 插入排序 插入排序(Insertion Sort)，是一种简单的排序算法他的工作原理:通过构建有序序列对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。因此需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。\n算法步骤:\n未排序序列中的第一个元素，视为该元素已排序 取出下一个待排序元素，在已排序序列中从后向前扫描，比较已排序序列元素和待排序元素，如果已排序的元素大于待插入元素，将该元素向后移动一位，为待插入元素腾出空间。 重复步骤2，直到所有元素均排序完毕 1 2 3 4 5 6 7 8 9 10 def insertion_sort(arr): for i in range(1,len(arr)): key = arr[i] j = i-1 # j不能为负数 while j \u0026gt;= 0 and key \u0026lt; arr[j]: arr[j+1] = arr[j] j -= 1 arr[j+1] = key return arr 希尔排序 希尔排序:是插入排序的一种，也称缩小增量排序。是插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。\n算法步骤:\n取一个小于待排序列表长度的正整数d1，把所有距离为d1的数据看成一组，在组内进行插入排序。 再取一个小于d1的正整数d2，继续用d2分组进行组内插入排序， 取的分组距离越来越小，组内的数据越来越多，直到d(n)=1，所有数据被分成一组再进行插入排序，则列表排序完成。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def shell_sort(arr): # 取整计算增量（间隔）值 gap = len(arr) // 2 while gap \u0026gt; 0: # 从增量值开始遍历比较 for i in range(gap, len(arr)): j = i current = arr[i] # 元素与他同列的前面的每个元素比较，如果比前面的小则互换 while j - gap \u0026gt;= 0 and current \u0026lt; arr[j - gap]: arr[j] = arr[j - gap] j -= gap arr[j] = current # 缩小增量（间隔）值 gap //= 2 return arr 快速排序 快速排序:也是一种常见且高效的采用分治策略的排序算法，它通过选取一个“基准”元素通过一次排序将待排序的数据分割成独立的两部分，小于基准的放左边，大于基准的放右边。然后递归地对左右两部分进行排序。\n算法步骤：\n从未排序的序列中挑出一个元素，称为“基准”(通常选取第一个数据) 重新排序数列，所有元素比基准值小的摆放在基准左边，所有元素比基准值大的摆在基准的右边(相同的数可以到任一边)。在这个分区结束之后，该基准就处于序列的中间位置。这个称为分区(partition)操作。 递归地把小于基准值元素的子序列和大于基准值元素的子序列排序， 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def quick_sort(arr): if len(arr) \u0026lt; 2: return arr # 选取基准，随便选哪个都可以，选中间的便于理解 mid = arr[len(arr) // 2] # 定义基准值左右两个数列 left, right = [], [] # 从原始数组中移除基准值 arr.remove(mid) for item in arr: # 大于基准值放右边 if item \u0026gt;= mid: right.append(item) else: # 小于基准值放左边 left.append(item) # 使用迭代进行比较 return quick_sort(left) + [mid] + quick_sort(right) 归并排序 归并排序是一种分治思想的应用，将一个大问题分解成两个小问题，分别解决这两个小问题，然后将解决的小问题合并起来，得到大问题的解。\n算法步骤：\n将数组分解成两个较小的子数组，直到子数组的大小为1 递归地对子数组进行排序，并将已排序的子数组合并成一个大的有序数组。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def merge_sort(arr): \u0026#34;\u0026#34;\u0026#34;归并排序\u0026#34;\u0026#34;\u0026#34; if len(arr) == 1: return arr # 使用二分法将数列分两个 mid = len(arr) // 2 left = arr[:mid] right = arr[mid:] # 使用递归运算 return marge(merge_sort(left), merge_sort(right)) def marge(left, right): \u0026#34;\u0026#34;\u0026#34;排序合并两个数列\u0026#34;\u0026#34;\u0026#34; result = [] # 两个数列都有值 while len(left) \u0026gt; 0 and len(right) \u0026gt; 0: # 左右两个数列第一个最小放前面 if left[0] \u0026lt;= right[0]: result.append(left.pop(0)) else: result.append(right.pop(0)) # 只有一个数列中还有值，直接添加 result += left result += right return result merge_sort([11, 99, 33 , 69, 77, 88, 55, 11, 33, 36,39, 66, 44, 22]) python有一个模块，专门提供了归并排序的方法，叫做“heapq”模块，因此我们只要将分解后的结果导入该方法即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 from heapq import merge def merge_sort(lst): if len(lst) \u0026lt;= 1: return lst # 从递归中返回长度为1的序列 middle = len(lst) // 2 left = merge_sort(lst[:middle]) # 通过不断递归，将原始序列拆分成n个小序列 right = merge_sort(lst[middle:]) return list(merge(left, right)) res = merge_sort([11, 99, 33 , 69, 77, 88, 55, 11, 33, 36,39, 66, 44, 22]) print(res) # 返回结果[11, 11, 22, 33, 33, 36, 39, 44, 55, 66, 69, 77, 88, 99] ","date":"2024-10-22T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","title":"Python-排序算法"},{"content":"引入 需要统计动物园中熊猫的姓名（name）、年龄（age）、性别（sex），在不考虑同名的情况下，要求：使用Python的数据类型进行统计。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #列表+元组 [ (\u0026#34;huahua\u0026#34;,5, \u0026#34;female\u0026#34;), (\u0026#34;menglan\u0026#34;, 10, \u0026#34;male\u0026#34;), (\u0026#34;heye\u0026#34;,5, \u0026#34;female\u0026#34;) ] #列表+ 字典 { {\u0026#34;name\u0026#34;: \u0026#34;huahua\u0026#34;, \u0026#34;ages\u0026#34;: 5, \u0026#34;sex\u0026#34;: \u0026#34;female\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;menglan\u0026#34;,\u0026#34;ages\u0026#34;: 10,\u0026#34;sex\u0026#34;: \u0026#34;male\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;heye\u0026#34;.\u0026#34;ages\u0026#34;:5,\u0026#34;sex\u0026#34;: \u0026#34;female\u0026#34;} } #字典+字典 { \u0026#34;huahua\u0026#34;:{\u0026#34;age\u0026#34;:5,\u0026#34;sex\u0026#34;: \u0026#34;female\u0026#34;}, \u0026#34;menglan\u0026#34;:{\u0026#34;age\u0026#34;: 10,\u0026#34;sex\u0026#34;: \u0026#34;male\u0026#34;}, \u0026#34;heye\u0026#34;:{\u0026#34;age\u0026#34;:5,\u0026#34;sex\u0026#34;: \u0026#34;female\u0026#34;} } 数据结构 在计算机科学中，数据结构是存储和组织数据的特定方式，以便有效地访问和修改数据。\n数据结构决定了如何收集数据、我们可以实现的功能以及数据之间的关系。 数据结构几乎用于计算机科学和编程的所有领域，从操作系统到前端开发，再到机器学习。\n数据结构有助于:\n管理和利用大型数据集 从数据库中快速搜索特定数据 在数据点之间建立清晰的分层或关系连接 简化并加快数据处理 各种各样的数据结构如字典(Dictionary),列表(List),元组(Tuple)，集合(Set)，数组(Array)，链表(Linked List)，栈(Stack)，队列(Queue)，哈希表(Hash Table)，树(Tree)，图(Graph)等都被设计出来以便于特定的操作。\n链表 链表是一种线性的数据结构，由一系列节点组成，这些节点按照特定的顺序排列，通过指针相互连接在一起。每个节点包含两部分：元素和指向下一个节点的指针。\n基本元素:\n节点:每个节点有两个部分，左边称为值域（data），存放用户数据；右边部分称为指针域（next），用来存放指向下一个元素的指针。 Head:head节点永远指向第一个节点 Tail:tail节点永远指向最后一个节点。 None:链表中最后一个节点的指针域为None. 单链表结构： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 class Node: \u0026#39;\u0026#39;\u0026#39;创建单列表节点\u0026#39;\u0026#39;\u0026#39; def __init__(self, data): self.data = data self.next = None class LinkedList: \u0026#39;\u0026#39;\u0026#39;创建链接\u0026#39;\u0026#39;\u0026#39; def __init__(self): #定义head为私有属性 self.__head = None def is_empty(self): #判断链表是否为空 return self.__head == None def length(self): #获取链表长度 #创建一个游标指向头节点 current = self.__head count = 0 while current != None: count += 1 current = current.next return count def travel(self): #遍历链表 current = self.__head while current != None: print(current.data,end=\u0026#34; \u0026#34;) current = current.next print(\u0026#39;\u0026#39;) def add(self,data): #头插法，头部添加元素 new_node = Node(data) new_node.next = self.__head self.__head = new_node def append(self,data): #尾插法，尾部添加元素 new_node = Node(data) #判断链表是否为空，为空直接添加 if self.is_empty(): self.__head = new_node else: current = self.__head while current.next != None: current = current.next current.next = new_node def insert(self,pos,data): #指定位置添加元素,pos元素下角标 if pos \u0026gt; (self.length()-1): #当pos超出列表长度时，尾插法 self.append(data) elif pos \u0026lt;= 0: #当pos为0或负数时，头插法 self.add(data) else: new_node = Node(data) pre = self.__head count = 0 while count \u0026lt; (pos-1): count += 1 pre = pre.next new_node.next = pre.next pre.next = new_node def remove(self,data): #删除元素 current = self.__head pre = None while current != None: if current.data == data: #判断当前节点元素是否为该元素 if current == self.__head: #判断要删除的元素是否在头节点 self.__head = current.next else: pre.next = current.next break else: #否则继续判断下一个节点 pre = current current = current.next def search(self,data): current = self.__head while current != None: if current.data == data: return True else: current = current.next return False if __name__ == \u0026#39;__main__\u0026#39;: linklist= LinkedList() #加入几个元素 linklist.add(1) linklist.add(2) linklist.add(3) linklist.append(5) linklist.append(6) linklist.append(7) #遍历链表 linklist.travel() print(linklist.is_empty()) print(linklist.length()) print(linklist.search(2)) print(linklist.search(8)) 链表的用途 动态数据集合:链表允许动态的添加和删除元素，这使得它们在处理未知数量或频繁变化的数据集时非常有用。 元素顺序:链表可以按照插入顺序来保持元素的顺序，这对于需要维护元素插入顺序的应用程序非常有用。 内存效率:与数组相比，链表在内存使用上更为高效，因为它们不需要连续的内存空链表通过节点之间的指针来连接元素，这样可以更有效地利用内存空间。 避免数组扩容:数组在初始化时需要指定大小，如果超出大小，则需要扩容，这是一个昂贵的操作。链表则可以避免这个问题，因为它们可以动态地增长。 单向链表的缺点: 只能从头遍历到尾或者从尾遍历到头(一般从头到尾)。 也就是链表相连的过程是单向的。实现的原理是上一个链表中有一个指向下一个的引用我们可以轻松的到达下一个节点,但是回到前一个节点是很难的。但是,在实际开发中,经常会遇到需要回到上一个节点的情况。\n举个例子:假设一个文本编辑用链表来存储文本。每一行用一个String对象存储在链表的一个节点中。当编辑器用户向下移动光标时,链表直接操作到下一个节点即可。但是当用于将光标向上移动呢?这个时候为了回到上一个节点,我们可能需要从头开始,依次走到想要的节点上。\n双向链表 既可以从头遍历到尾，又可以从尾遍历到头，也就是列表相连的过程是双向的。 一个节点具有向前连接的引用，也有一个向后连接的引用 双向列表可以有效的解决单向链表中提到的问题。 双向链表的尾插法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 class Node(object): \u0026#34;\u0026#34;\u0026#34;双向链表节点\u0026#34;\u0026#34;\u0026#34; def __init__(self, item): self.item = item self.next = None self.prev = None # 双向链表代码实现 class DoubleLinkList(object): \u0026#34;\u0026#34;\u0026#34;双向链表\u0026#34;\u0026#34;\u0026#34; def __init__(self): self._head = None def is_empty(self): \u0026#34;\u0026#34;\u0026#34;判断链表是否为空\u0026#34;\u0026#34;\u0026#34; return self._head is None @property def length(self): \u0026#34;\u0026#34;\u0026#34;返回链表的长度\u0026#34;\u0026#34;\u0026#34; cur = self._head count = 0 while cur is not None: count += 1 cur = cur.next return count def travel(self): \u0026#34;\u0026#34;\u0026#34;遍历链表\u0026#34;\u0026#34;\u0026#34; cur = self._head while cur is not None: print(cur.item) cur = cur.next print(\u0026#34;\u0026#34;) def add(self, item): \u0026#34;\u0026#34;\u0026#34;头部插入元素\u0026#34;\u0026#34;\u0026#34; node = Node(item) if self.is_empty(): # 如果是空链表，将_head指向node self._head = node else: # 将node的next指向_head的头节点 node.next = self._head # 将_head的头节点的prev指向node self._head.prev = node # 将_head 指向node self._head = node def append(self, item): \u0026#34;\u0026#34;\u0026#34;尾部插入元素\u0026#34;\u0026#34;\u0026#34; node = Node(item) if self.is_empty(): # 如果是空链表，将_head指向node self._head = node else: # 移动到链表尾部 cur = self._head while cur.next is not None: cur = cur.next # 将尾节点cur的next指向node cur.next = node # 将node的prev指向cur node.prev = cur def is_contain(self, item): \u0026#34;\u0026#34;\u0026#34;查找元素是否存在\u0026#34;\u0026#34;\u0026#34; cur = self._head while cur is not None: if cur.item == item: return True cur = cur.next return False def insert(self, pos, item): \u0026#34;\u0026#34;\u0026#34;在指定位置添加节点\u0026#34;\u0026#34;\u0026#34; if pos \u0026lt;= 0: self.add(item) elif pos \u0026gt; (self.length - 1): self.append(item) else: node = Node(item) cur = self._head count = 0 # 移动到指定位置的前一个位置 while count \u0026lt; (pos - 1): count += 1 cur = cur.next # 将node的prev指向cur node.prev = cur # 将node的next指向cur的下一个节点 node.next = cur.next # 将cur的下一个节点的prev指向node cur.next.prev = node # 将cur的next指向node cur.next = node def remove(self, item): \u0026#34;\u0026#34;\u0026#34;删除元素\u0026#34;\u0026#34;\u0026#34; if self.is_empty(): return else: cur = self._head if cur.item == item: # 如果首节点的元素即是要删除的元素 if cur.next is None: # 如果链表只有这一个节点 self._head = None else: # 将第二个节点的prev设置为None cur.next.prev = None # 将_head指向第二个节点 self._head = cur.next return while cur is not None: if cur.item == item: # 将cur的前一个节点的next指向cur的后一个节点 cur.prev.next = cur.next # 将cur的后一个节点的prev指向cur的前一个节点 cur.next.prev = cur.prev break cur = cur.next # 测试数据 if __name__ == \u0026#34;__main__\u0026#34;: print(\u0026#34;------创建链表------\u0026#34;) list = DoubleLinkList() list.add(1) list.add(2) list.append(3) list.insert(2, 4) list.insert(4, 5) list.insert(0, 6) print(\u0026#34;length:\u0026#34;, list.length) list.travel() print(list.is_contain(3)) print(list.is_contain(8)) list.remove(1) print(\u0026#34;length:\u0026#34;, list.length) list.travel() 栈（stack） 栈（stack）：它是一种运算受限的线性表，是一种容器，可存入数据、访问元素、删除元素。它的特点在于只能允许在容器的一端，输入数据和输出数据的运算，没有位置概念，保证任何时候都可以访问、删除元素。栈仅允许在栈顶一端进行操作，因此，栈是按照先进后出的原理进行运作。\n栈的操作 解释 push(data) 将数据压入栈顶 pop() 将栈顶数据弹出 peek() 产看栈顶的元素 is_empty() 查看栈是否为空 size() 获取栈的大小 栈的应用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class Stack: def __init__(self): self.__list = [] def push(self, data): #将数据压入栈顶 self.__list.append(data) def pop(self): #将栈顶数据弹出 if self.is_empty(): return \u0026#34;这是一个空栈\u0026#34; else: return self.__list.pop() def peek(self): #看栈顶的元素 if self.__list: return self.__list[-1] else: return None def is_empty(self): #查看栈是否为空 return self.__list == [] def size(self): #获取栈的大小 return len(self.__list) if __name__ == \u0026#39;__main__\u0026#39;: mystack = Stack() mystack.push(10) mystack.push(20) mystack.push(30) mystack.push(40) mystack.push(50) print(mystack.is_empty()) print(mystack.size()) print(mystack.pop()) print(mystack.peek()) 队列（Queue） 队列也是一种数据结构，在队列中的插入和删除都遵循先进先出的原则。元素可以在任何时刻从队尾插入，但是只有在队列最前面的元素才能被取出或则删除。通常将队列中允许插入的一端称为队尾，将允许删除的一端称为队头，不允许在中间部位进行操作。\n队列的结构： 队列的操作 Queue() 创建一个空队列 is_empty() 队列是否为空 enqueue(data) 从队列尾添加一个元素 dequeue(data) 从队列头移除并返回第一个元素 size() 返回队列的大小 队列的操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Queue(): def __init__(self): self.__list = [] def is_empty(self): #队列是否为空 return self.__list == [] def enqueue(self,data): # 从队列尾添加一个元素 self.__list.append(data) def dequeue(self): #从队列头移除并返回第一个元素 return self.__list.pop(0) def size(self): #返回队列的大小 return len(self.__list) if __name__ == \u0026#39;__main__\u0026#39;: queue = Queue() queue.enqueue(50) queue.enqueue(100) queue.enqueue(200) queue.enqueue(300) print(queue.size()) queue.dequeue() print(queue.size()) 队列的第三方库导入：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import queue q = queue.Queue() q.put(10) q.put(20) q.put(30) q.put(40) #打印队列元素 print(q.qsize()) #打印队列长度 print(q.qsize()) #打印队列是否为空 print(q.empty()) #队列是否满了 print(q.full()) #取出一个队头的元素 data = q.get() print(data) 双端队列 双端队列支持队列的头部和尾部进去插入和删除操作，是一种具有队列和栈的性质的数据结果。\n双端队列结构： 双端队列的操作 \u0026ndash; Deque() 创建一个空的双端队列 add_frontldata() 从队头加入一个元素 add_rear(data) 从队尾加入一个元素 remove_front() 从队头删除一个元素 remove_rear() 从队尾删除一个元素 is_empty() 判断队列是否为空 size() 返回队列的大小 双端队列的自定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 class Deque: def __init__(self): self.__list = [] def add_frontldata(self,data): #从队头加入一个元素 self.__list.insert(0,data) def add_rear(self,data): #|从队尾加入一个元素 self.__list.append(data) def remove_front(self): #|从队头删除一个元素 return self.__list.pop(0) def remove_rear(self): #|从队尾删除一个元素 return self.__list.pop() def is_empty(self): #|判断队列是否为空 return len(self.__list) == 0 def size(self): #|返回队列的大小 return len(self.__list) if __name__ == \u0026#39;__main__\u0026#39;: d = Deque() d.add_frontldata(7) d.add_frontldata(11) d.add_frontldata(19) d.add_frontldata(20) d.add_rear(1) print(d.remove_front()) print(d.size()) print(d.remove_rear()) print(d.size()) 哈希表（Hash） 哈希表(Hash)，也可以叫做散列表。哈希表是一种特殊的数据结构，它与数组、链表以及我们之前学到过的数据结构相比，有很明显的区别。它可以提供快速插入和查找的操作，不论哈希表中有多少数据，我们对其进行操作时，平均时间复杂度接近于O(1)，也就是常数时间。\n哈希表的原理:它利用哈希函数将给定的键(key)映射到数据的存储位置。通过哈希函数可以快速地插入、查找、删除数据。\n哈希函数:是用于计算对象的哈希值的一种内置机制，它对于支持哈希操作(如字典dict 的key)的对象非常重要。哈希函数的目标是将任意大小、复杂度各异的数据(如字符串、整数、自定义对象等)转换为固定长度的整数，这个整数称为哈希值(或散列值)。哈希值主要用于快速查找、比较和索引数据，特别是在实现哈希表这样的数据结构时。\n注意:可变的对象通常是不可哈希的，因为他们的值可以改变，这会导致哈希值不一致。\n哈希冲突:由于哈希表大小有限，而需要我们存储的数据总量再增大，总会发生上述案例的冲突，即不同key值通过哈希函数后会产生相同的地址，一般来说，哈希冲突是无法避免的，所以提出了几种解决办法：\n开放寻址法:如果发生了哈希冲突，则可以向后探查新的位置来存储这个值。 链地址法(拉链法):哈希表的每个位置都链接一个链表，当冲突发生的时候，冲突的元素将被加到该位置的链表最后 ","date":"2024-10-21T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","title":"Python-数据结构"},{"content":"多线程的基本概念 线程的概念 线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程内的实际执行单元。进程是资源分配的最小单位，而线程是调度的最小单位。与进程的创建不同，线程在创建时除了会申请线程本身所必须的资源之外，其他的资源比如内存空间、文件描述符等资源会使用进程中已经存在的资源，并且一个进程中的多个线程会共享本进程中的内存空间、文件描述符等大部分资源。需要注意的是，线程不具备进程级别的隔离性，一旦所属进程崩溃，虽然不会影响到其他进程，但该进程内的所有线程都将终止。\n多线程与多进程的区别 在Python中，多线程和多进程都是实现多并发执行的技术，但它们在多个方面存在显著的区别:\n调度 多线程(Threading):线程是操作系统能够进行运算调度的最小单位，被包含在进程之中，是进程中的实际运作单位。由于线程共享进程的内存空间，操作系统可以在同一进程空间中快速切换不同线程，实现并发执行。 多进程(Multiprocessing):进程是操作系统分配资源的独立单位。每个进程都有自己的内存空间，因此进程间的通信比线程要复杂，但在pvtbon中，多进程可以利用多核处理器的多个核心，实现真正的并行计算。 GIL(全局解释器锁) 多线程:CPython解释器(Python的主要实现)有一个全局解释器锁(GIL)，它确保同一时刻只有一个线程执行Python字节码。因此，即使在多核CPU上，使用多线程的Python程序也无法实现真正的并行计算，GIL限制了线程在执行CPU密集型任务时的效率。 多进程:每个Python进程都有自己的Python解释器和内存空间，因此GIL不会限制多进程。多进程可以绕过GIL，充分利用多核处理器进行并行计算。 GIL锁的优点:\n简化内存管理:由于GIL确保同一时刻只有一个线程在执行，因此CPython的内存管理可以设计得更加简单。 它不需要考虑多个线程同时修改对象的情况，从而避免了复杂的多线程内存回收问题。 易于实现:GIL简化了CPython解释器的实现，因为它不需要考虑多线程并发执行时的数据竞争和同步问题。3.单线程性能:在没有多线程竞争的情况下，单个线程的性能可以保持得很好，因为G儿L避免了不必要的上下文切换。 Python中的多线程 在Pvthon中，多线程是通过threading模块实现的，该模块允许程序员创建、启动、同步多个线程，并提供了一系列的API来支持线程间同步和通信。 在Python中，使用threading模块中的Thread类来创建线程，Thread类创建对象时的参数为:\nthreading.Thread(group=None, target=None, name=None, args=(), kwargs=None, *,daemon=None) 以下是各个参数的说明:\ngroup: 应该始终为 None，保留供未来扩展使用。·target: 是一个可调用的对象(函数)，该线程启动时，这个对象将被调用。如果不提供，则不会运行任何东西。 name: 线程名称。默认情况下，将分配一个唯一的名称。 args: 传递给 target 函数的位置参数，默认是一个元组。 kwargs: 传递给 target 函数的关键字参数，默认是一个字典, daemon:指定线程是否为守护线程。如果设置为True，则该线程会在主线程结束时自动退出。如果是None，则继承自创建它的线程。 以下是一些 Thread 类提供的主要方法和属性:\nstart():启动线程活动。使用start去启动线程，会调用run()方法，它会创建一个新的线程来执行run()方法中的代码。 run():表示线程活动的方法。可以在子类中重写此方法，重写之后执行重写的代码。通常不需要直接调用rur方法，应该调用start方法去启动线程，如果直接调用run方法(没有通过start方法去启动线程)那么run方法中的代码将在当前线程中同步执行，而不是在新的线程中执行。 join(timeout=None):等待线程终止。timeout 参数是可选的，表示等待的最长时间(以秒为单位)。如果没有指定 timeout，则该方法将无限期等待。 is alive():返回线程是否还活着。 getName():返回线程名。 setName(name):设置线程名。 isDaemon():返回线程的守护状态。 setDaemon(daemonic): 设置线程的守护状态，必须在start开始前设置 name: 线程名称 ident: 线程标识符 daemon：线程的守护状态 不传参的列子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import time from functools import total_ordering from threading import Thread def func1(): print(\u0026#39;func1 is running\u0026#39;) time.sleep(2) print(\u0026#39;func1 is done\u0026#39;) def func2(): print(\u0026#39;func2 is running\u0026#39;) time.sleep(2) print(\u0026#39;func2 is done\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: start = time.time() #创建一个线程运行func2 process = Thread(target=func1) process.start() #主程序运行func1 func1() #等待线程结束 process.join() total = time.time() - start print(f\u0026#34;程序运行了{total}秒\u0026#34;) Timer Timer，也被称为定时器，它允许你在一定时间后执行一个函数或者可调用的对象。Timer 类是 Thread 类的一个子类，因此它具有线程的所有特性，并且可以用来在后台执行定时务。 以下是 Timer 类的基本用法和特性:\n1 class threading.Timer(interval, function, args=None, kwargs=None) 参数说明 interva:一个浮点数或整数，表示在执行 function之前需要等待的时间(以秒为单位)。function:一个可调用的对象，当定时器到期时将被执行。 args:传递给 function的位置参数元组, kwargs: 传递给 function 的关键字参数字典。 实例方法 start():启动定时器。 Timer将在指定的时间间隔后开始执行目标函数。 cancel():取消定时器。定时器未启动时，此方法无效。 定时器简单应用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import time import threading def get_time(): current_time = time.time() #将时间戳格式化 formatted_time = time.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;, time.localtime(current_time)) print(formatted_time) if __name__ == \u0026#39;__main__\u0026#39;: #出啊关键一个定时器，5秒后打印时间戳 timer = threading.Timer(5, get_time) timer.start() print(\u0026#34;等待打印时间戳中\u0026#34;) timer.join() 线程间通信 消息队列 在Python中，queue 模块提供了一个适用于多线程环境的队列实现，这里介绍三种消息队列，分别是Queue,LifoQueue和PriorityQueue.\nQueue 最常用的消息队列，遵循先进先出的原则，使用queue.queue 创建。\n1 queue.Queue(maxsize=0) maxsize:队列的最大尺寸。如果设置为小于或等于0的数，则队列的尺寸是无限的。以下是 queue.\nqueue类的方法:\nQueue.qsize():返回队列中当前有几条消息\nQueue.empty():如果队列为空，返回True，否则返回 Fa1se。\nQueue.fu11():如果队列已满(达到最大尺寸)，返回 True，否则返回 False。\nQueue.put(item,block=True, timeout=None):将item 放入队列。如果 block是True 目 timeout是 None(默认)，则在必要时阻塞至有空闲的插槽。如果 timeout 是正数，将最多阻塞 timeout 秒，如果在这段时间内没有可用的插槽，将引发 queue.Fu11 异常。\nQueue.put_nowait(item):相当于 Queue.put(item，block=Fa1se)。如果队列已满，立即引发queue.Fu11 异常。\nQueue.get(b1ock=True，timeout=None):从队列中移除并返回一个元素。如果 b1ock 是 True 且timeout 是 None(默认)，则在必要时阻塞至队列中有项目可用。如果 timeout 是正数，将最多阻塞timeout 秒，如果在这段时间内没有项目可用，将引发 queue.Empty 异常。\nQueue.get_nowait():相当于 Queue.get(b1ock=Fa1se)。如果队列为空，立即引发 queue.Empty 异常。\nQueue.task_done():指示之前入队的一个任务已经完成。由队列的消费者线程使用。每个Queue.get()调用之后，需要调用 queue.task_done()告诉队列该任务处理完成。\nQueue.join():阻塞调用线程，直到队列中的所有项目都被处理完(即队列中每个项目都有一个对应的Queue.task_done()调用)\n应用举例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from threading import Thread from queue import Queueimport time def process1(thread_queue): print(\u0026#39;准备接收数据\u0026#39;) # 接收数据 received_data = thread_queue.get() print(\u0026#39;接收到的数据为:\u0026#39;，received_data) if __name__ ==\u0026#39;__main__\u0026#39;: thread queue = Queue(5) t1= Thread(target=process1,args=(thread_queue,)) t1.start() time.sleep(2) thread_queue.put(\u0026#39;hello\u0026#39;)#发送数据 t1.join()#等待线程结束 LifoQueue 用于实现后进先出(Last In, First Out)的队列。与标准的 queue.Queue(先进先出，FIFO)不同，Lifoqueue允许最后被放入队列的元素最先被取出，使用queue.Lifoqueue 创建。\n1 queue.LifoQueue(maxsize=0）) maxsize:队列的最大尺寸。如果设置为小于或等于0的数，则队列的尺寸是无限的,。\n常用方法:\nLifoQueue.put(item,block=True,timeout=None):将item 放入队列。如果 block 是True 目timeout 是 None(默认)，则在必要时阻塞至有空闲的插槽。如果 timeout 是正数，将最多阻塞timeout 秒，如果在这段时间内没有可用的插槽，将引发完全异常。 LifoQueue.put_nowait(item):相当于 LifoQueue.put(item,block=False)。如果队列已满，立即引发完全异常。 LifoQueue.get(b1ock=True，timeout=None):从队列中移除并返回一个元素。如果 block是 True 日timeout 是 None(默认)，则在必要时阻塞至队列中有项目可用。如果 timeout 是正数，将最多阻塞timeout 秒，如果在这段时间内没有项目可用，将引发完全异常， Lifoqueue.get_nowait():相当于 LifoQueue.get(block=False)。如果队列为空，立即引发完全异常 Lifoqueue.qsize():返回队列中的项目数量 Lifoqueue.empty():如果队列为空，返回True Lifoqueue.full():如果队列满了，返回True 消息存入与取出顺序：\n1 2 3 4 5 6 7 8 9 10 11 import queue # 创建一个 LifoQueue Lifo_queue = queue.LifoQueue(5) #向LifoQueue 中放入元素 Lifo_queue.put(\u0026#39;First\u0026#39;) Lifo_queue.put(\u0026#39;Second\u0026#39;) Lifo_queue.put(\u0026#39;Third\u0026#39;) #从LifoQueue 中取出元素 print(lifo_queue.get()) print(lifo_queue.get()) print(lifo_queue.get()) PriorityQueue PriorityQueue用于实现优先级队列，在 priorityqueue 中，元素被赋予一个优先级值，并且元素会按照优先级顺序被取出。在Python中，使用queue.priorityqueue来创建。\n1 queue.PriorityQueue(maxsize=0) maxsize:队列的最大尺寸。如果设置为小于或等于0的数，则队列的尺寸是无限的。\n常用方法:\nPriorityqueue.put((priority,item)，block=True,timeout=None):将item 放入队列，并为其指定一个优先级 priority。如果 b1ock 是 True 目 timeout 是 None(默认)，则在必要时阻塞至有空闲的插槽。如果 timeout 是正数，将最多阻塞 timeout 秒，如果在这段时间内没有可用的插槽，将引发完全异常。 Priorityqueue.put_nowait(item, priority):相当于 priorityoueue.put((item, priority), b1ock=Fa1se)。如果队列已满，立即引发完全异常 Priorityqueue.get(block=True，timeout=None):从队列中移除并返回一个元素。如果 b1ock 是 True月 timeout 是 None(默认)，则在必要时阻塞至队列中有项目可用。如果 timeout 是正数，将最多阻塞timeout 秒，如果在这段时间内没有项目可用，将引发完全异常。 Priorityoueue.get_nowait():相当于 PriorityQueue.get(block=False)。如果队列为空，立即引发完全异常。 Priorityqueue.qsize():返回队列中的项目数量， 消息存入与取出顺序：\n1 2 3 4 5 6 7 8 9 10 11 import queue #创建一个 PriorityQueue priority_queue = queue.PriorityQueue(5) #向 PriorityQueue 中放入元素 priority_queue.put((2,\u0026#39;Task1\u0026#39;)) priority_queue.put((0,\u0026#39;Task2\u0026#39;)) priority_queve.put((1,\u0026#39;Task3\u0026#39;)) #从PriorityQueue 中取出元素 print(priority_queue.get()) print(priority_queue.get()) print(priority_queue.get()) 线程同步 在Python中，线程同步指的是一系列用于控制多个线程访问共享资源的方法和规则，以避免数据不一致或竞争条件(Race condition)的问题。由于线程是操作系统调度的基本单元，它们可能会同时操作同一份数据，这可能会导致数据错误或难以预测的结果。以下是几种常见的线程同步机制:\n锁(Locks):锁是最基本的同步机制。在Python中，可以通过 threading 模块的 Lock 类来实现。锁可以确保同一时间只有一个线程能够访问共享资源。线程在访问资源前必须获取锁，访问结束后释放锁。 信号量(Semaphores):信号量是一个更高级的同步机制，它维护了一个计数器，线程可以增加或减少这个计数器。如果计数器为零，则线程会阻塞，直到其他线程增加计数器。 事件(Events):事件是一种线程之间的通信机制。\u0026ndash;个线程可以设置事件，而其他线程可以等待该事件的发生。这可以用来通知一个或多个线程某个条件已经满足。 条件变量(Condition Variables):条件变量通常与互斥锁一起使用，它允许线程在某个条件不满足时挂起(等待)，直到另一个线程通知条件已经满足。 屏障(Barriers):屏障是一种同步机制，允许多个线程在某个点上同步，直到所有线程都到达屏障点后，才能继续执行。 锁 Python中的线程锁也有两个，一个是普通的锁Lock，另一个是可重入锁RLock。使用与进程类似。\n屏障 在Python的 threading模块中，Barrier(屏障)是一种同步机制，用于让一组线程在某个点上同步。当所有线程都到达屏障点时，它们将继续执行;如果任何线程没有到达屏障点，则所有线程都会被阻塞，直到所有线程都到达。 创建Barrier对象 要使用 Barrier，首先需要导入threading模块，并创建一个Barrier对象:\n1 2 import threading barrier= threading.Barrier(parties,action=None, timeout=None) parties:屏障点上需要等待的线程数量 action(可选):当所有线程到达屏障点时，可以执行的一个函数。 timeout(可选):默认的超时时间，如果wait没有指定时间将使用这个时间。 Barrier的方法与属性:\nwait(timeout):阻塞线程，直到屏障被释放。如果所有线程都到达屏障点，屏障将被释放，所有线程继续执行;如果任何线程没有到达，所有线程将被阻塞。如果提供了timeout，这里的timeout会优先于创建Barrier对象时提供的timeout参数。改函数会返回一个整数，取值在0~(n-1)之间。 reset():重置Barrier为默认的初始状态。如果Barrier中仍有线程等待释放，将会引发异常。 abort():使Barrier处于破损状态，这将导致任何现有和未来对wait()方法的调用失败并引发异常。 parties:冲出Barrier所需要的线程数量。 n_waiting:当前时刻正在Barrier中阻塞的线程数量。 broken:一个布尔值，表示Barrier是否为破损态。 线程池 线程池的概念 线程池维护一个工作线程的集合，用于执行任务。当任务到达时，线程池可以选择一个空闲的线程来处理任务，而不是为每个任务都创建一个新的线程。\n为什么使用线程池 降低资源消耗:线程的创建和销毁开销较大，通过重用线程，可以降低这些开销。 提高响应速度:不需要等待线程的创建就能立即执行任务。 提高线程的可管理性:线程池可以统一管理线程的创建、销毁、数量等内容。 Python中的线程池实现 concurrent.futures,ThreadPoolExecutor: Python标准库中的 concurrent.futures 模块提供了一个高层次的异步执行接口，ThreadPoo1Executor是其提供的线程池实现。\n线程池的创建 1 2 concurrent,futures.ThreadPoolExecutor(max_workers=None, thread_name_prefix=\u0026#39;\u0026#39; initializer=None，initargs=()) 参数解释：\nmax_workers:线程池中线程的最大数量。如果设置为None 或未指定，为min(32,os.cpu_count()+4)，这个默认值会保留至少5个工作线程用于 I/O密集型任务。 对于那些释放了 GIL 的 CPU 密集型任务，它最多会使用 32 个 CPU 核心。这样能够避免在多核机器上不知不觉地使用大量资源。 thread_name_prefix:线程名称的前缀，有助于调试时识别线程。 initia1izer:一个可选的可调用对象，每个工作线程在启动时都会调用它。这可以用来执行线程的初始化操作，例如设置线程局部存储。 initargs:一个元组，其中包含传递给initializer的可调用对象的参数。 initia1izer和 initargs 参数通常用于为每个线程设置特定的环境或上下文。\n线程池的方法 submit(fn,args, kwargs):提交一个可调用的函数 fn和必要的参数args 和 kwargs 到线程池中执行。这个方法返回一个 Future 对象。 map(func, *iterables,timeout=None, chunksize=1):它允许你将一个函数 func 应用于多个可迭代对象iterab1es 中的元素，并且并行地在多个线程上执行这些函数调用。 timeout是可选参数，用于设置阻塞等待每个任务完成的最大秒数。如果 timeout 被触发，将引发 concurrent.futures.TimeoutErrorchunksize 是可选参数，用于指定每次切割几个参数给func，不过只对进程池有效果，对线程池无效。返回的结果是一个迭代器。 shutdown(wait=True): 关闭线程池，停止接收新任务。如果wait 参数为True，则等待所有已提交的任务完成。当使用with语句创建线程池时，with语句会在结束后自动调用shutdown。 ","date":"2024-10-17T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python-%E5%A4%9A%E7%BA%BF%E7%A8%8B/","title":"Python-多线程"},{"content":"串行执行、并发执行、并行执行 串行执行、并发执行和并行执行是计算机程序执行方式的三个不同阶段，它们的发展历史与计算机硬件和软件的进步紧密相关。\n串行执行 串行执行属于最早期的程序执行方式，是指任务按顺序一个接一个地执行在串行执行中，一个任务必须等待前一个任务完成后才能开始执行。这种执行方式简单、易于控制，但效率较低，特别是在处理大量任务时，因为CPU的云算能力没有得到充分利用。在早期计算机系统中非常普遍，因为当时的硬件资源有限，且CPU的能力远不如现在，无法同时执行多个任务，并且大部分计算机都只有一个CPU。因此程序设计通常采用串行执行，在这一时期计算机主要用于科学计算和军事目的，任务通常是简单的、顺序的，不需要复杂的并发或并行处理。\n串行执行具有以下几个特点:\n顺序性:任务必须按照一定的顺序执行，一个任务完成后才能开始下一个任务。 易于管理:由于任务按顺序执行，因此管理和调试相对简单。 资源利用率低:在执行单个任务时，CPU的运算能力没有得到充分利用，可能导致效率低下。 并发执行 随着计算机技术的发展和多用户需求的出现，单一串行执行方式逐渐显得力不从心。此时操作系统引入了进程的概念，且它允许多个程序在内存中同时存在，操作系统负责调度这些程序，通过时间片轮转等技术使得它们可以交替使用CPU，从而达到一种看似并发的效果。这一技术提高了CPU的利用率，因为当一个程序等待I/0操作时，CPU可以切换到另一个程序执行。这一时期，计算机开始被广泛应用于商业和科学领域，需要处理更多的数据和更复杂的任务。\n并发执行具有以下几个特点:\n效率提高:通过在不同的任务之间切换，提高了CPU的利用率 响应性增强:在交互式应用中，可以提高用户体验，比如用户在等待某个计算密集型任务的同时还可以进行其他操作。 复杂性增加:并发编程需要处理诸如同步、死锁等问题，增加了开发难度。 并行执行 随着晶体管和集成电路技术的进步，计算机的处理器能力得到了显著提升，并且制造出了包含多个处理器的计算机系统，这促进了并行计算的发展。并行执行能够显著提高计算机处理大量数据和复杂计算的能力，特别是在科学研究、天气预报、数据分析等领域。随着时间的发展，并行计算逐渐成为高性能计算(HPC)的核心技术，并行处理技术也在多核处理器和分布式系统中得到了广泛应用。\n并行执行具有以下几个特点:\n高性能:通过将任务分解为多个子任务并分配给不同的处理器执行，可以显著提高执行速度. 复杂性高:并行编程通常需要对算法进行重新设计以支持并行化，同时还需要考虑数据共享、同步等问题。 可扩展性：并行系统的设计往往考虑到了将来扩展的可能性，可以以通过增加处理器数量来提高性能。 I/O密集型任务与CPU密集型任务 IO密集型任务和CPU密集型任务时根据任务执行时主要消耗的资源类型来分类的。\nI/O密集型任务 10密集型任务是指那些任务执行过程中，大部分时间花费在输入/输出操作上，而不是CPU计算。这些任务的性能瓶颈通常在于磁盘读写、网络通信或用户输入等10操作的速度。以下是I0密集型任务的特点:\n等待时间:任务大部分时间在等待10操作完成。 CPU使用率:CPU使用率通常不高，因为CPU在等待I0操作完成期间常常处于空闲状态。 并发优势:IO密集型任务可以通过并发执行来提高效率，因为在等待一个IO操作完成时，CPU可以切换到另一个任务执行。 比如：文件处理、网络请求处理、数据库操作等。\nCPU密集型任务 CPU密集型任务是指大部分时间用于CPU计算的任务，设计大量的运算、判断和数据处理。这些任务的性能瓶颈通常在于CPU的计算能力。以下是CPU密集型任务的特点：\n计算时间：任务大部分在进行计算 CPU使用率：CPU使用率通常很高，因为任务需要大量的CPU资源 CPU密集型任务可以通过并行执行在不同的处理器核心上不同时运行来提高性能。 对程序执行的影响 对于IO密集型任务，多线程通常是一个较好的选择，因为它可以在单个进程内有效地处理多个IO操作，因为进程间切换的开销而降低效率。 对于CPU密集型任务，多进程可以更好地利用多核CPU的能力，因为每个进程可以在不同的核心上运行，从而提真整休的处理速度。 多进程的概念 进程介绍 进程:进程就是程序的一次执行过程，就是一个正在执行的任务，一段程序的每一次运行都会产生一个或多个进程。进程是有生命周期的，大部分会随着程序的运行而创建，随着程序的结束而终止，也可以去手动结束进程。在操作系统中，进程是操作系统进行资源分配和调度的基本单位。每个进程都有自己的私有地址空间、执行堆栈、程序计数器、局部变量以及其他系统资源(如文件描述符、网络连接等)等。通俗的说，一个正在运行的程序就是一个进程，比如QQ、微信等，但也有可能这个程序会生成多个进程。\n进程和程序的关系 进程:进程是程序的一次执行过程，它是动态的，具备生命周期，在程序运行时存在，程序执行完毕及用户主动结束、系统错误等都会导致进程结束。\n程序:程序是静态的，没有生命周期，在磁盘上存放，由一系列指令和数据组成的文件，这些文件可以被操作系统加载到内存中并执行。\n进程的种类 在Windows操作系统中，进程可以根据其创建方式和执行环境被分为几种类型。以下是一些常见的Windows进程类型:\n系统进程：\n这些进程是操作系统启动时由系统本身创建的，它们负责管理系统的核心功能，如内存管理、设备驱动程序、安全性和其他系统级服务。\n例如:Isass.exe(本地安全认证子系统服务)、wininit,exe(Windows初始化进程)。\n**服务进程(Service Process)：\n这些进程通常在系统启动时或按需启动，它们在后台运行，提供网络、安全、系统维护等服务，通常不直接与用户交互。\n例如:DHCP client(管理IP地址分配)\n用户进程(User Process):\n这些是由用户启动的应用程序创建的进程，用于执行特定任务，如文字处理、网页浏览、游戏等。\n例如:winword.exe(Microsoft Word)、chrome.exe(Google Chrome浏览器)。\n交互式进程(Interactive Process):\n这些是与用户交互的进程，它们通常在用户登录并直接与操作系统交互时运行。\n例如:命令提示符(cmd.exe)或PowerShell(powershe11.exe)。\nPID PID是“进程标识符”(Process ldentifier)的缩写，它是一个由操作系统分配给每个进程的唯一数字(大于等于0)。在操作系统中，每个进程都会被赋予一个唯一的PID，以便系统可以追踪和管理这些进程。\n唯一性:在一个操作系统中，每个正在运行的进程都有一个唯一的PID。即使在进程结束后，该PID通常也不会立即被重新分配给其他进程，以避免混淆。 进程管理:操作系统使用PID来识别和管理进程。例如，可以使用PID来发送信号给进程(如终止信号)、检查进程的状态、或者调整进程的优先级。 系统资源:PID还用于关联进程使用的系统资源，如打开的文件、网络连接和内存分配。 父进程与子进程:每个进程除了有自己的PID外，还有一个与之关联的父PID(PPID)。父PID是指启动该进程的进程的PID。 工具和命令:在命令行界面中，可以使用各种工具和命令来査看和管理进程，如 ps(Unix-ike系统)task1ist(Windows)等，这些工具通常会显示进程的PID。 kil命令:在Windows中，可以在CMD中通过ki+PID 来终止该进程的运行。\n多进程的概念 多进程(Multiprocessing)是指在同一时间内同时执行多个程序的技术或能力，每个进程都有自己的内存空间.文件描述符及其他系统资源。以下是多进程的一些特点:\n并发执行:多进程可以在多核或多处理器系统上实现真正的并行执行，即不同的进程可以在不同的CPU核心上同时运行。 资源分配:每个进程通常拥有独立的内存空间，这意味着它们不共享内存，这减少了资源共享带来的复杂性和潜在的问题。 独立性:全局变量在多个进程中不共享资源，进程之间的数据是独立的，默认是互不影响的。且由于进程间相对独立，一个进程的失败通常不会影响到其他进程，这提高了系统的稳定性和可靠性。 进程间通信(IPC):进程间通信机制(如管道、消息队列、共享内存、信号量等)用于允许进程之间交换数据和同步操作。 创建多进程 在Python中，multiprocessing库提供了创建和管理进程的方法，它允许程序员创建进程，并提供了一系列的API来支持进程间数据共享、同步和通信。 在Python中，使用multiprocessing中的Process类来创建子进程，Process类创建对象时的参数为:\n1 multiprocessing.Process(group=None, target=None, name=None, args=(), kwargs={},*,daemon=None) 以下是各个参数的说明:\ngroup:通常不使用，是为将来可能的扩展预留的。 target:表示调用对象，即子进程要执行的任务。这个参数通常是一个函数的名字 name:进程的名称。默认情况下，进程名称为Process-N，其中N是进程的序号。可以通过这个参数来指定一个自定义的名称。 args:表示调用 target函数时传递的参数元组， kwargs:表示调用target函数时传递的参数字典。 daemon:如果设置为True，则子进程将是一个守护进程。当主进程结束时，所有守护进程都将被终止。默认值为 None ，表示继承当前进程的守护进程设置。 创建的对象也拥有一些方法，分别是:\nstart():启动进程。这将执行在创建process对象时指定的target函数，调用start时会自动调用run。 run():此方法用于定义进程启动时执行的操作。默认情况下，它调用传递给 target 参数的函数。如果 join([timeout]):主进程等待子进程终止或直到达到指定的超时时间。如果 timeout 被省略或为 None，则主进程将一直停留在这里。 is_a1ive():返回一个布尔值，表示进程是否仍然在运行。 terminate():强行终止进程，且不会进行任何清理操作。 如果该进程创建了子进程，那么这个子进程就变成了僵尸进程，如果p还保存了一个锁，那么这个锁也不会被释放，会变成死锁。 ki11():终止进程。在Unix上，这是通过发送SIGKILL信号实现的;在Windows上，则是通过调用TerminateProcess . c1ose():关闭进程。此方法释放Process对象所持有的资源，如果子进程仍在进行，调用此方法将是错误的。 除此之外，还有属性:\nname:返回或设置进程的名称。 pid:返回进程的PID。 exitcode:返回进程的退出代码，如果进程未结束，就返回None，负值-N表示子进程被信号N终止，正常终 止返回0。 authkey:返回或设置进程间通信的密钥，用于进程间通信的身份认证，了解即可。 PID获取示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import time from multiprocessing import Process import os def say(): print(\u0026#34;子PID：\u0026#34;,os.getpid()) print(\u0026#34;父PID：\u0026#34;,os.getppid()) time.sleep(3) if __name__==\u0026#34;__main__\u0026#34;: p1 = Process(target = say) p1.start() print(\u0026#39;main PID:\u0026#39;,os.getpid()) p1.join() 进程间通信 进程间通信(Inter-Process Communication,IPC)是指在不同进程之间传送数据或信号的一些方法。在多进程程序中，IPC是非常重要的，因为它允许进程协同工作、共享数据或同步操作。以下是几种常见的进程间通信机制:\n管道(pipe) 管道是一种在父子进程间或兄弟进程间进行通信的机制。Python的mu1tiprocessing 模块提供了Pipe()函数可以用来创建管道。\n创建管道 1 parent_conn,child_conn=pipe() 使用 multiprocessing.Pipe()可以创建一个管道。这个函数返回一个由两个连接对象组成的元组，这两个对象分别代表管道的两端。默认情况下，管道是双向的，每个端点都可以即读又写。\n1 2 3 from multiprocessing import Process, Pipe # 创建一个管道 parent_conn,child_conn = Pipe() 管道方法 在上面的例子中，parent_conn和child_conn都是管道对象，它们都拥有共同的方法:\nsend(obj):发送一个对象到管道的另一端。这个对象必须是可序列化的。 recv():从管道的另一端接收一个对象。该方法是阻塞的。 close():关闭管道连接。当不再需要管道时，应该调用这个方法来释放资源。 fileno():返回由连接对象使用的文件描述符。 poll(timeout):返回连接对象中是否有可以读取的数据。如果未指定timeout，会马上返回，如果timeout是一个数字，则指定了阻塞的最大秒数，如果未指定timeout，那么将一直等待。 send_bytes(buffer,offset,size):通过连接发送buffer，offset是buffer中的偏移量，size是要发送的字节数。数据以一条完整的数据发送。 recv_bytes(maxlength):以字符串的形式返回一条从连接对象另一端发送过来的字节数据。此方法在接收到数据前一直阻塞。如果连接对象被关闭或没有数据可读取，将抛出异常。如果消息长度大于maxlength，则会抛出异常且该连接对象不可再读。 recv_bytes_into(buffer,offset):将一条完整的数据读入buffer中并返回消息的字节数，此方法在接收到数据前一直阻塞。如果连接对象被关闭或没有数据可读取，将抛出异常。offset指定buffer中放置消息处的字节偏移量。如果消息长度大于buffer将抛出导常。 使用管道 管道可以在进程间传递数据。通常，一个连接会传递给一个子进程，而另一个连接保留在父进程中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from multiprocessing import Process, Pipe def child_process(conn): # 子进程从连接中接收数据 conn.send(\u0026#39;He1lo from child\u0026#39;) data =conn.recv() print(\u0026#39;Received:\u0026#39;,data) conn.close() if __name__ == \u0026#39;__main__\u0026#39;: # 创建一个管道 parent_conn, child_conn = Pipe() # 创建子进程 p = Process(target=child_process, args=(child_conn,)) p.start() # 父进程发送数据到子进程 parent_conn.send(\u0026#34;hello from parent\u0026#34;) print(\u0026#39;Received:\u0026#39;,parent_conn.recv()) #等待子进程结束 p.join() 管道特点 双向通信:管道允许两个方向的通信，即每个管道有一个接收端和一个发送端.。 点对点连接:管道通常用于两个进程之间的直接通信，不支持多个进程之间的通信。 管道大小有限:管道的缓冲区大小是有限的。如果缓冲区满了，发送操作会阻塞。 注意事项 管道默认是双向的，但也可以通过设置dup1ex=Fa1se来创建单向管道。此时返回的第一个对象只能接收消息，第二个对象只能发送消息。 当使用管道在进程间传递大量数据时，要注意管道可能会成为性能瓶颈。 1 2 3 4 5 6 7 8 9 from multiprocessing import Process, Pipe def sender(conn): conn.send([42,None,\u0026#39;Hi\u0026#39;]) conn.close() if __name__ == \u0026#34;__main__\u0026#34;: #创建一个单向管道 parent_conn, child_conn = Pipe(duplex=False) 消息队列（Queue） 消息队列提供了一种在进程间传输数据的方式，这种方式是通过在内核中维护一个消息队列来实现的。进程可以发送数据到队列，也可以从队列中接收数据。在Python的mu1tiprocessing模块中，Queue 类提供了一个先进先出(FIFO)的消息队列。\n创建消息队列 1 2 3 4 from multiprocessing import Queue #创建一个消息队列 queue = Queue(maxsize=10) # maxsize为队列中最多可以存放的元素数量 消息队列的方法 在上面的例子中，queue是创建出来的消息队列，它拥有下面几种方法:\nput(obj，block=True，timeout=None):将obi放入队列，如果可选参数block是True而且timeout是None，将会阻塞当前进程，直到有空的缓冲槽。如果timeout是正数，将会在阻塞了最多timeout秒之后还是没有可用的缓冲槽时抛出异常。如果block是False，那么在没有空的缓冲槽时，会立即抛出异常，此时timeout会被忽略。 get(b1ock=True，timeout=None):从消息队列里获取消息。该方法为阻塞等待的方法。block和timeout的作用与put一致。 empty():如果队列为空，返回True，否则返回 False。 full() :如果队列满了，返回True，否则返回 False。 qsize():返回队列中当前元素的数量。 get_nowait():立即尝试从队列里获取一个元素，如果队列为空，抛出Queue.Empty异常 put_nowait():立即尝试从队列里放入一个元素，如果队列为空，抛出Queue.Full异常 在进程中使用消息队列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from multiprocessing import Queue,Process import time def process1(process_queue): print(\u0026#34;准备接收数据\u0026#34;) print(\u0026#34;接收到的数据为：\u0026#34;,process_queue.get()) if __name__== \u0026#39;__main__\u0026#39;: process_queue = Queue(5) p1 = Process(target=process1,arg=(process_queue,)) p1.start() time.sleep(2) process_queue.put(\u0026#39;Hi\u0026#39;) p1.join() p1.close() 消息队列的特点 先进先出(FIFO):队列遵循先进先出(FIFO)的原则，即先放入队列的元素会先被取出。 同步访问:queue 类提供了一系列同步方法，如 put()、get()等，以确保多进程对队列的访问是安全的。容量限制:队列可以指定最大容量，当队列满时，新元素将无法放入;当队列空时，试图从队列中获取元素的进程将阻塞，直到有新元素放入队列。 生产者-消费者模式:Queue 类非常适合用于生产者-消费者模式，其中生产者进程将数据放入队列，而消费者进程从队列中取出数据。 共享内存 共享内存是一种进程间通信(IPC)机制，顾名思义，它允许多个进程访问同一块内存空间。每个进程都可以读取或写入这块内存，从而实现数据的共享。\n创建共享内存 在Python中，共享内存分为两种，一种是共享一个变量，一种是共享一个数组。\n在Python中，使用multiprocessing.value(type_code，*args，1ock=True)来创建一个共享变量，其中type_code表示类型代码，*args表示初始化变量的值。lock表示锁，默认会创建一个锁用来保护共享变量。如果传入False，Value的实例就不会被锁保护，它将不是进程安全的。 在Python中，使用multiprocessing.Array(type_code,size_or_initializer,1ock=True)来创建-个共享数组，其中type_code表示类型代码，size_or_initializer表示数组的大小或初始化值，如果是一个整数，则表示数组的长度，且数组将被初始化为0，如果是一组序列，则就是数组的初始化值，其长度决定数组的长度。lock表示锁，默认会创建一个锁用来保护共享数组。 类型代码 映射 描述 \u0026lsquo;b\u0026rsquo; ctypes.c_byte 有符号字节（8位） \u0026lsquo;B\u0026rsquo; ctypes.c_ubyte 无符号字节（8位） \u0026lsquo;h\u0026rsquo; ctypes.c_short 有符号短整型（16位） \u0026lsquo;H\u0026rsquo; ctypes.c_ushort 无符号短整型（16位） \u0026lsquo;i\u0026rsquo; ctypes.c_int 有符号整型（32位） \u0026lsquo;I\u0026rsquo; ctypes.c_uint 无符号整型（32位） \u0026rsquo;l' ctypes.c_long 有符号长整型（32位） \u0026lsquo;L\u0026rsquo; ctypes.c_ulong 无符号长整型（32位） \u0026lsquo;q\u0026rsquo; ctypes.c_longlong 有符号长长整型（64位） \u0026lsquo;Q\u0026rsquo; ctypes.c_ulonglong 无符号长长整型（64位） \u0026lsquo;f\u0026rsquo; ctypes.c_float 单精度浮点数（32位） \u0026rsquo;d' ctypes.c_double 双精度浮点数（64位） 共享内存的方法 value：对于value对象，其属性用于获取或设置共享变量的值 [:]‘: 对于Array对象，可以使用切片操作来获取或修改数组中的元素。 共享内存的使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from multiprocessing import Process,Value,Array def func(shared_num,shared_array): shared_num.value += 1 for i in range(len(shared_array)): shared_array[i] += 1 if __name__== \u0026#39;__main__\u0026#39;: shared_num = Value(\u0026#39;i\u0026#39;,0) shared_array = Array(\u0026#39;i\u0026#39;,range(10)) print(shared_num.value) print(shared_array[:]) p = Process(target=func,args= (shared_num,shared_array)) p.start() p.join() print(shared_num.value) print(shared_array[:]) 共享内存的特点 高效的数据共享:共享内存比其他IPC机制(如消息队列)更高效，因为它避免了数据的复制。。 同步问题:共享内存需要同步机制(如锁)来防止竞态条件 类型限制:共享内存的数据类型有限，通常只能是基本数据类型。 进程同步 在Python中，进程同步是指在多进程环境下协调各个进程对共享资源的访问，主要解决的问题是当多个进程并发访问共享资源时，如何确保任一时刻只有一个进程能够访问该资源，从而避免由于进程间的无序竞争而导致的系统资源冲突，确保系统的稳定运行。进程同步通常涉及到以下几个核心概念:\n临界资源是指一段时间内仅允许一个进程访问的资源，这可能是硬件资源，也可能是软件资源如变量、数据.表格、队列等 临界区是指访问临界资源的那部分代码。在进入临界区之前，需要检査是否可以访问临界资源，以确保资源的互斥访问。 进程同步的机制应遵循以下规则:\n空则让进:如果临界资源处于空闲状态，则进程可以进入其临界区。 忙则等待:如果临界资源正在被使用，则请求访问的进程需要等待。 常见的进程同步机制包括锁、信号量、事件、条件变量等。 锁 锁(Lock)是一种用于控制多个进程访问共享资源的机制，锁的主要目的是防止多个进程同时访问共享资源时可能产生的竞态条件(Race Condition)，确保数据的一致性和完整性。在Pvthon中，最常用的锁为互斥锁(Lock)和递归锁(RLock)\n互斥锁 这是最常见的一种锁，它确保同一时间只有一个进程可以访问共享资源。当一个进程正在使用资源时，它会锁定该资源，其他进程必须等待锁被释放后才能访问。在mu1tiprocessing模块中，Lock对象可以用来确保临界区代码的互斥执行。\n方法:\nacquire(blocking=True，timeout=-1):尝试获取锁。如果b1ocking为True 并且timeout 是默认值 -1，该方法会阻塞直到锁被获取。如果 b1ocking为 False，则立即返回而不阻塞。 release():释放锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 import multiprocessing from multiprocessing import Queue,current_process import time #定义一个task函数，它将用于创建进程 def task(lock,queue,amount): while True: #获取一个锁 lock.acquire() # 上锁 #从队列中获取当前的余额 money = queue.get() #检查余额是否足够 if money \u0026gt;= amount: #余额足够，进行取款 money -= amount print(f\u0026#39;{current_process().name}取出{amount},现在还有{money}\u0026#39;) else: print(f\u0026#39;{current_process().name}余额不足\u0026#39;) #释放锁，允许其他进程操作 lock.release() #将跟新后的余额放回队列 queue.put(money) break queue.put(money) time.sleep(1) lock.release() if __name__ == \u0026#39;__main__\u0026#39;: count = 1000 queue = Queue(5) queue.put(count) #定义互斥锁 lock = multiprocessing.Lock() #创建两个进程 t1 = multiprocessing.Process(target=task, args=(lock,queue,50),name= \u0026#39;ZS\u0026#39;) t2 = multiprocessing.Process(target=task, args=(lock,queue,100),name= \u0026#39;LS\u0026#39;) t1.start() t2.start() t1.join() t2.join() 递归锁 递归锁与互斥锁最大的不同就是它允许同一个进程多次获取同一把锁，这意味着如果一个进程获取了锁，它还可以再次获取锁而不会导致死锁。但是该锁的内部有一个计数器，每当一个进程获取到锁时，计数器就会增加，当进程释放锁时，计数器就会减少。只有当计数器为0时，锁才会真正释放，才会允许其他的进程去获取锁，其他的使用和互斥锁一模一样。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import time from multiprocessing.dummy import current_process,Queue, RLock,Process #定义一个函数，它会不断向队列中添加数据 def producer(queue): while True: for i in range(10): queue.put(\u0026#34;HI\u0026#34;) time.sleep(1) #定义一个函数，它会不断从队列中取出数据 def consumer(queue,lock): while True: with lock: #time.sleep(2) #检查队列是否为空 if not queue.empty(): result = queue.get() print(f\u0026#39;{current_process().name}:{result}\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: queue = Queue(10) #定义一个递归锁，保证所有内容 lock = RLock() producer1 = Process(target=producer, args=(queue,)) producer1.start() consumer1 = Process(target=consumer, args=(queue,lock,),name=\u0026#39;consumer1\u0026#39;) consumer1.start() consumer2 = Process(target=consumer, args=(queue,lock,),name=\u0026#39;consumer2\u0026#39;) consumer2.start() producer1.join() consumer1.join() consumer2.join() 信号量 信号量是一个更高级的同步机制，它内部维护任个计数器，用于控制对共享资源的最大并发访问数量。在multiprocessing模块中，semaphore对象用于此类同步，\nmultiprocessing.semaphore(value=1):创建一个信号量对象，value 参数指定了初始可用的数量，默认为1。\n信号量的方法:\nacquire([timeout=None]):尝试获取信号量。如果信号量可用，则其值减一并立即返回 True。如果信号量不可用，则阻塞直到超时或信号量变为可用。如果没有指定timeout或timeout为None，则一直等待直至信号量可用。 release():释放一个信号量，其值加一。如果信号量之前已被阻塞，则会唤醒一个正在等待的进程 事件 事件是一种简单的同步机制，允许一个进程通知一个或多个等待的进程某些事件已经发生，也就是发送一个信号而其他进程可以根据这个信号做出反应。Event对象的使用场景:\n一个进程等待另一个进程完成某项任务。 控制多个进程间的简单通信。 实现对共享资源的访问控制。 在Python中使用multiprocessing.Event 创建事件对象，其基本方法有:\nis_set():返回事件是否已设置的状态，如果被设置则返回True，否则返回 False。 set():将事件设置为真状态，即 True ，表示可以唤醒正在等待该事件的所有线程或进程。 clear():将事件设置为假状态，即 Fa1se，表示没有线程或进程会被唤醒。 wait([timeout]):阻塞当前进程直到事件被设置为真状态或超时(如果提供了timeout 参数)。 如果没有设置超时时间，则会一直等待直到事件被设置。事件的使用分为两种情况:\n事件只被唤醒一次，然后开始进行自己的工作。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 from multiprocessing import Event,Process import time from scipy.special.cython_special import powm1 def producer(start_event,): start_event.set() while True: time.sleep(1) def consumer1(start_event,): start_event.wait() while True: print(1) def consumer2(start_event,): start_event.wait() while True: print(2) def consumer3(start_event,): start_event.wait() while True: print(3) if __name__ == \u0026#39;__main__\u0026#39;: start_event = Event() p1 = Process(target=producer, args=(start_event,)) p1.start() c1 = Process(target=consumer1, args=(start_event,)) c1.start() c2 = Process(target=consumer2, args=(start_event,)) c2.start() c3 = Process(target=consumer3, args=(start_event,)) c3.start() p1.join() c1.join() c2.join() c3.join() 进程池 进程池是一组预先创建的空闲进程，它们等待执行任务，主进程负责将任务分配给进程池中的空闲进程去执行。进程池可以管理进程的创建和销毁，避免了频繁地创建和销毁进程带来的开销，通过进程池可以轻松的实现多任务的 并行处理。\n为什么使用进程池 效率:相比于手动创建和管理多个进程，使用进程池可以更高效地利用系统资源。 简化:进程池简化了并行编程的复杂性，开发者不需要关注进程的创建和销毁细节。 控制:可以限制同时运行的进程数量，防止系统资源被过度消耗。 进程池的创建 在Python中，进程池的创建有两种方式。\n使用multiprocessing库 在Python中，使用multiprocessing 模块中的Pool创建进程池:\n1 2 import multiprocessing.Pool multiprocessing.Pool(processes=None,initializer=None,initargs=(),maxtasksperchild=None) 参数解释：\nprocesses:进程池中的进程数。如果processes为None，则默认使用系统的处理器核心数。。 initializer:每个工作进程启动时要执行的可调用对象，默认为None。如果是None，则调用initializer(*initargs)。 initargs:传递给initializer的可变参数元组。 maxtasksperchild:工作进程退出之前可以完成的任务数，完成后用一个新的工作进程来替代原进程，来让闲置的资源被释放。maxtasksperchild默认是None，意味着只要Pool存在工作进程就会一直存活。 使用concurrent.futures库 在Python中，使用concurrent.futures的ProcessPoolExecutor创建进程池。\n1 2 concurrent.futures.ProcessPoolExecutor(max_workers=None, mp_context=None. initializer=None,initargs=) 参数解释：\nmax_workers:指定进程池中可以同时运行的最大进程数。如果设置为 Non列或未指定，则默认为机器的处理器数量，最多为61。 mp_context:指定多进程上下文。默认情况下，ProcessPoolExecutor 使用multiprocessing.get_context()来获取上下文。这允许你选择不同的上下文，例如 spawn、 fork.forkserver 等，这些上下文可能提供不同的功能，如更好的资源隔离、更好的安全性等。 initializer:一个可选的可调用对象，每个工作进程在启动时都会调用它。这可以用来执行进程的初始化操作，例如设置进程局部存储。 initargs:一个元组，其中包含传递给 initializer 的参数。 ","date":"2024-10-15T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python-%E5%A4%9A%E8%BF%9B%E7%A8%8B/","title":"Python-多进程"},{"content":"文件操作 文件操作的重要性 数据持久化:文件是存储数据的一种非常基本且重要的方式。通过文件，我们可以将程序运行时产生的数据永久保存下来，以便将来使用。 跨平台兼容性:文件是一种通用的数据交换格式，可以在不同的操作系统和平台上进行传输和处理。 数据备份与恢复:定期备份数据到文件有助于防止数据丢失，便于数据恢复。 数据共享:文件可以轻松地在网络之间共享，使得多人协作成为可能。I 配置管理:许多应用程序使用文件来存储配置信息，方便用户根据需要调整设置。·日志记录:文件被广泛用于记录程序运行时的日志，这对于调试和性能监控非常重要 应用场景 数据分析:读取数据文件进行数据分析，或者程序的运行结果输出到文件，以便于报告或进一步分析。 Web开发:读取配置文件来设置Web服务器的各种参数，处理用户上传的文件。 系统管理:读取和写入日志文件以监控系统状态。 文本处理:读取文本文件，进行搜索、替换等操作，并将处理后的结果保存到文件中。 游戏开发:读取账号数据、保存账号数据，管理游戏资源文件。 文件的基本概念 文件的概念 文件是一个存储在某种持久性存储介质(如硬盘、固态驱动器或磁带等)上的数据集合。文件可以包含各种类型的信息，包括文本、图像、音频、视频、应用程序代码以及其他类型的二进制数据。文件是操作系统用来组织和管理这些数据的主要方式之一。\n文件通常由以下几部分组成:\n数据:文件中存储的实际信息，即用户想要保存的具体信息，如文本、图像或代码等 元数据:关于文件本身的附加信息，包括但不限于文件名、创建日期、文件大小、文件类型等。 文件系统:这是操作系统用来组织和管理文件的一种逻辑结构，包括文件的命名、存储和检索方式。文件系统还负责管理磁盘空间的分配，并确保文件可以被正确地读写。常见的文件系统有 FAT32、NTFS 等。 文件的属性 文件名:用于标识文件的唯一名称，通常包含主文件名和扩展名(如 document.txt) 位置:文件存储在一个特定的位置，这个位置可以用目录或路径来表示。例如，在Windows系统中，文件路径可能是c:\\Documents\\example.txt;而在Unix-like系统中，路径可能是/home/user/Documents/example.txt。 文件类型:根据文件的内容和用途，文件可以有多种类型，如文本文件、图像文件、音频文件等4.文件大小:文件占用的存储空间大小，通常以字节(B)、千字节(KB)、兆字节(MB)或吉字节(GB)为单位 文件的类型 在Windows系统中，大致可以分为以下几种:\n文本文件:包含可读字符的文件，如.txt、.csv、.html等。 二进制文件:包含不可直接读的原始二进制数据的文件，如.exe、jpg、.mp3等。 可执行文件:可以被操作系统执行的文件，如.exe(Windows)。 数据文件:用于存储应用程序数据的文件，如数据库文件、配置文件等。 目录/文件夹:用于组织和管理其他文件的特殊文件。 在Linux系统中，可以分为以下几种:\n-：普通文件，比如txt、py等。 d:目录文件，比如xx目录，类比Windows中的文件夹。 b:块设备文件，Linux系统中的底层驱动文件。 c:字符设备文件，Linux系统中的底层驱动文件。 l:链接文件，类似于快捷方式 p:管道文件，用于进程间的通信。 s：套接字文件，用于网络通信的端点，用于网络传输。 文件的路径 在计算机文件系统中，路径是用来标识文件或目录位置的一种方式。路径有两种主要的形式:绝对路径和相对路径。这两种路径形式对于在文件系统中导航和访问文件非常重要。\n绝对路径 绝对路径是从文件系统的根目录开始的一条完整路径，它指明了从根目录到达目标文件或目录的具体步骤。\n特点:\n不依赖于当前工作目录。 在不同用户或程序间具有一致性 提供了文件或目录的完整位置信息。 示例:\n在Windows系统中，一个绝对路径可能看起来像这样:c:\\users\\John\\Documents\\report.txt。 在Linux/Unix系统中，一个绝对路径可能看起来像这样:/home/john/Documents/report.txt。 相对路径 相对路径是指相对于某个起始点(通常是当前工作目录)到达目标文件或目录的路径。\n特点:\n取决于当前工作目录的位置。 更加灵活，但可能会因上下文变化而变化。 适用于在同一目录层级或附近层级内的文件访问 示例:\n在Windows系统中，如果当前工作目录是c:\\users\\John\\Documents，那么我想去找同目录下的example.txt的话，就是,\\example.txt，如果上级目录下的example.txt的话，就是..\\example.txt。 在Linux/Unix中，如果当前工作目录是 /home/iohn/oocuments ，那么我想去找同目录下的example.txt的话，就是./example.txt，如果上级目录下的example.txt的话，就是../example.txt。 路径中的特殊符合 .(当前目录):表示当前目录。 ..(上一级目录):表示当前目录的父目录。 使用场景 绝对路径:当需要指定确切位置，或者在不同环境(如不同用户的系统)下保持一致时使用。\n相对路径:当文件位于同一目录或相关联的子目录中时使用，可以使程序更加灵活和便携。\n文件的操作 打开文件 在Python中，使用open()函数来打开文件，这个函数返回一个文件对象，可以用来进行后续的读写等操作。函数原型为:\n1 res = open(file_name, mode=\u0026#39;r\u0026#39;, buffering=None, encoding=None, errors=None, newline=None,closefd=True) 参数解释：\nfile_name:要打开的文件的路径加名称(包含后缀名)，可以是绝对路径也可以是相对路径。mode:打开文件的模式，默认为\u0026rsquo;r\u0026rsquo;，表示只读模式且以文本模式读取。 buffering:可选参数，缓冲区大小。0表示无缓冲，1表示行缓冲，更大的整数表示具体的缓冲区大小。默认为None，表示默认的缓冲策略，大多数情况下，使用默认值就可以了。 encoding:可选参数，用于指定文件的编码，仅适用于文本模式，默认值None表示使用系统的默认编码来打开文本文件。 errors:可选参数，用于指定如何处理编码和解码错误，对于二进制模式无效。常见的值有strict、ignore、replace等。 newline:可选参数，用于控制通用换行符模式的行为。它可以是None、\u0026rsquo;\u0026rsquo;、\u0026rsquo;\\n\u0026rsquo;、\u0026quot;\\r\u0026rsquo;或\u0026rsquo;\\r\\n\u0026rsquo;。如果设置为 None ，则通用换行符模式被启用，\\n、\\r和\\r\\n都被识别为换行符，并以\\n的形式在文本模式下读取。如果设置为其他值，则在该值处进行换行符的转换。 closefd:可选参数，如果为True(默认值)，则在文件关闭时关闭文件描述符。如果为Fa1se，则文件描述符在文件关闭时保持打开状态。 文件模式 以下是几种常见的文件打开模式:\n\u0026lsquo;r\u0026rsquo;:read 只读模式(默认值)。如果文件不存在就会触发异常, \u0026lsquo;r+\u0026rsquo;:打开文件进行读写，该文件必须存在 \u0026lsquo;w\u0026rsquo;:write 写入模式，如果文件存在则覆盖，不存在则创建。 \u0026lsquo;W+\u0026rsquo;:打开文件进行读写，如果文件存在则覆盖，如果不存在则创建。 \u0026lsquo;a\u0026rsquo;:追加模式，如果文件存在则在文件末尾追加内容，不存在则创建, \u0026lsquo;a+\u0026rsquo;:打开文件进行读写，如果文件存在则在末尾追加，如果不存在则创建。 \u0026lsquo;x\u0026rsquo;:独占创建模式，如果文件已存在则抛出异常，这可以用来避免覆盖现有文件。 \u0026lsquo;b\u0026rsquo;:二进制模式，读写时，数据不会被转换，直接以字节形式处理。 \u0026rsquo;t\u0026rsquo;:文本模式(默认值)，读写时，数据会被视为字符串。 读取文件 打开文件后，可以使用以下方法读取内容:\nread(size):size是可选参数，在文本模式下，一次最多读取文件指针后面size个大小的字符，在二进制模式下，一次最多读取文件指针后面size个大小的字节，默认size为None，表示一次性读取文件指针后面的所有内容并将其作为字符串返回。 readline():从文件中读取单行数据 readlines():读取所有行，并返回一个列表。 写入文件 要将内容写入文件，可以使用以下方法:\nwrite(str):将str的内容追加到当前文件指针位置，并将文件指针移动到新的写入位置。会返回写入的字符数量，写入其他类型的对象时，要先将它们转化为字符串或字节对象。 writelines():写入一个字符串列表。 关闭文件 在python中，使用close()方法关闭文件。关闭文件是一个重要的操作，因为它释放了与文件对象关联的系统资源，并确保数据正确地写入存储介质。 功能：\n释放资源：关闭文件，释放与文件对象关联的所有系统资源，如文件描述符、缓冲区等。 刷新缓冲区:在关闭文件之前，它会自动刷新文件的内部缓冲区，确保所有缓冲的数据都被写入磁盘, 禁止进一步操作:关闭文件后，文件对象不再允许进行读取、写入或其他操作。 重要性： 文件操作完成后，应该关闭文件以释放资源，可以使用close()方法关闭文件。在Pvthon程序中，如果不关闭打开的文件，可能会产生以下影响: 资源管理:文件描述符是有限的资源，如果不关闭文件，可能会导致资源泄漏，特别是在打开大量文件时。 数据完整性:确保所有缓冲的数据都写入磁盘，防止数据丢失。尤其是在写入操作后，如果不关闭文件，可能会导致最后写入的数据没有保存。 防止错误:关闭文件可以防止对已关闭文件的非法操作，这些操作可能会引发异常。 提高效率:关闭不再需要的文件可以释放系统资源，提高程序的整体效率。 清理操作:在关闭文件时，可以执行一些清理操作，如关闭网络连接或释放其他相关资源。 with语句 用于简化资源的打开和关闭过程，确保资源在Python中，with语句是一种上下文管理器(contextmanager)在不需要时得到适当的释放。这种机制常用于文件操作、网络连接、锁等资源的处理，可以避免资源泄露和出现其他资源管理问题。\n基本语法为:\n1 2 3 4 5 with expression [as variabfel]: with-block 例如： with open(\u0026#39;./1.txt\u0026#39;,\u0026#39;w\u0026#39;) as fd: res = fd.write() 表达式(expression):这个表达式必须返回一个实现了上下文管理器协议的对象，也就是说，它需要包含enter_和_exit_两个方法。 as 子句:这是可选的。如果提供了as子句，那么expression中_enter_方法的返回值将被赋值给变量。 with-b1ock:这个代码块是 with语句的主体，在执行这个代码块之前，会首先调用上下文管理器的_enter_方法。当with-b1ock执行完毕后，不论是因为正常完成还是因为异常，都会调用上下文管理器的exit 方法，该方法负青关闭文件 文件指针的操作 获取文件指针的位置 在python中，使用tell()函数去返回当前文件指针的位置.\n1 tell() tell()函数没有参数，它的功能就是返回文件指针当前位置相对于文件开头的偏移量。这个偏移量是一个整数，表示从文件开头到当前读取位置的字节数。\n注意事项:\ntell()方法仅在文件被打开用于读取时才有意义，因为在写入模式下，文件指针的位置会随着写入操作而改变 在读取模式下，tell()方法返回的是当前读取位置相对于文件开头的偏移量。 其返回值是字节数，不是字符数，对于utf-8的编码格式来说，一个汉字占三个字节，所以读取中文时，字符数与字节数是不一样的。 改变文件指针的位置 在python中，使用seek()函数去改变文件指针的位置。\n1 seek(offset,whence=0) 其中: offset:表示相对于whence的偏移量，是一个整数。这个偏移量可以是正数，也可以是负数。正数表示向文件末尾方向移动，负数表示向文件开头方向移动，0则表示不偏移。\nwhence:是一个可选的参数，默认为0。它指定了offset的起始位置，可以是以下三个值之一\n0:表示从文件开头开始计算偏移量(默认值) 1:表示从当前文件指针位置开始计算偏移量。 2:表示从文件末尾开始计算偏移量。 注意事项:\nseek 方法在文本模式和二进制模式下都有效，但文本模式whence只能使用默认值，不能自己修改。 seek 方法基于字节偏移量。这意味着即使文件包含多字节字符，seek 改变的仍然是字节偏移量。 1 2 3 4 5 6 7 8 9 10 11 12 import os from io import TextIOWrapper path =\u0026#39;./1.txt\u0026#39; with open(\u0026#39;./1.txt\u0026#39;,\u0026#39;a+\u0026#39;) as fd: res = fd.tell() ret = fd.read() print(ret) fd.seek(0) ret1 = fd.read() print(ret1) 获取文件属性 在Python中，可以使用内置的os模块来获取文件的属性。以下是一些常用的方法来获取文件属性:\n获取文件大小 在python中，使用**os.path.getsize()**获取指定文件的大小(以字节为单位)\nos.path.getsize(path) path(字符串)-文件的路径。\n返回一个整数，表示文件的大小(以字节为单位)。如果文件不存在或无法访问，会抛出异常。\n获取文件的最后修改时间 在python中，使用**os.path.getmtime()**获取指定文件的最后修改时间。\nos.path.getmtime(path) path(字符串)-文件的路径。\n获取文件的创建时间 在python中，使用**os.path.getctime()**获取指定文件的创建时间。\nos.path.getctime(path) path(字符串)-文件的路径。\n获取文件的最后访问时间 在python中，使用**os.path.getatime()**获取指定文件的最后访问时间。\nos.path.getatime(path) path(字符串)-文件的路径\n目录操作 在Python中，可以使用多个模块来操作目录，但是最常用的就是os模块，以下就是一些常见的目录操作:\n创建目录 在Python中使用os.mkdir(path)函数来创建目录。\n1 2 import os os.mkdir(path, mode=0o777) 其中：\npath(字符串)-要创建的目录的路径。 mode (整型，可选)-设置新创建目录的权限位。默认值是 0o777(八进制表示)，意味着所有人都有读、写和执行权限，只针对Linux系统，Windows系统会忽略。 如果目录创建成功，则函数不返回任何内容。如果指定的路径已经存在就会抛出异常，如果路径是无效的，或者由于权限不足等原因无法创建目录，也会抛出异常。\n注意事项：\nos.mkdir 只能创建一级目录，如果父目录不存在，则会抛出异常。 如果需要创建多级目录结构，可以使用os.makedirs函数，它会递归地创建所需的中间目录。 删除目录 在Python中使用os.rmdir(path)函数去删除目录。\n1 2 import os os.rmdir(path) path(字符串)-要删除的空目录的路径。\n如果目录删除成功，则函数不返回任何内容。如果指定的路径不存在，则会抛出异常，如果路径不是一个空目录,或者由于权限不足等原因无法删除目录，也会抛出此异常。\n注意事项 os.rmdir 只能删除空目录。如果目录中包含文件或其他目录，os.rmdir 将无法删除它，并且会抛出异常。\n改变当前工作目录 在Python中使用os.chdir(path)函数来改变工作目录\n1 2 import os os.chdir(path) path(字符串)-要切换到的目录的路径。如果指定的路径不存在、指定的路径不是一个目录、没有权限更改到指定的目录就会抛出异常。\n如果目录切换成功，则函数不返回任何内容\n获取当前工作目录 在Python中使用os.getcwd()函数获取当前的工作目录\n1 os.getcwd() 该函数没有参数，但会返回一个字符串，表示当前工作目录。\n列出自录下的所有内容 在Python中使用os.listdir(path)函数获取指定目录下的所有文件和子目录的名称。\n1 2 import os items =os.listdir(path) path(字符串)-要列出内容的目录的路径。如果省略，默认为当前工作目录。如果指定的路径不存在、指定的路径不是一个目录、没有权限读取指定的目录就会抛出异常。\n这个函数返回一个列表，其中包含指定路径下的所有文件和子目录的名称。\n注意事项\nos.1istdir 不会递归地列出子目录中的内容。它只列出直接位于指定目录下的文件和子目录。 返回的列表中只包含名称，不包含路径。如果需要完整路径，你需要将目录名称与路径结合起来。 如果目录为空，返回的列表将是空的。 在使用 os.1istdir 时，应该考虑到可能出现的异常，并适当处理它们，以确保代码的健壮性， 重命名目录 在Python中使用os.rename(src，dst)函数对一个文件或目录进行重命名。这个函数可以将一个文件或目录从其当前路径(源路径)更改为一个新的路径(目标路径)。\n1 2 import os os.rename(src,dst) 参数解释\nsrc(字符串)-要重命名的文件或目录的当前路径， dst(字符串)-文件或目录的新名称和路径。如果重命名成功，则函数不返回任何内容。 检查路径是否为目录 在Python中使用os.path.isdir()函数检查给定的路径是否是一个目录。\n1 2 import os.path is_directory=os.path.isdir(path) 参数解释：\npath(字符串)-要检查的路径,如果指定的路径是一个目录，返回 True;否则返回 Fa1se\n路径拼接 在Python中使用**os.path.join(path,*path)**函数将一个或多个路径组件合并成一个完整的路径!这个函数会根据操作系统的文件系统约定来正确地处理路径分隔符。\nimport os os.path.join(path,*paths) 参数解释：\npath(字符串)-起始路径，通常是一个目录路径, *paths(可变参数)-需要连接到 path 的其他路径片段。返回一个字符串，表示将所有路径片段连接后的完整路径。 os.path.join()的作用包括:\n合并路径:将多个路径组件合并成一个单一的路径字符串, 处理分隔符:它会根据操作系统自动添加或删除路径分隔符(例如，在 Windows 上是反斜杠\\，在Unix/Linux 上是正斜杠 /)。 消除冗余分隔符:如果路径组件之间有多余的分隔符，os.path,join() 会自动处理，避免产生错误的路径. 使用os.path.join()的好处是，它能够确保生成的路径在不同的操作系统上是正确的，从而提高了代码的可移植性。此外，它还能避免手动拼接路径时可能出现的错误，如忘记添加分隔符或添加了错误的分隔符。\n路径拆分 在Python中使用os.path.split(path)函数将路径分割成两部分:目录路径和文件名。\n1 2 import os head, tail = os.path.split(path) 参数解释：\npath:表示要分割的路径， head:它是 path 的目录路径 tai1:它是 path 的文件名 os.path.split()的主要用途包括:\n从完整路径中提取文件名或目录名。 用于文件处理时，需要单独操作文件名和路径的其他部分。 在遍历文件系统时，帮助确定每个文件的上级目录。 需要注意的是，如果提供的路径以路径分隔符结尾，那么 tai1 将是一个空字符串，表示路径的最后一部分是一个目录。此外，如果路径是空字符串，os.path.split()将返回两个空字符串。\n","date":"2024-10-14T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","title":"Python文件操作"},{"content":"正则表达式 正则表达式，又称规则表达式，(Regular Expression，在代码中常简写为regex、regexp或RE)，是一种文体模式，包括普通字符(例如，a到z之间的字母)和特殊字符(称为\u0026quot;元字符\u0026quot;)。正则表达式使用单个字符串来描述。匹配一系列符合某个句法规则的字符串，通常被用来检索、替换那些符合某个模式(规则)的文本。通俗的说，正则表达式就是一种语法规则，用来匹配文本中的文本。\nre.match 该函数尝试从字符串的起始位置匹配，如果起始位置没有匹配成功的话，就返回None，否则会返回一个匹配对象，匹配对象的方法可参考下面的表格。\n方法 说明 group() 返回被匹配的字符串 start() 返回匹配开始的位置 ecd() 返回匹配结束的位置 span() 返回一个元组包含开始和结束的位置 函数原型:\nre.match(pattern，string，flags=0) 其中： pattern:正则表达式的格式。 string:被匹配的文本。 flags(可选):标志位，用于控制正则表达式的匹配方式， 如:是否区分大小写、设置多行匹配模式等，具体有哪些标志可参考下面的附录1表格。 常用的应用场景有:\n验证输入格式:检查用户输入是否符合特定的格式，例如电子邮件、电话号码、日期等 提取信息:从字符串的开始位置提取符合正则表达式模式的字串，如提取文件名等。 数据解析:在处理日志文件或配置文件时，可以用来解析每行的开始部分，获取关键信息。 1 2 3 4 5 6 7 8 9 10 11 import re while True: email = input(\u0026#39;请输入有效的邮箱:\u0026#39;) pattern =r\u0026#34;[0-9a-zA-Z+-_.]+@[0-9a-zA-Z.-]+\\.[a-zA-Z]{2,}\u0026#34; #匹配【0-9，a-z，A-Z，+ - _ .至少一次】，【@符号】，【匹配0-9，a-z，A-Z，- . 至少一次】，【符号.】，【a-z，A-Z两次以上】 res =re.match(pattern,email) if res: print(\u0026#39;您的邮箱格式正确\u0026#39;) break else: print(\u0026#39;您的邮箱格式有误，请重新输入\u0026#39;) re.search 该函数从文本中获取第一个符合正则表达式模式的字符的位置，并返回一个匹配对象，如果没有匹配到，就返回None.\n函数原型:\nre.search(pattern，string,flags=0) 其中： pattern:正则表达式的格式。 string:被匹配的文本。 flags(可选):标志位，用于控制正则表达式的匹配方式， 如:是否区分大小写、设置多行匹配模式等，具体有哪些标志可参考下面表格。 flags参数 说明 re.I 忽略字母大小写 re.L 影响 “w, “W, “b, 和 “B，这取决于当前的本地化设置。 re.M 多行匹配，使^和\u0026amp;能够匹配每一行的行首和行尾 re.S 单行匹配，使.特殊字符能匹配任何字符，包括换行符 re.X 允许你编写更易于阅读的正则表达式，忽略空白字符和注释 常用的应用场景有:\n检查字符串是否包含子串:检査一个字符串是否包含某个特定的文本。 提取数据:从字符串中的任意位置提取信息，例如从一个文本段落中提取所有提到的日期。 搜索文件:在某文件中查找特定的消息或事件。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import re text =\u0026#39;\u0026#39;\u0026#39; gjiaokremgn vkn24124pa2 13315561889 hbvuijrbnio 15633567985 \u0026#39;\u0026#39;\u0026#39; pattern =r\u0026#39;^[1]{1}[3589]{1}[0-9]{9}$\u0026#39; res =re.search(pattern,text，re.M) if res: print(res.group()) print(res.start()) re.findall 该函数从文本中寻找所有与模式匹配的子串，并将所有的匹配结果存储到一个列表中进行返回，如果没有匹配成功会返回一个空列表。\n函数原型:\nre.findall(pattern，string，flags=0) 其中： pattern:正则表达式的格式。 string:被匹配的文本。 flags(可选):标志位，用于控制正则表达式的匹配方式， 如:是否区分大小写、设置多行匹配模式等，具体有哪些标志可参考上面的表格flags参数。 常用的应用场景有:\n提取多个子串:当你需要在字符串中找到所有匹配特定模式的字串时, 文本分析:在文本中，提取文本中特定的词汇、短语或模式。 1 2 3 4 5 6 7 8 9 10 11 12 import re text =\u0026#39;\u0026#39;\u0026#39; gjiaokremgn vkn24124pa2 13315561889 hbvuijrbnio 15633567985 \u0026#39;\u0026#39;\u0026#39; pattern =r\u0026#39;^[1]{1}[3589]{1}[0-9]{9}$\u0026#39; res =re.findall(pattern,text，re.M) print(res) re.sub 该函数的作用就是将文本中与模式匹配的部分替换为其他的内容。\n函数原型:\nre.sub(pattern,repl,string,count，flags=0) 其中： pattern:正则表达式的格式。 repl:这是替换文本或一个函数。如果是文本，就是将匹配到的内容替换为该文本;如果是函数，会在函数中进行文本处理的操作。 string:被匹配的文本。 count(可选):这是可选参数，表示替换的最大次数。默认值为0，表示替换所有匹配项。 flags(可选):标志位，用于控制正则表达式的匹配方式， 如:是否区分大小写、设置多行匹配模式等，具体有哪些标志可参考下面的附录1表格。 常用的应用场景有:\n文本格式化:将文本中的特定模式的文本替换为另一种格式。 数据清洗:在处理数据时，移除或替换无效或不需要的字符，比如在一系列文本中删除非数字字符以清理电话号码。 敏感信息脱敏:在显示或存储数据前，将敏感信息(比如身份证号、手机号)的部分内容替换为星号 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import re #原始字符串 text =\u0026#34;Hello 123 World 456\u0026#34; #定义一个正则表达式模式，匹配数字\\d pattern =r\u0026#39;d+\u0026#39; #定义一个替换函数 def replace(match): #将匹配到的数字乘以2 number = int(match.group()) return str(number*2) #使用re.sub 和替换函数 new_text =re,sub(pattern, replace, text) print(new_text) #输出\u0026#34;Hello 246 World 91 re.split 该函数的作用就是将某文本根据匹配模式进行分割，并将分割后的结果放入列表中返回。\n函数原型:\nre.split(pattern,string,maxsplit，flags=0) 其中： pattern:正则表达式的格式, string:被匹配的文本。 maxsplit(可选):这是可选参数，表示最大分割次数。默认值为0，表示分割所有匹配项。 flags(可选):标志位，用于控制正则表达式的匹配方式， 如:是否区分大小写、设置多行匹配模式等，具体有哪些标志可参考上面的表格。 1 2 3 4 5 6 import re text = \u0026#39;apple, banana, orange, watermelon\u0026#39; fruits = re.split(r\u0026#39;,\\s*\u0026#39;,text) #匹配，\\s 匹配空白符，*匹配0次或多次 print(fruits) re.compile 该函数会预先编译正则表达式要匹配的模式，并会返回一个正则表达式的对象，该对象与re.match返回的对象不同，该对象可以调用上面的函数。\n函数原型:\nre.compile(pattern,flags=0) 其中： pattern:要匹配的正则表达式。 flags(可选):标志位，用于控制正则表达式的匹配方式， 如:是否区分大小写、设置多行匹配模式等，具体有哪些标志可参考上面的表格。 常见的应用场景: 多次匹配:当你需要在一个较长的文本中多次应用同一个正则表达式时，使用re.compile可以避免每次匹配时都重新编译表达式。\n装饰器 在Python中，装饰器(Decorator)本质上是一种特殊的嵌套函数，它接收一个函数作为参数(该函数就是被装饰的函数)，并返回一个新的函数(装饰之后的函数)。\n装饰器最大的作用就是可以让我们在不改变被装饰函数的代码的情况下去给它添加新的功能\n装饰器的基本用法 在不改变原有func()的情况下，使用装饰器给func()函数添加打印b，c的功能。\n1 2 3 4 5 6 7 8 9 10 11 12 def decorator(f): def f1(): print(\u0026#39;b\u0026#39;) f() print(\u0026#39;c\u0026#39;) return f1 def func(): print(\u0026#39;a\u0026#39;) func = decorator(func) #可以替换为@decorator func() ","date":"2024-10-13T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","title":"Python的正则表达式"},{"content":"模块与包 模块的概念 模块就是一个包含了Python代码的.py为后缀的Python文件，可以被其他Python程序导入和使用，也可以自己独立执行，里面存放着一组相关的函数或者类，比如产看关键字列表时导入的keyword模块。\n模块的导入有以下几种形式：\nimport 模块 import 模块 as 别名 from 模块 import 模块 from 模块 import * from 模块 import 模块 as 别名 使用import直接导入\n1 2 3 4 5 6 #moduleA def add(x,y): return x + y a = 1 b = 2 调用模块A的方式为：moduleA.add( )\n1 2 3 4 #moduleB import moduleA ret = module.add(4,9) print(ret) 模块的作用：\n令Python代码的编写不必从零开始。 避免了同一模块内命名重复问题。 方便代码的管理与维护，提高代码的维护性。 包的概念 包就是一个有层次的文件目录结构，用来跟好的组织和管理模块。通俗的说就是一个目录，里面存放Python文件和新的包目录，并且每一个包都需要存在一个__init__.py文件。\ninit.py文件的主要作用：\n标识包目录 执行初始化代码 控制包的导入行为：通过__all__ 来控制那些模块可以被导入，防止不需要的模块导入。 提供包级别的命名空间 批量导入模块 第三方包的相关操作：\n安装包\npip install package-name == version 更新包\npip install -upgrade package-name == version 卸载包\npip uninstall package-name 异常处理机制 异常是一个事件，会在程序执行过程中产生，并且会影响程序的正常执行。\n一般情况下，Python遇见错误的代码或者无法处理正常程序就会产生一个异常，异常被抛出后，捕捉程序会按照某种机制继续运行，如果对抛出的异常不做任何处理，程序就会终止运行。\n常见的异常有：\nKeyboardInterrupt：用户主动结束程序 AttributeError：尝试访问对象没有的属性 TypeError：操作非法类型的数据 IndexError：序列中没有索引 KeyError：字典中没有键 Exception：通用的异常类，用于捕获其他说有的异常情况 在Python中，使用try、except、finally、else关键字来组合成不同方式，其中try和except时异常处理机制的核心。\n异常处理分三种，捕获单个异常、捕获多个异常和捕获全部异常，在捕获dao对应的异常后，不会再导致程序终止执行，而是会执行处理异常的代码。\n异常捕获格式：\n1 2 3 4 5 6 7 8 9 10 try： #有可能发生异常的代码 except 某个异常： #某个异常可以用（异常1，异常2）表示捕获多个异常 #也可以用替换为Exception，捕获所有异常 #异常发生后要执行的代码 else： #如果没有异常发生，在try执行完毕后执行这里的代码 finally： #不管有没有捕获到异常，最后都会执行这里的代码 自定义异常 在Python中使用raise关键字手动抛出异常，使用方法：\nraise Exception(arg) Exception用于指定要抛出的异常类型，该类型来自Python解释器自带的异常类型。 agr是一个可选参数，用于提供关于异常的信息。 例如： 1 2 3 4 for i in range(100): print(i) print(a) raise NameError(\u0026#39;未定义变量\u0026#39;) 自定义异常，在Python中，自定义属于自己的异常必须继承Exception类，其格式：\n1 2 3 4 5 6 7 8 9 10 11 class MyException(Exception): def __init__(message, code, traceback): self.code = code self.traceback =traceback #使用自定义异常 try： raise MyException(message:\u0026#34;\u0026#34;,code = 404 , traceback = None) except MyException as e: print(f\u0026#39;捕获到自定义异常：{e}\u0026#39;) print(f\u0026#39;错误代码：{e.code}\u0026#39;) print(f\u0026#39;追踪信息：{e.traceback}\u0026#39;) 在Python中记录日志文件，记录日志使用logging库，日志的级别从高到底为：\nCritical:系统崩溃级别的错误 error：运行时的错误，可能导致程序无法运行 warning：警告消息 info：信息性消息，程序正常运行 debug：详细信息，通常在诊断问题时有用 1 2 3 4 5 6 7 8 9 import logging #设置日志打印到指定路径，日志打印级别 logging.basicConfig(filename= \u0026#39;./app.log\u0026#39;，level= logging.debug,format = \u0026#39;%(name)s - %(levelname)s - %(asctime)s - %(message)s\u0026#39;) #format = \u0026#39;%(name)s - %(levelname)s - %(asctime)s - %(message)s\u0026#39; logging.critical(\u0026#39;程序崩溃\u0026#39;) logging.error(\u0026#39;程序出错\u0026#39;) logging.warning(\u0026#39;警告\u0026#39;) logging.info(\u0026#39;正常运行\u0026#39;) logging.debug(\u0026#39;调试运行\u0026#39;) 迭代器 迭代器(iterator)是一个实现了迭代器协议的对象。迭代器协议指的是对象需要实现两个方法:\n__iter__方法:当迭代器被创建时，这个方法会被调用，并且应该返回迭代器对象本身。这个方法使得对象能 够被用在for循环以及其他需要送代器的上下文中。 __next__方法:这个方法会在每次迭代中被调用，并且返回序列中的下一个元素。如果所有的元素都已经迭代完毕，会抛出一个Stopiteration类型的异常，表示迭代已经完成。 可迭代对象 可迭代对象(Iterable)是指能够返回一个迭代器的对象，换句话说，可迭代对象是实现了__iter__方法的对象，具有以下特点:\n实现了__iter__ 方法:可迭代对象必须拥有该方法，以便于返回一个迭代器对象。 可以用于for循环: 可迭代对象可以用于for循环，在for循环时，Python会自动调用__iter__方法来获取迭代器，然后不断调用迭代器的__next__去获取下一个元素。 Python中内置的列表、元组、字符串等都是可迭代对象，在使用for循环去遍历时，会调用可迭代对象的__iter__方法来获取一个迭代器，接着不断调用迭代器的__next__方法去获取下一个元素，直到元素全部迭代完毕，抛出异常，for循环会自己捕获这个异常并退出循环，从而完成一次for循环。\n迭代器与可迭代对象的关系： 所有迭代器都是可迭代对象:因为迭代器都必须具有__iter__和__next__方法，并且通常返回自身，也可以去访问序列中的下一个元素，并在所有元素都被迭代后抛出Stoplteration异常。 不是所有可迭代对象都是迭代器:可迭代对象只实现__iter__ 方法，并不实现__next__方法。比如Python内置的列表、元组、字符串等虽然是可迭代对象，但不是迭代器。 简单来说就是：1.凡是可作用for循环的对象都是可迭代对象；2.凡是同时拥有__iter__和__next__方法的都是迭代器。\n使用迭代器遍历列表 比如下列使用迭代器 __next__方法来遍历列表\n1 2 3 4 5 6 7 8 9 ls1 = [1,2,3,4,5,6] ls1_iter = ls1.__iter__() try: while True: item = ls1_iter.__next__() print(item) except StopIteration: print(\u0026#34;遍历完成\u0026#34;) 生成器 生成器(Generator)是一种特殊的迭代器，它可以在需要时动态生成值,避免一次性生成所有值所占用的大量内存。生成器使用 yield语句来产生值，可以通过迭代器协议来逐个获取生成器产生的值。生成器可以在循环中被逐个迭代，从而实现高效地处理大量数据或者无限序列。在Python中，生成器可以通过函数定义和生成器表达式来创建。\n生成器的特点 生成器的主要特点包括:\n惰性求值:生成器不会在创建时生成所有值，而是逐个生成值。这意味着生成器可以在需要的时候再去生成值, 使用yield关键字:只有yield被调用时，生成器才会返回一个值，并且程序暂停执行，直到下一次迭代时才继续执行。 内存效率:生成器可以处理大型数据集或生成大型数据结构，而不会占用太多内存，因为它们只在需要时生成值。 迭代器协议:生成器也是迭代器，所有实现了迭代器协议，因此可以用于for循环和其他需要迭代器的代码中。 生成器函数 生成器使用最多的地方是和函数结合，因此，拥有生成器的函数就叫做生成器函数，也可以理解为函数中包含了vield关键字的函数就是一个生成器函数。生成器函数包含如下特点:\n使用yield关键字:普通函数使用return返回值，而生成器函数使用yield关键字返回值。 状态保持:生成器函数在每次产生一个值之后会暂停执行，并保持当前的状态，包括局部变量的状态和当前的执行位置。当再次调用 生成器时，他会从上次yield语句之后的地方继续执行。 惰性求值:生成器只在需要时才计算并生成值，这意味着它可以高效处理大量数据或无限流数据, 生成器函数在调用时，不会立即执行函数里面的代码，而是会先返回一个生成器的对象，当调用生成器对象的__next__方法时，才会进入函数中并执行函数里面的代码，遇到yield关键字后，函数的执行将会暂停，并将yield后面的表达式作为当前迭代的值返回。然后每次调用生成器的__next__方法或使用for循环进行迭代时，函数会从上次暂停的地方继续执行，直到再次遇到yield关键字，并再次返回一个值，直到无法继续生成为止。\n","date":"2024-10-11T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python%E6%A8%A1%E5%9D%97%E4%B8%8E%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E6%9C%BA%E5%88%B6/","title":"Python模块与异常处理机制"},{"content":"面向过程和面向对象 面向过程【POP】是一种以过程为中心的编程思想，将程序看作一系列的命令，函数或过程的集合，主要是解决问的步骤和过程。程序被划分为一系列的函数，每个函数扶着完成一个特定的任务。数据在整个程序都是自由流动的，任何函数都可以访问和修改数据。\n面向对象编程【OOP】是将程序看作一系列对象的集合，每个对象都是独立 的个体，包含数据和操作这些数据的方法。这些对象之间通过发送消息来相互共同解决某种问题。\n面向过程：\n优点：效率高，性能高效。\n缺点：耦合度高，扩展性差，不易维护。\n面向对象：\n优点：模块化，扩展性强，易维护，代码重复性高。\n缺点：效率比面向过程低，学习难度大，性能开销大。\n类的定义 在Python中，使用class关键字定义一个类。定义格式为：\n1 2 class MyClass: pass 类的调用，也称为类的实例化，实例化出来的内容就称为对象，也叫创建对象。\n创建对象的格式为：\n对象名 = 类名（） 对象与类之间的关系：\n对象拥有类所定义的全部的属性和行为。 对象的属性和行为可以单独进行增加、修改、删除。 对象不能单独创建，必须依托类的实例化，且一个类可以实例化无数的对象。 对象之间的属性和行为不是共享的。 self参数 self是一个参数，表示对象自身，里面存放着对象自身的地址。如果希望类中的方法可以被对象调用，那么第一个参数必须是self。作用就是将实例对象与类的方法进行绑定，这样才能让每个对象都能调用属于自己的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class MyClass: name = \u0026#39;zhangsan\u0026#39; height = 180 def func(self): print(f\u0026#39;我是：{self.name}\u0026#39;) #创建对象 example1 = MyClass() #通过对象去调用属性， example1.func() #修改类中的属性 example1.name = \u0026#39;lisi\u0026#39; print(example1.name) #添加一个属性 examlpe1.age = 18 print(example1.age) #对类中的函数的添加和修改 def func(self): print(f\u0026#39;我的身高是{self.height}\u0026#39;) from types import MethodType example1.func = MethodType(func,example1) example1.func() 构造函数与析构函数 构造函数__init__():\n在创建对象时自动调用的一种函数，用来进行初始化属性，不是必须要定义的，可以在需要的时候再定义。\n析构函数__del__():\n在对象的引用清理时会自动调用的一种函数，一般用来进行释放资源的操作。在Python有自动回收内存机制，不推荐使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #构造函数示例 class Person: def __init__(self,name,age): self.name = name self.age = age def say(self): print(f\u0026#39;我是{self.name}，今年{self.age}岁了\u0026#39;) person1 = Person(\u0026#39;zhangsan\u0026#39;,18) person2 = Person(\u0026#39;lisi\u0026#39;,55) print(person1.name) print(person2.age) person1.say() person2.say() 类的封装 在Python中可以通过给属性名和方法名添加下划线（_）设置权限，根据下划线的个数分为不同类型：\n单下划线前缀：表示该属性或方法是内部使用，事实上程序是可访问的。 双下划线前缀：设置私有权限的方法，将该属性或行为定义为私有，且不可被对象访问。 双下划线前后缀：表示Python中的特殊的属性或方法，有特殊的意义和用途，不推荐自定义。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #私有权限设置 class Person: def __init__(self,name,password): self.name = name self.phone_id= \u0026#39;1234567890\u0026#39; self.__password = None #设置一个私有属性 def __say(self): print(f\u0026#34;我的密码是{self.__password}\u0026#34;) def change_password(self): self.__password = \u0026#34;4567898\u0026#34; self.__say() p1 = Person(\u0026#39;zhangsan\u0026#39;,\u0026#39;123456\u0026#39;) print(p1.name) print(p1.phone_id) p1.change_password() 类的继承 在Python中，一个类可以被继承，也可以去继承别的类，其中类的关系为父类与子类。在继承过程中，子类会继承父类的所有属性和行为，并且一个子类可以有多个父类。\n表示格式为：\nclass Person(要继承的类): pass 当不写【要继承的类】时，Python3.x中默认继承object类。object类中有以下函数：\n名称 作用 new() 创建对象 init() 初始化对象 eq() 定义比较符 iter() 让对象支持迭代 next() 在迭代中返回下一个值 class 对象所属的类 doc 对象的文档字符串 name 类的名称 类的多继承中，可以继承多个父类，但是也可能导致冲突，比如子类和多个父类有相同的属性和方法。那么此时在使用该属性或方法，其顺序为：\n子类》从左到右第一个父类》第二个父类》... 对于复杂的继承关系，使用子类的mro( )方法获取继承顺序。\n1 2 3 4 5 6 7 8 9 10 11 12 #单继承 class Zhangsan: name = \u0026#39;zhangsan\u0026#39; height = 180 def func(self): print(f\u0026#39;我是：{self.name}\u0026#39;) class Lisi(Zhangsan): pass p1 = Lisi() p1.func() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #多继承 class A: def __init__(self): print(\u0026#34;A\u0026#34;) class B1(A): def __init__(self): A.__init__(self) print(\u0026#34;B1\u0026#34;) class B2(A): def __init__(self): A.__init__(self) print(\u0026#34;B2\u0026#34;) class C(B1,B2): def __init__(self): B1.__init__(self) B2.__init__(self) print(\u0026#34;C\u0026#34;) c = C() #打印结果 A B1 A B2 C 这里的打印结果中，出现了两次A，如何避免这种资源浪费？\n答案是：使用super() 函数，根据mro继承顺序去搜索父类中的指定函数，并且自动绑定self参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #多继承，使用super()函数 class A: def __init__(self): print(\u0026#34;A\u0026#34;) class B1(A): def __init__(self): super().__init__() print(\u0026#34;B1\u0026#34;) class B2(A): def __init__(self): super().__init__() print(\u0026#34;B2\u0026#34;) class C(B1,B2): def __init__(self): super().__init__() print(\u0026#34;C\u0026#34;) c = C() #打印结果 A B2 B1 C 类的多态 多态指允许不同对象对同一个方法卓出不同响应，即同一个方法可以根据不同对象的类型而表现出不同行为。\n比如len()函数，对于字符串来说是统计字符串的长度，对于列表是统计列表中元素的个数。\n在类的继承中所用到的方法重写，就是一种实现多态的方式。通过重写父类中的属性和方法，使其拥有自己独特的属性和方法。\n","date":"2024-10-10T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python%E7%9A%84%E7%B1%BB/","title":"Python的类"},{"content":"函数的概念 函数：具有独立功能的代码块，使用函数名封装，通过函数名进行调用。其出现的目的就是为了代码的重复使用。\nPython中的函数分为两类：\n内置函数：在Python内部封装好的函数，比如前面用到的print()、input()等。\n自定义函数：用户在Python的语法规则下自己创建的具有独特功能的函数。\n常用的一些【内置函数】如：\n函数名 描述 min() max() 获取最大值最小值 help() 获取说明文档，使用示例help(min) abs() 求绝对值，可直接打印绝对值 round() 四舍五入，可按要求保留位数 pow(x,y) 求x的y次幂 自定义函数以def 关键字开头，后街函数名和():()中的参数需要定义，使用return结束函数，可选择返回一个值。如下列一个例子：\n1 2 3 def add(x,y): z = x +y return z 自定义函数需要关注，主要有名称、功能、参数、返回值。\n函数的参数 参数：\n参数是在函数定义时圆括号内的变量，用于接收调用函数时外部传递进来的数据。参数的最大作用就是可以让函数能够在不同的情况下重复使用。\n形式参数：也叫做形参，是函数定义中的参数，用于接收调用函数时传递的数据。形式参数在函数定义时被声明，并且在函数体内被用来执行相应的操作。\n实际参数：也称为参数值或者实参，是在函数调用时提供给函数的具体数值或变量。实际参数是根据函数定义中形式参数的顺序或者参数名对应传递给函数的数据。\n参数传入有5种方法：\n位置参数：参数传递时实参的顺序和个数必须和形参保持一致 1 2 3 4 def sub(x,y): print(x - y) sub(2,1) 关键字参数：使用【形参名字=实参】的方式,不用考虑形参的位置 1 2 3 4 def sub(x,y): print(x - y) sub(y=1,x=2) 默认参数：默认在定义时，必须放在形参的最右边 1 2 3 4 5 6 def add(x,y=2,z=1): print(\u0026#34;x的值为：\u0026#34;,x) print(\u0026#34;y的值为：\u0026#34;,y) print(\u0026#34;z的值为：\u0026#34;,z) add(1,y=3,z=5) 位置不定长参数：在函数定义时，使用*args来表示 1 2 3 4 5 6 7 8 def func(*args): for i in args: print(i) print(len(args)) print(type(args)) print(args) func(1,2,3,\u0026#39;abd\u0026#39;) 关键字不定长参数：以**kwargs作为标志，它会将输入的关键字参数中的关键字作为键值对的建，将关键字参数中的实参作为键值对的值。 1 2 3 4 5 def func(**kwargs): print(kwargs) print(type(kwargs)) func(name = \u0026#34;lisi\u0026#34;,age = 55) 函数的返回值 如果函数的运行结果需要在其他函数中使用，那么这个函数就应该被定义为带返回值的函数。\n函数的运行结果使用return关键字进行返回。\nreturn可以出现在函数的任意位置用于结束函数，但是一般放在函数的最后面以保证代码块能正常运行完毕。\n返回值可以是一个值，或多个值，如果返回的值是多个结果，默认为元组类型。\n1 2 3 4 5 6 7 8 def sub(x,y): z = x - y #将计算结果返回 return z #也可以 return x-y #定义一个变量ret接受返回值 ret = sub(2,1) print(ret) 局部变量和全局变量 变量的作用域是指变量生效的范围，根据范围作用的大小可分为局部变量和全局变量。\n1 2 3 a = 1 #全局变量 def : b = 2 #局部变量 局部变量：在函数定义时用到的参数和函数内部定义的变量。\n作用域：仅作用在函数内部，函数执行完毕，局部变量销毁。\n全局变量：在函数外部定义的变量或在函数内部使用global关键字修饰的变量。\n作用域：整个程序，直到程序运行结束，全局变量才会被销毁。\n匿名函数 匿名函数lambda：指没有名字的函数，一般在函数的函数体有一句且返回值，只有一个的时候才使用。其语法如下：\nlambda 参数列表：表达式 其中：\nlambda是Python的关键字，参数列表和表达式由用户自定义。 参数列表：它的结构与Python中函数的参数列表是一样的。 表达式：就是函数体，可以有多种形式，比如 a+b,su(a)等。 lambda的特性：\nlambda函数是匿名的，即它是没有名字的函数，并且自带return。 lambda函数可以使用任意数量的参数，但只能包含一个表达式。 lambda函数返回一个值，这个值就是表达式的结果。 lambda函数的生命周期很短，调用后立即被回收。 lambda函数的注意事项：\n匿名函数也可以使用默认参数和可变参数，语法与普通函数相同。\n内部函数 内部函数只能在外部函数中调用\n1 2 3 4 5 6 7 8 9 10 11 def outfnuc(): x = 1 def infunc(): x = 2 print(\u0026#34;内部函数\u0026#34;,x) #调用内部函数 infunc() print(\u0026#34;外部函数\u0026#34;,x) return outfnuc() 也可以以内函数作为返回值进行返回调用,形成闭包函数\n1 2 3 4 5 6 7 8 9 10 def outfnuc(): x = 1 def infunc(): x = 2 print(\u0026#34;内部函数\u0026#34;,x) print(\u0026#34;外部函数\u0026#34;,x) return infunc ret = outfnuc() ret() ","date":"2024-10-09T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python-%E5%87%BD%E6%95%B0/","title":"Python-函数"},{"content":"Numpy库 Numpy是Python中的一个扩展程序库，用于大量的维度数组与矩阵运算，同时针对数组运算提供了大量函数库。\n数组的创建 方式一：通过array{}函数将Python的列表或元组转换为数组，数组中的类型是由列表或原组原有的数据类型。\n1 2 3 4 5 import numpy as np a = np.array([2,3,4]) print(a) #打印类型 print(a.dtype) 方式二：Numpy提供了几个常用函数数组。\n1.zeros()创建一个指定大小全零数组 2.ones()创建一个指定大小的全一数组 3.empty()创建一个数组，其内容随机生成 1 2 3 4 5 6 7 import numpy as np a = np.zeros(3,4) b = np.ones(3,4) c = np.empty(3,4) print(a) print(b) print(c) 方式三：通过arrange（）函数得到数组\narrange函数原型arrange(start，end，step)函数的参数中end不包含该值。\n1 2 d = np.arrange(1,5,2) print(d) 矩阵运算 矩阵相乘表示方法：\na = np.array([1,2,3]) b = np.array([4,5,6]) c = a@b 矩阵形状改变 Numpy可以使用raveL()和reshape()函数改变矩阵形状，T函数将矩阵转置。\n1 2 3 4 5 6 7 8 9 10 11 import numpy as np a = np.array([(1,2,3),(4,5,6)]) print(a) #打印形状 print(a.shape) #展平 print(a.ravel()) #修改形状 print(a.reshape(3,2)) #转置 print(a.T) Pandas数据分析库 Series对象是Pandas中的一堆数据结构，能存储不同类型的数据。可以传入数字、列表、字典等类型，将该打印该对象同时会打印索引。\n1 2 3 4 5 6 7 8 9 10 11 import pandas as pd a = pd.Series([1,-5,[1,2],\u0026#34;aa\u0026#34;,{\u0026#34;aa\u0026#34;:555}]) print(a) \u0026#39;\u0026#39;\u0026#39; 打印结果 0 1 1 -5 2 [1, 2] 3 aa 4 {\u0026#39;aa\u0026#39;: 555} \u0026#39;\u0026#39;\u0026#39; Matplotlib绘图库 绘制一个正弦函数示例图：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import matplotlib.pyplot as plt import numpy as np #计算正弦曲线上x，y坐标 x = np.linspace(0, 2 * np.pi, 200) y = np.sin(x) #创建一个子图 fig, ax = plt.subplots() #使用plot绘制图像 ax.plot(x, y) #定义坐标轴和标签 plt.xlabel(\u0026#39;x轴\u0026#39;) plt.ylabel(\u0026#39;y轴\u0026#39;) plt.title(\u0026#39;Sine\u0026#39;) #显示图像 plt.show() 得到正弦函数: ","date":"2024-10-07T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%931/","title":"Python的第三方库1"},{"content":"数据类型-列表 列表：是一种有序的元素集合，用于存储一组有序的数据，可以包含任意数量的元素，并且每个元素可以是不同的数据类型。与字符串不同的是，列表里的元素是可以修改的。\n其表示方法为:\n列表名称 = [元素1,元素2,....,元素n] 列表的访问方式有下标访问和切片访问.列表的下标访问和切片访问与字符串的索引一样.\n不同的是,列表的切片访问可以访问多个元素\n列表的操作 对列表中内容,主要有增加,删除,修改,查找.\n列表的内容增加: append()像列表尾部加入元素; insert()在列表指定位置加入袁术; extend()将一个列表的所有元素添加到另一个列表 1 2 3 4 5 6 7 8 9 10 11 12 ###append()用法### list1 = [1,2,3] list1.append(4) print(list1) ###insert()用法### list2 = [1,2,3] list2.insert(2,4)#在下标2处插入4 print(list2) ###extend()用法### list1 = [1,2,3] list1.extend([4,5,6]) print(list1) 列表的内容删除: remove(元素)删除指定元素,列表中必须包含该元素 pop(下标)移除列表的一个元素,并返回该元素, clear()删除列表中的所有元素 del 关键字,指定下标时删除对应元素,未指定则删除整个列表对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ls = [1,2,3] #remove删除列表中的\u0026#39;1\u0026#39; print(ls.remove(1)) #打印结果:[2,3] #pop将指定下标的元素取出 print(ls.pop(1)) ##打印结果:2 #clear函数 print(ls.clear()) #打印结果:[] #del是一个关键字,当指定下标时,删除指定元素 del ls[0] del ls #不指定下标时,为删除这个列表吗,后续不可再用 列表的内容修改: 修改格式 列表名[索引] = '新内容' 1 2 3 list1 = [1,2,3,4] list1[0] = 0 print(list1) 列表的内容查找: 1.count()返回列表中某个元素的数量 2.使用in关键字查找,如果存在就返回True,否则返回False 1 2 3 4 5 6 7 8 #count使用 ls = [1,2,3,4,5] print(ls.count(3)) #打印结果:1 #使用in关键字 if 1 in ls: print(\u0026#39;1在列表中\u0026#39;) 列表的其他常用操作: len()获取列表中元素的个数 reverse()反转列表中的元素 sort()对列表元素进行排序(只针对数字型列表) copy()对列表的拷贝 ls[][]列表的嵌套,如ls[[1,2],[3,4]] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #对数字列表排序 list1 = [1,88,36,45,42,9] list1.sort(reverse=True)#默认False从小到大排序 print(list1) #如果想对字符串排序 list1 = [\u0026#39;a\u0026#39;,\u0026#39;bdf\u0026#39;,\u0026#39;de\u0026#39;,\u0026#39;dasdd\u0026#39;] list1.sort(reverse=True,key=len)#依据字符串的长度排序 print(list1) #列表的浅拷贝, l1 = [1,2,3] l2 = l1.copy() #列表的深拷贝 import copy l3 = copy.deepcopy(l1) #列表推导式,如对列表平方 ls = [1,2,3,4,5] squared_ls = [x ** 2 for x in l1] print(squared_ls) 数据类型-元组 元组:与列表相似,不同之处在于元组的元素不可修改.\n元组的表示使用()表示:\n元组名 = (元素1,元素2,...,元素n) 元组元素的访问,有下标与切片访问,与字符串、列表的方式相同.\n元组的常用操作 元组的常用操作: len():获取元组中元素的个数 max():返回元组中元素最大值 min():返回元组中元素最小值 使用in或not in 查找元素是否在元组中 del:删除元组,使用和列表相同\n元组的推导式语法:\nfor 元素 in 元组 if 条件1 序列 元组、列表、字符串的共同点:\n1.都可以通过下标获取每一个元素. 2.第一个元素的下标为0(从左到右). 3.都可以通过切片的方法获取一个范围. 这些共同点简称序列.其中列表是可变序列,元组和字符串是不可变序列.\n序列的操作 min()和max(),可以用于统计序列中最大值和最小值,根据传入的序列和参数的不同有不同的结果.\nlen()函数:用来计算序列的长度或元素的个数.\nsum()函数:求序列元素的和,可以通过start参数来决定求的初始值.\n1 2 s1 = [1,2,3,4,5] print(sum(s1,start=10)) sorted():用于对序列进行排序,与列表的sort函数不同在于,该函数会返回一个全新的列表,原有的序列不会改变.\n1 2 3 4 s = [1,2,3,4,6] print(sorted(s,reverse=True)) s.sort() print(s) reversed():对序列进行反转,该函数会返回一个迭代器,需要通过强转或for循环来观看元素\n1 2 3 s = [1,2,3,4,5,6] for i in reversed(s1): print(i) all():用于判断序列中的所有元素是否为真,返回布尔值.\nany():用于判断序列中的某个元素是否为真,返回布尔值.\n1 2 3 s = [1,2,3,4,5,6] print(all(s)) print(any(s)) enumerate():用于将一个可遍历对象的数据对象中的下标与元素组合起来,返回的是枚举对象(类似:(0,\u0026lsquo;H\u0026rsquo;))\n1 2 3 s = [\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;d\u0026#39;,\u0026#39;e\u0026#39;] for i in enumerate(s): print(i) zip():用于将多个可迭代对象中对应位置的元素打包成一个元组,然后返回这一元组.\n1 2 3 4 5 6 7 l1 = [1,2,3] l2 = [4,5,6] l3 = [7,8,9] l4 = zip(l1,l2) print(list(l4)) l5 = zip(l1,l2,l3) print(list(l5)) 此外还有map()函数:对可迭代对象中的每个元素用一个指定的函数;filter()函数:对可迭代对象中的每个元素用一个指定的函数,并返回结果为真的元素.\n数据类型-集合 集合是一个无序的不重复的序列,分为可变和不可变集合.\n可变集合的元素在定义好之后是不可修改的,但集合本身是可以增加三处元素,这意味着集合的元素只能是数字字符串及元组,并且每个元素只能出现一次.\n集合使用花括号{}表示:\n集合名 = {元素1,元素2,...,元素n} 可变集合的添加 add(): 一次添加单个元素.\nupdata():一次添加多个元素.\n1 2 3 4 5 6 set1 = {1,2,3,4,5} set2 = {4,5,6,7} set1.add(7) print(set1) set2.update(\u0026#39;hello\u0026#39;,\u0026#39;world\u0026#39;) print(set2) remove():删除指定的元素,如果不存在,会报错\ndiscard():删除指定的元素,如果不存在,不会报错\npop():删除第一个元素,如果集合为空,会报错\n1 2 3 4 5 6 7 8 set1 = {1,2,3,4,5} set1.remove(2) set1.remove(9) print(set1) set2 = {4,5,8,9} ret = set2.pop() print(ret) 可变集合元素的查找:\nin:使用关键字查找某元素是否存在于集合中.\n部分其他操作:\nlen():计算集合里元素个数\nset():生成一个集合\ncopy():浅拷贝\nclear():清空集合\nintersection():求两个集合的交集\nunion():求两个集合的并集\nissubset():求两个集合是不是子集关系\nissuperset():求两个集合是不是父集关系\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 set1 = set(\u0026#39;abc\u0026#39;) print(set1) set2 = set1.copy() print(set2) #求交集 set3 = {4,5,6} set4 = {1,2,3,4} set5 ={1} print(set3.intersection(set4)) #求并集 print(set3.union(set4)) #求关系 print(set5.issubset(set4)) print(set4.issuperset(set5)) 每日一曲 ","date":"2024-10-02T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%954/","title":"Python基础语法4"},{"content":"强制数据类型转换 type()函数可以用来查看一个变量的数据类型.目前常见的数据类型用下面几种:\n数据类型 解释 int 整数 float 浮点数 bool 布尔值 str 字符串 list 列表 tuple 元组 set 集合 dict 字典 如果我们想转换数据类型,有两种方式.\n1.显式类型转换\n显式类型转换是强制类型转换,这种转换并不是所有对象都可以安全的转换为任意其他类型,转换的过程中可能会报错.\n2.隐式类型转换\n隐式类型转换则是解释器自动将一种数据类型的值转换为另一种数据类型.\n下面举个例子\n1 2 3 4 5 6 7 8 9 10 11 a = input(\u0026#39;输入整数a:\u0026#39;) b = input(\u0026#39;输入整数b:\u0026#39;) print(a+b) print(type(a)) \u0026#39;\u0026#39;\u0026#39; 打印结果: a:5 b:6 56 \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026#39;\u0026#39;\u0026#39; 可以看到这里打印的a+b是56,使用type函数发现输入的值以字符串形式存储的,这显然不和要求,因此需要进行输入数据转换\n1 2 3 4 a = int(input(\u0026#39;输入整数a:\u0026#39;)) #或者 a = input(\u0026#39;输入整数a:\u0026#39;) a = int(a) 条件语句 条件语句,也叫做判断语句,简单来说就是如果满足某个条件,就去做某件事,不满足就不做.\n条件语句使用if关键字作判断,使用方式三种判断格式:\nif格式 这是一种基础格式,他的执行逻辑:先执行表达式,如果表达式为真,则执行代码块,否则不会执行.\n1 2 3 4 a = int(input(\u0026#39;输入整数a:\u0026#39;)) b = int(input(\u0026#39;输入整数b:\u0026#39;)) if a \u0026lt; b: print(\u0026#34;a小于b\u0026#34;) if-else格式 if-else执行逻辑:先执行表达式,如果表达式为真,则执行代码块1,否则执行代码块2.\n1 2 3 4 5 6 a = int(input(\u0026#39;输入整数a:\u0026#39;)) b = int(input(\u0026#39;输入整数b:\u0026#39;)) if a \u0026lt; b: print(\u0026#34;a小于b\u0026#34;) else: print(\u0026#34;a大于等于b\u0026#34;) if-elif-else if-elif-else的执行逻辑:先执行表达式1，如果表达式1为真则执行代码块1，否则继续执行表达式2；如果表达式2为真则执行代码块2，否则继续向下执行；如果所有的表达式都为假，则 执行else分支。\n1 2 3 4 5 6 7 8 a = int(input(\u0026#39;输入整数a:\u0026#39;)) b = int(input(\u0026#39;输入整数b:\u0026#39;)) if a \u0026lt; b: print(\u0026#34;a小于b\u0026#34;) elif a == b: print(\u0026#34;a等于b\u0026#34;) else: print(\u0026#34;a大于b\u0026#34;) match-case 在Python3.10版本后,新增加了match case语句,也可以用来作条件判断,处理复杂的条件分支:\n1 2 3 4 5 6 7 8 match subject: case condition1: pass#代码块1 case condition2: pass#代码块2 case _: pass#代码块3 循环语句 在Python中,循环语句是程序重复执行一段代码知道满足特定条件为止的关键结构,共有2种格式:for 和 while 两种.\nwhile循环 while循环语法: 如果满足条件,则进入while循环执行代码块,执行完后返回条件再判断返回结果,直到条件不满足,退出循环.\n如下面求1~100累加和的例子\n1 2 3 4 5 6 i = 0 sum = 0 while i \u0026lt;= 100: sum += i i += 1 print(f\u0026#34;1+2+3+...+100的和为:{sum}\u0026#34;) for循环 for循环可以循环遍历任何序列,比如字符串,列表等可遍历对象,只要可遍历 对象没有遍历完,那么代码块就会一直执行,直到可遍历对象遍历完毕.\n1 2 for 临时变量 in 可遍历对象: 代码块 这里的可遍历对象可以是整数序列,整数列表等,也可以直接用range()函数,直接生成一个整数序列对象.\n1 range(start,stop,step) 从语法上可知,这个整数序列从start开始(不写默认为0);到stop结束,但是不包括stop;step为步长(不写默认为1).如range(2,9,1):返回序列[2,3,4,5,6,7,8]\n1 2 3 4 5 # 使用for和range函数生产9*9乘法表 for i in range(1,10): for j in range(1,i+1): print(f\u0026#34;{j} * {i} = {j*i}\u0026#34;,end=\u0026#39; \u0026#39;) print() 循环控制关键字 在for和while循环中,有三种循环控制关键字.\n1.break:在代码块执行过程中终止循环,并跳出本层循环.\n2.continue:在代码块执行过程中终止本次循环，执行下一次循环.\n3.pass:空语句，相当于一个占位符，它的作用是在语法上需要一个语句，但 程序不需要任何操作时使用。例如,某个语句后面不写内容会报错,就会先用pass占位.\n每日一曲 ","date":"2024-10-01T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%952/","title":"Python基础语法2"},{"content":"数据类型-数字 在Python中,数字类型包括以下几种:\n1.整型int( ):包括正整数,负整数和0,在程序中的表达与数学上一致\n2.浮点型float( ):小数.\n3.布尔型bool( ):特殊的整型,只用True和False,True为1,False为0.\n4.复数complex( ):与数学上表达式一致,分为实部与虚部,用j表示,多用于科学计算.\n布尔型数据的短路求值 在Python中,布尔型数据的短路求值是一种特殊的逻辑运算规则，当逻辑表达式的某个部分已经能够确定整个表达式的值时，就不再计算表达式的其余部分。 比如在下面个例子中\n1 2 3 4 5 a = 10 b = 0 re1 = a or b re2 = a and b print(re1,re2) 数据类型-字符串 字符串由引号括起来的一系列数字,字母,及中文的组合,并且定义好的字符串是不可修改的.\n1 2 3 4 5 6 7 8 9 10 11 #单引号 src = \u0026#39;hello world\u0026#39; #三引号创建多行字符串 src2 = \u0026#39;\u0026#39;\u0026#39; 闲吟秋景外， 万事觉悠悠。 此夜若无月， 一年虚过秋。 \u0026#39;\u0026#39;\u0026#39; print(src1) print(src2) 转义字符 转义字符：是一种特殊字符，用于表示无法直接表示的字符，以反斜杠“\\”开头。\n常用的转义字符：\n换行符：\\n，用于实现换行。 制表符：\\t，相当于一个Tab。 回车符：\\r，将光标移至当前行的开头。 反斜杠：\\\\，将反斜杠本身转义，使反斜杠本身成为一个普通字符。 单引号与双引号：\\’和\\”，将单引号与双引号转义，使其不再是字符串的标识，而是仅仅只是一个单引号或双引号。 字符串的访问 字符串的访问有下标访问与切片访问。下标访问：所谓的下标，其实就是编号，通过编号就可以找到对应的字符，下标可按照从左至右的顺序开始计算，也可以按照从右至左的顺序开始计算，但是访问的时候下标不能超出范围。\nsrc = 'zhangsan' src[0] = z src[1] = h 切片访问与下标访问类似，都是通过字符串的下标进行的，不同的是，下标访问每次只能访问到单个字符，切片访问可以一次访问到多个字符，其访问方式为：\n字符串名[初始位置：终止位置：步长] 访问时，包括初始位置不包括终止位置，且步长默认为1。如果没有给出初始位置，默认初始位置为开始位置；如果没有给出终止位置，默认终止位置为字符串结束位置，此时访问时包括终止位置。\nsrc = 'zhangsan lisi' print(src[0:10:1]) #打印结果:zhangsan l #从左0开始,到第9个,步长为1,打印输出 字符串的操作 字符串的操作总结来说有:查询、转换、判断、分割等\n查询函数 解释 find() 检测字符串是否包含指定字符，如果是则返回开始的索引值，否则返回-1 index() 检测字符串是否包含指定字符，如果是则返回开始的索引值，否则报错 rfind() 从右向左，检测字符串是否包含指定字符，如果是则返回开始的索引值，否则返回-1 rindex() 从右向左，检测字符串是否包含指定字符，如果是则返回开始的索引值，否则报错 转换函数 解释 lower() 将字符串转换为小写 upper() 将字符串转换为大写 title() 将字符串中每个单词的首字母大写 判断函数 解释 startswith() 如果字符串一obj开头,返回True,否则返回False endswith() 如果字符串以obj结尾，则返回True，否则返回False isspace() 如果字符串只包含空格则返回True，否则返回False isalnum() 如果字符串都是字母或数字则返回True，否则返回False isdigit() 如果字符串都是数字则返回True，否则返回False isalpha() 如果字符串都是字母则返回True，否则返回False 分割函数 解释 partition() 将字符串根据参数分割为三部分 rpartition() 从右向左，将字符串根据参数分割为三部分 split() 将字符串根据参数进行分割，且可以指定分割的次数 splitlines() 按照\\n分割，返回一个列表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #字符串的分割 #partition()函数:将字符串按参数分割 str3 = \u0026#39;hello world hello python\u0026#39; print(str3.partition(\u0026#39;world\u0026#39;)) print(str3.rpartition(\u0026#39;world\u0026#39;)) #split()将字符串分割有限次 print(str3.split(\u0026#39; \u0026#39;,2)) print(str3.splitlines()) #count()函数 print(str3.count(\u0026#39;o\u0026#39;)) #join函数 str4 = \u0026#39;_\u0026#39; str5 = [\u0026#39;hello\u0026#39;,\u0026#39;world\u0026#39;] print(str4.join(str5)) #replace函数 print(str3.replace(\u0026#39;hello\u0026#39;,\u0026#39;nihao\u0026#39;)) #capitalize函数,将首字母大写 print(str3.capitalize()) 每日一曲 ","date":"2024-10-01T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/R-C.png","permalink":"https://UPPO8.github.io/Myblog/p/python%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%953/","title":"Python基础语法3"},{"content":"引言 Python作者：Guido von Rossum(吉多·范·罗苏姆)\n诞生时期：1991年，第一个Python解释器诞生.它是用C语言实现的，并能够调用C语言的库文件.\n编程语言的种类有很多，但目前常用的有C、C++、Java、JavaScript、C#、PHP、Ruby以及Python，并且在2021年Python已经超过C称为第一受欢迎的编程语言.\nPython的优缺点 以下代码使用C语言和Python输出a+b的例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13 -----C语言中----- #include \u0026lt;stdio.h\u0026gt; int main() { int a = 1; int b = 1; printf(\u0026#34;%d\\n\u0026#34;,a + b); return 0; } -----Python----- a = 1 b = 1 print(a + b) 这里的代码我们可以发现,Python中每行代码通常代表一条语句的结束,且不需要任何的符号作为每行的结束符.\n缩进与注释 在Python中，通过缩进来组织代码块，例如函数体、循环体、类等.缩进必须一直，通常使用空格来实现（推荐使用4个空格），也可以使用一个制表符.并且同一级别的代码块具有相同的缩进量，下一级别的代码块应比上级别的代码 块增加一个缩进层级.例如:\n1 2 3 4 5 # 使用for和range函数生产9*9乘法表 for i in range(1,10): for j in range(1,i+1): print(f\u0026#34;{j} * {i} = {j*i}\u0026#34;,end=\u0026#39; \u0026#39;) print() 这个例子中,单行注释以(#)开头,井号(#)所在位置的右边都会被当作注释.多行注释则是三引号\u0026rsquo;\u0026lsquo;\u0026lsquo;或\u0026quot;\u0026quot;\u0026quot;,引号中间的内容注释掉.\n1 2 3 4 5 6 7 \u0026#39;\u0026#39;\u0026#39; # 求1到100的和 sum = 0 for i in range(1,101,1): sum += i print(sum) \u0026#39;\u0026#39;\u0026#39; 变量与关键字 变量的三个基本属性:\nid号:反映的是变量值的内存地址.\n类型:每一个变量都有自己的类型.\n值:存储的数据.\n1 2 3 4 5 6 7 8 9 10 # 查看变量id好id() # 查看变量类型type() # 使用 is 或 is not 比较两个变量的id号是否相同 a = 2 b = \u0026#39;nihao\u0026#39; c = 2 print(id(a), id(b), id(c)) print(type(a), type(b), type(c)) print(a is b ,a is c) 输出结果:\n1 2 3 140719832613704 3081789329776 140719832613704 \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; False True 输出结果中可以发现,a和c的id号与类型是一致的,使用is判断返回结果为True.\n变量命名的注意事项:\n1.只能包含字母、数字、下划线，但不能以数字开头。\n2.不能包含空格，但是可以使用下划线来分割名称。\n3.不能使用Python的关键字作为标识符的名称。\nPython运算符 在Python中，常用的运算符分为以下几类：\n算数运算符 算术运算符包括以下几种：\n+：加法运算符，返回两个对象的和\n-：减法运算符，返回两个对象的差\n*：乘法运算符，返回两个对象的积\n/：除法运算符，返回两个对象的商\n//：整除运算符，返回两个对象的商的整数部分\n%：取余运算符，返回两个对象的商的余数部分\n**：平方运算符：返回两个对象的平方运算的结果\n比较运算符 比较运算符包括以下几种：\n==：等于，比较两个对象是否相等，返回布尔值\n！=：不等于，比较两个对象是否不相等，返回布尔值\n＞：大于，比较两个对象的大小关系，返回布尔值\n\u0026lt;：小于，比较两个对象的大小关系，返回布尔值\n＜=：大于等于，比较两个对象的大小关系，返回布尔值\n\u0026lt;=：小于等于，比较两个对象的大小关系，返回布尔值\n逻辑运算符 逻辑运算符 逻辑运算符包括以下几种： and：布尔与，and两边都为True时，才会返回True，只要有一个为False，就会返回False\nor：布尔或，or两边都为False时，才会返回False，只要有一个为True，就会返回True\nnot：布尔非，将True改为False，将False改为True\n赋值运算符 赋值运算符包括以下几种： =：赋值运算符，把=右边的对象赋值给=左边的对象\n+=：加法赋值运算符\n-=：减法赋值运算符\n*=：乘法赋值运算符\n/=：除法赋值运算符\n//=：整除赋值运算符\n%=：取余赋值运算符\n**=：平方赋值运算符\n位运算符 位运算符包括以下几种：\n\u0026amp;：按位与，对两个数据的补码进行位与位之间的与运算，全1为1，有0则0\n|：按位或，对两个数据的补码进行位与位之间的或运算，全0为0，有1则1\n^：按位异或，对两个数据的补码进行位与位之间的异或运算，相同为0，同为1\n运算符的优先级 运算符的优先级（从上向下排列，上面的优先级最高）：\n圆括号()：圆括号内的表达式拥有最高优先级\n**：乘方运算\n*、/、%、//：算术运算符，先乘除\n+、-：算数运算符，后加减\n\u0026laquo;、\u0026raquo;：位运算符的左移与右移\n\u0026amp;：位运算符的按位与\n^：位运算符的按位异或\n|：位运算符的按位或\n＞、＜、\u0026gt;=、\u0026lt;=、==、!=：比较运算符\nand、or：逻辑运算符\n=、+=等赋值运算符优先级最低\n输入与输出 在Python中，使用内置的print()函数进行输出，并且有几种不同的输出方式如下所示：\n基本输入输出： 使用input()输入,使用print()输出,直接打印数据或变量:\n1 2 a = 2 print(a) 格式化输出： 使用百分号(%)格式符:\n格式符 解释 %c 字符 %s 字符串 %d 有符号十进制整数 %f 浮点数 %e 科学计数法 %o 八进制整数 现在不推荐使用，但是旧版本的代码中很常见.\n1 2 a = 2 print(\u0026#39;%d\u0026#39;,a) format()方法： 使用花括号{}作为占位符来指定要格式化的数据类型和格式，然后通过将数据插入到占位符中来生成最后的输出结果。\n1 2 3 4 5 6 7 #用format方法 name = \u0026#39;zhangsan\u0026#39; age = 18 weight = 55.55632 print(\u0026#34;My name is {} and {} years old and {} weight\u0026#34;.format(name,age,weight)) # 控制浮点数精度 :.nf,n为位数\\n\u0026#34;, print(\u0026#34;My name is {} and {} years old and {:.4f} weight\u0026#34;.format(name,age,weight)) f-string： 在字符串前加一个f或F，然后在输出的内容中加上花括号{}，花括号{}里面是要输出的表达式，是一种新的字符串格式方法，在Python3.6版本之后引入的输出方法。\n1 2 3 4 5 6 7 #用format方法 name = \u0026#39;zhangsan\u0026#39; age = 18 weight = 55.55632 print(f\u0026#34;My name is {name} and {age} years old and {weight} weight\u0026#34;) # 控制浮点数精度 :.nf,n为位数\\n\u0026#34;, print(f\u0026#34;My name is {name} and {age} years old and {weight:.2f} weight\u0026#34;) 六大基本数据类型 数据类型 解释 mymum = 11 数值 myfloat = 3.141 浮点数 mystr = \u0026lsquo;hello\u0026rsquo; 字符串 mylist = [1,2,3,4] 列表 mytuple = (1,2,3,4) 元组: myset = {1,2,3,4} 集合 mydict = {\u0026ldquo;key1\u0026rdquo;:\u0026ldquo;value1\u0026rdquo;} 字典 强制数据类型转换函数\n函数 解释 int(x) 转换为整数 float(x) 转换为浮点数 str(x) 转换为字符串 tuple(s) 序列转换为元组 list(s) 序列转换为列表 hex(s) 序列转换为16进制 每日一曲 ","date":"2024-09-30T00:00:00Z","image":"https://UPPO8.github.io/Myblog/images/PythonCourse/write-plan.jpg","permalink":"https://UPPO8.github.io/Myblog/p/python%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%951/","title":"Python基础语法1"},{"content":"使用Python爬取百度图片\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 from fake_useragent import UserAgent import requests import re import uuid headers = {\u0026#34;User-agent\u0026#34;: UserAgent().random, # 随机生成一个代理请求 \u0026#34;Accept-Encoding\u0026#34;: \u0026#34;gzip, deflate\u0026#34;, \u0026#34;Accept-Language\u0026#34;: \u0026#34;zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\u0026#34;, \u0026#34;Connection\u0026#34;: \u0026#34;keep-alive\u0026#34;, \u0026#34;cookie\u0026#34;: \u0026#39;BAIDU_WISE_UID=wapp_1726906421787_41; ZFY=cggvvWz7Y:AvYezL06fvqCimMOCYkqDMtbJ5RzE0wB1Y:C; BAIDUID_BFESS=316C0566E374307EC37BCF07E6F2F4AF:FG=1; newlogin=1; BIDUPSID=316C0566E374307EC37BCF07E6F2F4AF; BDRCVFR[dG2JNJb_ajR]=mk3SLVN4HKm; H_WISE_SIDS=60829; BDRCVFR[-pGxjrCMryR]=mk3SLVN4HKm; BDRCVFR[tox4WRQ4-Km]=mk3SLVN4HKm; BDRCVFR[A24tJn4Wkd_]=mk3SLVN4HKm; BDRCVFR[X_XKQks0S63]=mk3SLVN4HKm; firstShowTip=1; cleanHistoryStatus=0; RT=\u0026#34;z=1\u0026amp;dm=baidu.com\u0026amp;si=a0fa21b3-7bde-440a-966a-404ccd3e6fdd\u0026amp;ss=m1w0jp0l\u0026amp;sl=i\u0026amp;tt=7cg\u0026amp;bcn=https%3A%2F%2Ffclog.baidu.com%2Flog%2Fweirwood%3Ftype%3Dperf\u0026amp;ld=3luz\u0026amp;ul=4pvi\u0026amp;hd=4q6a\u0026#34;; indexPageSugList=%5B%22cat%22%2C%22dog%22%5D; ab_sr=1.0.1_MzQwMjZkMGYwMTM5ZjAzOWYzMGZlMTU2ZjFhOWZkMjlkNDk2NjQzZTdmOTFlYmZkZDFmMjA2YjM3Y2E4YzgxYzU3MTJlYWQ0NjNiNTQwZGM4ZTJiNThmMzBlN2IzMGNmYzI3NzNhMTNhYTc2M2VmODkwZTNjMmJmYTRhNTRmNmE0YTAyNWFiY2UwZGFlM2I4YmM3MGRmM2QxYzcwYjg3Ng==\u0026#39; } img_re = re.compile(\u0026#39;\u0026#34;thumbURL\u0026#34;:\u0026#34;(.*?)\u0026#34;\u0026#39;) img_format = re.compile(\u0026#34;f=(.*).*?w\u0026#34;) def file_op(img): uuid_str = uuid.uuid4().hex tmp_file_name = \u0026#39;E:/HQYJ/course1/images/%s.jpeg\u0026#39; % uuid_str with open(file=tmp_file_name, mode=\u0026#34;wb\u0026#34;) as file: try: file.write(img) except: pass def xhr_url(url_xhr, start_num=0, page=5): end_num = page * 30 for page_num in range(start_num, end_num, 30): resp = requests.get(url=url_xhr + str(page_num), headers=headers) if resp.status_code == 200: img_url_list = img_re.findall(resp.text) # 这是个列表形式 for img_url in img_url_list: img_rsp = requests.get(url=img_url, headers=headers) file_op(img=img_rsp.content) else: break print(\u0026#34;内容已经全部爬取\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: org_url = \u0026#34;https://image.baidu.com/search/acjson?tn=resultjson_com\u0026amp;word={text}\u0026amp;pn=\u0026#34;.format( text=input(\u0026#34;输入你想检索内容:\u0026#34;)) xhr_url(url_xhr=org_url, start_num=int(input(\u0026#34;开始页:\u0026#34;)), page=int(input(\u0026#34;所需爬取页数:\u0026#34;))) ","date":"2024-09-30T00:00:00Z","permalink":"https://UPPO8.github.io/Myblog/p/%E4%BD%BF%E7%94%A8python%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E5%9B%BE%E7%89%87/","title":"使用Python爬取百度图片"},{"content":"添加网易云音乐: 在网易云音乐页面,点击一首歌曲, 例如:大鱼 点击生成外链播放器,得到该音乐的HTML插入代码,然后在你的文章md中插入改代码即可播放音乐了.\n添加QQ音乐: QQ音乐获取外链教程具体见:如何获得QQ音乐官方外链播放器并嵌入进网页\n","date":"2024-09-30T00:00:00Z","permalink":"https://UPPO8.github.io/Myblog/p/%E7%BD%91%E9%A1%B5%E5%B5%8C%E5%85%A5%E5%BC%8F%E9%9F%B3%E4%B9%90%E6%92%AD%E6%94%BE%E5%99%A8/","title":"网页嵌入式音乐播放器"},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://UPPO8.github.io/Myblog/p/","title":""}]